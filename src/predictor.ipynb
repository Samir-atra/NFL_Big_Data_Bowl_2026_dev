{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Force JAX to use CPU due to GPU conflicts and memory issues in the current environment.\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "# Force TensorFlow to use CPU due to GPU conflicts and memory issues in the current environment.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_label_specs(dataset):\n",
    "    \"\"\"\n",
    "    Gets the feature and label specifications from a TensorFlow Dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): The TensorFlow Dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the feature and label specifications.\n",
    "               (feature_spec, label_spec)\n",
    "    \"\"\"\n",
    "    element_spec = dataset.element_spec\n",
    "    return element_spec[0], element_spec[1]\n",
    "\n",
    "def create_preprocessor(features_df):\n",
    "    \"\"\"\n",
    "    Creates a preprocessor for the NFL Big Data Bowl 2026 prediction data.\n",
    "\n",
    "    Args:\n",
    "        features_df (pd.DataFrame): The dataframe with the features.\n",
    "\n",
    "    Returns:\n",
    "        ColumnTransformer: The preprocessor.\n",
    "    \"\"\"\n",
    "    categorical_features = ['play_direction', 'player_position', 'player_side', 'player_role', 'nfl_id']\n",
    "    numerical_features = ['x', 'y', 's', 'a', 'dir', 'o', 'absolute_yardline_number', 'player_weight', 'num_frames_output', 'ball_land_x', 'ball_land_y', 'age', 'height_inches']\n",
    "    boolean_features = ['player_to_predict']\n",
    "\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    boolean_transformer = FunctionTransformer(lambda x: x.astype(int))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('bool', boolean_transformer, boolean_features)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "def height_to_inches(height_str):\n",
    "    \"\"\"Converts height string 'feet-inches' to inches.\"\"\"\n",
    "    if isinstance(height_str, str):\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return feet * 12 + inches\n",
    "    return jnp.nan\n",
    "\n",
    "SEQUENCE_LENGTH = 10\n",
    "\n",
    "def create_sequences(df, sequence_length, feature_columns_for_model):\n",
    "    \"\"\"\n",
    "    Creates sequences of features and corresponding labels for a single player/play.\n",
    "    Each sequence consists of `sequence_length` frames, and the label is the\n",
    "    x_label, y_label of the frame immediately following the sequence.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    # Ensure the DataFrame is sorted by frame_id\n",
    "    df = df.sort_values(by='frame_id').reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        # Features are frames i to i + sequence_length - 1, selecting only model features\n",
    "        seq_features = df.iloc[i:i + sequence_length][feature_columns_for_model]\n",
    "        # Label is frame i + sequence_length\n",
    "        seq_label = df.iloc[i + sequence_length][['x_label', 'y_label']]\n",
    "        \n",
    "        sequences.append(seq_features)\n",
    "        labels.append(seq_label)\n",
    "    \n",
    "    return sequences, labels\n",
    "\n",
    "def load_and_prepare_data(data_dir, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Loads input and output data from CSV files in the specified directory,\n",
    "    merges them, preprocesses the features, splits them into training and \n",
    "    validation sets, and returns them as TensorFlow Datasets.\n",
    "    The data is prepared into sequences of SEQUENCE_LENGTH frames.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the directory containing the training data.\n",
    "        test_size (float): The proportion of the dataset to allocate to the validation set.\n",
    "        random_state (int): The seed for the random number generator used for the split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and validation TensorFlow Datasets,\n",
    "               and the preprocessor.\n",
    "               (train_dataset, val_dataset, preprocessor)\n",
    "    \"\"\"\n",
    "    input_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('input')])\n",
    "    output_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('output')])\n",
    "\n",
    "    input_dfs = [pd.read_csv(f) for f in input_files]\n",
    "    output_dfs = [pd.read_csv(f) for f in output_files]\n",
    "\n",
    "    input_df = pd.concat(input_dfs, ignore_index=True)\n",
    "    output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "\n",
    "    merged_df = pd.merge(input_df, output_df, on=['game_id', 'play_id', 'nfl_id', 'frame_id'], suffixes=('', '_label'))\n",
    "\n",
    "    # Feature Engineering\n",
    "    merged_df['height_inches'] = merged_df['player_height'].apply(height_to_inches)\n",
    "    \n",
    "    game_date_str = merged_df['game_id'].astype(str).str[:8]\n",
    "    game_date = pd.to_datetime(game_date_str, format='%Y%m%d')\n",
    "    player_birth_date = pd.to_datetime(merged_df['player_birth_date'])\n",
    "    merged_df['age'] = (game_date - player_birth_date).dt.days / 365.25\n",
    "\n",
    "    all_sequences = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Define the columns that will be used as features for the preprocessor\n",
    "    # This list should exclude labels and identifiers that are not model features\n",
    "    feature_cols_for_model = [\n",
    "        'x', 'y', 's', 'a', 'dir', 'o', 'absolute_yardline_number',\n",
    "        'player_weight', 'num_frames_output', 'ball_land_x', 'ball_land_y',\n",
    "        'age', 'height_inches', 'play_direction', 'player_position',\n",
    "        'player_side', 'player_role', 'nfl_id', 'player_to_predict'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with only the features that will be preprocessed\n",
    "    # This is what the preprocessor will be fitted on\n",
    "    features_for_preprocessor_fitting = merged_df[feature_cols_for_model]\n",
    "\n",
    "    preprocessor = create_preprocessor(features_for_preprocessor_fitting)\n",
    "    preprocessor.fit(features_for_preprocessor_fitting) # Fit the preprocessor here\n",
    "\n",
    "    # Group by game, play, and player to create sequences\n",
    "    for (game_id, play_id, nfl_id), group_df in merged_df.groupby(['game_id', 'play_id', 'nfl_id']):\n",
    "        if len(group_df) >= SEQUENCE_LENGTH + 1: # Need at least SEQUENCE_LENGTH + 1 frames for one sequence and its label\n",
    "            sequences, labels = create_sequences(group_df, SEQUENCE_LENGTH, feature_cols_for_model) # Pass feature_cols_for_model\n",
    "            all_sequences.extend(sequences)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    if not all_sequences:\n",
    "        raise ValueError(\"No sequences could be created. Check data and SEQUENCE_LENGTH.\")\n",
    "\n",
    "    # Transform all sequences using the already fitted preprocessor\n",
    "    processed_sequences = []\n",
    "    for seq_df in all_sequences:\n",
    "        # Ensure seq_df only contains the columns the preprocessor was fitted on\n",
    "        processed_seq = preprocessor.transform(seq_df).toarray()\n",
    "        processed_sequences.append(processed_seq)\n",
    "\n",
    "    X = jnp.array(processed_sequences)\n",
    "    y = jnp.array(pd.DataFrame(all_labels).values)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "    return train_dataset, val_dataset, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from data_loader import load_and_prepare_data, SEQUENCE_LENGTH\n",
    "\n",
    "def build_model(input_features, output_shape, lstm_units=64):\n",
    "    \"\"\"\n",
    "    Builds a sequential model with two LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        input_features (int): The number of input features per timestep.\n",
    "        output_shape (int): The number of output units.\n",
    "        lstm_units (int): The number of units in the LSTM layers.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(SEQUENCE_LENGTH, input_features)),  # Input shape for a sequence of timesteps\n",
    "        layers.LSTM(lstm_units),\n",
    "        layers.Dense(output_shape)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Trains the Keras model.\n",
    "    \"\"\"\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    if val_dataset:\n",
    "        val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_dataset)\n",
    "    print(\"Model training finished.\")\n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, build, and train the model.\n",
    "    \"\"\"\n",
    "    prediction_data_dir = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/train'\n",
    "    \n",
    "    batch_size = 32\n",
    "    epochs = 10\n",
    "\n",
    "    train_ds, val_ds, preprocessor = load_and_prepare_data(prediction_data_dir)\n",
    "\n",
    "    if train_ds.cardinality().numpy() == 0:\n",
    "        print(\"No training data generated. Please check data loading and feature engineering.\")\n",
    "        return\n",
    "\n",
    "    # Get the input and output shapes from the dataset specs\n",
    "    feature_spec, label_spec = train_ds.element_spec\n",
    "    input_features = feature_spec.shape[1] # Now shape is (SEQUENCE_LENGTH, input_features)\n",
    "    output_shape = label_spec.shape[0]\n",
    "\n",
    "    model = build_model(input_features, output_shape)\n",
    "    model.summary()\n",
    "\n",
    "    train_model(model, train_ds, val_ds, epochs, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
