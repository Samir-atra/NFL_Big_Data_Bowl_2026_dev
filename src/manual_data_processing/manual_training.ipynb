{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerator strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:44:18.108799Z",
     "iopub.status.busy": "2025-11-29T09:44:18.108386Z",
     "iopub.status.idle": "2025-11-29T09:44:36.343798Z",
     "shell.execute_reply": "2025-11-29T09:44:36.342983Z",
     "shell.execute_reply.started": "2025-11-29T09:44:18.108774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 09:44:19.641579: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764409459.819841      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764409459.866906      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU or CPU\n",
      "Number of accelerators:  1\n",
      "Running in Kaggle environment\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Detect hardware\n",
    "try:\n",
    "    # Check for TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    # Check for GPU(s)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if len(gpus) > 1:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        print(f'Running on {len(gpus)} GPUs')\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print('Running on single GPU or CPU')\n",
    "\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Configure for Kaggle\n",
    "if os.path.exists('/kaggle'):\n",
    "    print(\"Running in Kaggle environment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:44:41.309413Z",
     "iopub.status.busy": "2025-11-29T09:44:41.308182Z",
     "iopub.status.idle": "2025-11-29T09:45:53.391931Z",
     "shell.execute_reply": "2025-11-29T09:45:53.391230Z",
     "shell.execute_reply.started": "2025-11-29T09:44:41.309359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.25.0)\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.5)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.10.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras->keras-tuner) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras->keras-tuner) (2024.2.0)\n",
      "=== Testing Unsupervised Data Loader ===\n",
      "\n",
      "Test 1: Loading UNLABELED data only\n",
      "Loading unsupervised data from 1 directories...\n",
      "Include labeled: False, Include unlabeled: True\n",
      "  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-prediction/train\n",
      "    input_2023_w01.csv: 285714 -> 209315 rows\n",
      "    input_2023_w02.csv: 288586 -> 212680 rows\n",
      "    input_2023_w03.csv: 297757 -> 217215 rows\n",
      "    input_2023_w04.csv: 272475 -> 201138 rows\n",
      "    input_2023_w05.csv: 254779 -> 185674 rows\n",
      "    input_2023_w06.csv: 270676 -> 198064 rows\n",
      "    input_2023_w07.csv: 233597 -> 169527 rows\n",
      "    input_2023_w08.csv: 281011 -> 205643 rows\n",
      "    input_2023_w09.csv: 252796 -> 187479 rows\n",
      "    input_2023_w10.csv: 260372 -> 191043 rows\n",
      "    input_2023_w11.csv: 243413 -> 178645 rows\n",
      "    input_2023_w12.csv: 294940 -> 218379 rows\n",
      "    input_2023_w13.csv: 233755 -> 168963 rows\n",
      "    input_2023_w14.csv: 279972 -> 204595 rows\n",
      "    input_2023_w15.csv: 281820 -> 205578 rows\n",
      "    input_2023_w16.csv: 316417 -> 231710 rows\n",
      "    input_2023_w17.csv: 277582 -> 203035 rows\n",
      "    input_2023_w18.csv: 254917 -> 188456 rows\n",
      "Concatenating dataframes...\n",
      "Processing features...\n",
      "Total sequences: 127105\n",
      "Converting to NumPy arrays...\n",
      "Loaded 127105 sequences\n",
      "Unlabeled sequences: 127105\n",
      "\n",
      "Test 2: Loading ALL data (labeled + unlabeled)\n",
      "Loading unsupervised data from 1 directories...\n",
      "Include labeled: True, Include unlabeled: True\n",
      "  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-prediction/train\n",
      "    input_2023_w01.csv: 285714 -> 285714 rows\n",
      "    input_2023_w02.csv: 288586 -> 288586 rows\n",
      "    input_2023_w03.csv: 297757 -> 297757 rows\n",
      "    input_2023_w04.csv: 272475 -> 272475 rows\n",
      "    input_2023_w05.csv: 254779 -> 254779 rows\n",
      "    input_2023_w06.csv: 270676 -> 270676 rows\n",
      "    input_2023_w07.csv: 233597 -> 233597 rows\n",
      "    input_2023_w08.csv: 281011 -> 281011 rows\n",
      "    input_2023_w09.csv: 252796 -> 252796 rows\n",
      "    input_2023_w10.csv: 260372 -> 260372 rows\n",
      "    input_2023_w11.csv: 243413 -> 243413 rows\n",
      "    input_2023_w12.csv: 294940 -> 294940 rows\n",
      "    input_2023_w13.csv: 233755 -> 233755 rows\n",
      "    input_2023_w14.csv: 279972 -> 279972 rows\n",
      "    input_2023_w15.csv: 281820 -> 281820 rows\n",
      "    input_2023_w16.csv: 316417 -> 316417 rows\n",
      "    input_2023_w17.csv: 277582 -> 277582 rows\n",
      "    input_2023_w18.csv: 254917 -> 254917 rows\n",
      "Concatenating dataframes...\n",
      "Processing features...\n",
      "Total sequences: 173150\n",
      "Converting to NumPy arrays...\n",
      "Loaded 173150 sequences\n",
      "Total sequences: 173150\n",
      "\n",
      "Sample sequence length: 26\n",
      "Sample features per timestep: 18\n",
      "\n",
      "=== Testing Sequence Generators ===\n",
      "\n",
      "Autoencoder sequence:\n",
      "UnsupervisedNFLSequence initialized:\n",
      "  Samples: 1000\n",
      "  Batch size: 32\n",
      "  Max length: 10 (FIXED)\n",
      "  Task: autoencoder\n",
      "Input shape: (32, 10, 18)\n",
      "Output shape: (32, 10, 18)\n",
      "Are input and output same? True\n",
      "\n",
      "Next-step prediction sequence:\n",
      "UnsupervisedNFLSequence initialized:\n",
      "  Samples: 1000\n",
      "  Batch size: 32\n",
      "  Max length: 10 (FIXED)\n",
      "  Task: next_step\n",
      "Input shape: (32, 10, 18)\n",
      "Output shape: (32, 10, 18)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars\n",
    "!pip install keras-tuner\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class UnsupervisedNFLDataLoader:\n",
    "    \"\"\"Loads NFL data for unsupervised learning (no trajectory labels needed).\n",
    "    \n",
    "    This loader processes ALL player sequences (player_to_predict=True and False)\n",
    "    to maximize the amount of training data for representation learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_sequences = None\n",
    "        \n",
    "    def load_files(self, directories, include_labeled=True, include_unlabeled=True):\n",
    "        \"\"\"Load input files from specified directories.\n",
    "        \n",
    "        Args:\n",
    "            directories (list): List of directory paths to load from\n",
    "            include_labeled (bool): Include player_to_predict=True sequences\n",
    "            include_unlabeled (bool): Include player_to_predict=False sequences\n",
    "        \"\"\"\n",
    "        input_dfs = []\n",
    "        \n",
    "        print(f\"Loading unsupervised data from {len(directories)} directories...\")\n",
    "        print(f\"Include labeled: {include_labeled}, Include unlabeled: {include_unlabeled}\")\n",
    "        \n",
    "        for d in directories:\n",
    "            if not os.path.exists(d):\n",
    "                print(f\"Warning: Directory not found: {d}\")\n",
    "                continue\n",
    "                \n",
    "            input_files = sorted([f for f in os.listdir(d) if f.startswith('input') and f.endswith('.csv')])\n",
    "            print(f\"  Found {len(input_files)} input files in {d}\")\n",
    "            \n",
    "            for f in input_files:\n",
    "                try:\n",
    "                    df = pl.read_csv(os.path.join(d, f), infer_schema_length=10000)\n",
    "                    \n",
    "                    initial_rows = len(df)\n",
    "                    \n",
    "                    # Filter based on player_to_predict flag\n",
    "                    if \"player_to_predict\" in df.columns:\n",
    "                        if include_labeled and not include_unlabeled:\n",
    "                            # Only labeled\n",
    "                            if df[\"player_to_predict\"].dtype == pl.Boolean:\n",
    "                                df = df.filter(pl.col(\"player_to_predict\") == True)\n",
    "                            else:\n",
    "                                df = df.filter(pl.col(\"player_to_predict\").cast(pl.Utf8).str.to_lowercase() == \"true\")\n",
    "                        elif include_unlabeled and not include_labeled:\n",
    "                            # Only unlabeled\n",
    "                            if df[\"player_to_predict\"].dtype == pl.Boolean:\n",
    "                                df = df.filter(pl.col(\"player_to_predict\") == False)\n",
    "                            else:\n",
    "                                df = df.filter(pl.col(\"player_to_predict\").cast(pl.Utf8).str.to_lowercase() == \"false\")\n",
    "                        # If both True, include all (no filtering)\n",
    "                    \n",
    "                    if len(df) > 0:\n",
    "                        input_dfs.append(df)\n",
    "                        print(f\"    {f}: {initial_rows} -> {len(df)} rows\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {f}: {e}\")\n",
    "        \n",
    "        if not input_dfs:\n",
    "            print(\"No data found.\")\n",
    "            self.input_sequences = pl.DataFrame()\n",
    "            return\n",
    "        \n",
    "        # Concatenate all dataframes\n",
    "        print(\"Concatenating dataframes...\")\n",
    "        full_input = pl.concat(input_dfs, how=\"vertical_relaxed\")\n",
    "        \n",
    "        # Deduplicate\n",
    "        full_input = full_input.unique(subset=[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n",
    "        \n",
    "        # Process features\n",
    "        print(\"Processing features...\")\n",
    "        id_cols = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"player_to_predict\", \"time\"]\n",
    "        feature_cols = [c for c in full_input.columns if c not in id_cols]\n",
    "        \n",
    "        expressions = []\n",
    "        for col in feature_cols:\n",
    "            if full_input[col].dtype == pl.Utf8:\n",
    "                expr = (\n",
    "                    pl.when(pl.col(col).str.to_lowercase() == \"true\").then(1.0)\n",
    "                    .when(pl.col(col).str.to_lowercase() == \"false\").then(0.0)\n",
    "                    .when(pl.col(col).str.to_lowercase() == \"left\").then(0.0)\n",
    "                    .when(pl.col(col).str.to_lowercase() == \"right\").then(1.0)\n",
    "                    .when(pl.col(col).str.to_lowercase() == \"defense\").then(0.0)\n",
    "                    .when(pl.col(col).str.to_lowercase() == \"offense\").then(1.0)\n",
    "                    .otherwise(\n",
    "                        pl.col(col).cast(pl.Float64, strict=False).fill_null(\n",
    "                            pl.col(col).hash() % 10000\n",
    "                        )\n",
    "                    ).cast(pl.Float64).alias(col)\n",
    "                )\n",
    "                expressions.append(expr)\n",
    "            else:\n",
    "                expressions.append(pl.col(col).cast(pl.Float64).alias(col))\n",
    "        \n",
    "        full_input = full_input.with_columns(expressions)\n",
    "        \n",
    "        # Sort by frame_id\n",
    "        if \"frame_id\" in full_input.columns:\n",
    "            full_input = full_input.sort([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n",
    "        \n",
    "        # Group into sequences\n",
    "        agg_exprs = [pl.col(c) for c in feature_cols]\n",
    "        self.input_sequences = full_input.group_by(\n",
    "            [\"game_id\", \"play_id\", \"nfl_id\"], \n",
    "            maintain_order=True\n",
    "        ).agg(agg_exprs)\n",
    "        \n",
    "        print(f\"Total sequences: {len(self.input_sequences)}\")\n",
    "        \n",
    "    def get_sequences(self):\n",
    "        \"\"\"Convert sequences to numpy arrays.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Array of input sequences (object array)\n",
    "        \"\"\"\n",
    "        if self.input_sequences is None or self.input_sequences.is_empty():\n",
    "            return np.array([])\n",
    "        \n",
    "        print(\"Converting to NumPy arrays...\")\n",
    "        \n",
    "        # Get feature columns (exclude keys)\n",
    "        input_cols = [c for c in self.input_sequences.columns \n",
    "                     if c not in [\"game_id\", \"play_id\", \"nfl_id\"]]\n",
    "        \n",
    "        # Convert to sequences\n",
    "        input_col_indices = [self.input_sequences.columns.index(c) for c in input_cols]\n",
    "        rows = self.input_sequences.iter_rows()\n",
    "        \n",
    "        X_list = []\n",
    "        for row in rows:\n",
    "            feature_seqs = [row[i] for i in input_col_indices]\n",
    "            X_seq = list(zip(*feature_seqs))\n",
    "            X_list.append(X_seq)\n",
    "        \n",
    "        X = np.array(X_list, dtype=object)\n",
    "        print(f\"Loaded {len(X)} sequences\")\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "class UnsupervisedNFLSequence(Sequence):\n",
    "    \"\"\"Keras Sequence for unsupervised learning on NFL data.\n",
    "    \n",
    "    For autoencoder: input and output are the same (reconstruction)\n",
    "    For next-step prediction: input is sequence[:-n], output is sequence[n:]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, batch_size=32, maxlen=10, shuffle=True, \n",
    "                 task='autoencoder', prediction_steps=1):\n",
    "        \"\"\"Initialize the sequence.\n",
    "        \n",
    "        Args:\n",
    "            X: Input sequences\n",
    "            batch_size: Batch size\n",
    "            maxlen: Maximum sequence length (fixed to 10 by default)\n",
    "            shuffle: Whether to shuffle\n",
    "            task: 'autoencoder' or 'next_step'\n",
    "            prediction_steps: For next_step, how many steps ahead to predict\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.task = task\n",
    "        self.prediction_steps = prediction_steps\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        \n",
    "        # Fixed sequence length to 10\n",
    "        self.maxlen = 10\n",
    "        \n",
    "        print(f\"UnsupervisedNFLSequence initialized:\")\n",
    "        print(f\"  Samples: {len(self.X)}\")\n",
    "        print(f\"  Batch size: {batch_size}\")\n",
    "        print(f\"  Max length: {self.maxlen} (FIXED)\")\n",
    "        print(f\"  Task: {task}\")\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_X = [self.X[i] for i in batch_indices]\n",
    "        \n",
    "        if self.task == 'autoencoder':\n",
    "            # Input and output are the same (reconstruction task)\n",
    "            X_padded = pad_sequences(\n",
    "                batch_X,\n",
    "                maxlen=self.maxlen,\n",
    "                dtype='float32',\n",
    "                padding='post',\n",
    "                truncating='post',\n",
    "                value=0.0\n",
    "            )\n",
    "            return X_padded, X_padded\n",
    "            \n",
    "        elif self.task == 'next_step':\n",
    "            # Input: sequence up to -prediction_steps\n",
    "            # Output: last prediction_steps frames\n",
    "            batch_X_input = []\n",
    "            batch_y_output = []\n",
    "            \n",
    "            for seq in batch_X:\n",
    "                if len(seq) > self.prediction_steps:\n",
    "                    batch_X_input.append(seq[:-self.prediction_steps])\n",
    "                    batch_y_output.append(seq[-self.prediction_steps:])\n",
    "                else:\n",
    "                    # If sequence too short, use full sequence for both\n",
    "                    batch_X_input.append(seq)\n",
    "                    batch_y_output.append(seq)\n",
    "            \n",
    "            X_padded = pad_sequences(\n",
    "                batch_X_input,\n",
    "                maxlen=10,\n",
    "                dtype='float32',\n",
    "                padding='post',\n",
    "                truncating='post',\n",
    "                value=0.0\n",
    "            )\n",
    "            \n",
    "            y_padded = pad_sequences(\n",
    "                batch_y_output,\n",
    "                maxlen=10,\n",
    "                dtype='float32',\n",
    "                padding='post',\n",
    "                truncating='post',\n",
    "                value=0.0\n",
    "            )\n",
    "            \n",
    "            return X_padded, y_padded\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the loader\n",
    "    PREDICTION_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "    \n",
    "    print(\"=== Testing Unsupervised Data Loader ===\\n\")\n",
    "    \n",
    "    # Test 1: Load only unlabeled data\n",
    "    print(\"Test 1: Loading UNLABELED data only\")\n",
    "    loader = UnsupervisedNFLDataLoader()\n",
    "    loader.load_files([PREDICTION_TRAIN_DIR], include_labeled=False, include_unlabeled=True)\n",
    "    X_unlabeled = loader.get_sequences()\n",
    "    print(f\"Unlabeled sequences: {len(X_unlabeled)}\\n\")\n",
    "    \n",
    "    # Test 2: Load ALL data\n",
    "    print(\"Test 2: Loading ALL data (labeled + unlabeled)\")\n",
    "    loader_all = UnsupervisedNFLDataLoader()\n",
    "    loader_all.load_files([PREDICTION_TRAIN_DIR], include_labeled=True, include_unlabeled=True)\n",
    "    X_all = loader_all.get_sequences()\n",
    "    print(f\"Total sequences: {len(X_all)}\\n\")\n",
    "    \n",
    "    if len(X_all) > 0:\n",
    "        print(f\"Sample sequence length: {len(X_all[0])}\")\n",
    "        print(f\"Sample features per timestep: {len(X_all[0][0])}\")\n",
    "        \n",
    "        # Test sequence generators\n",
    "        print(\"\\n=== Testing Sequence Generators ===\")\n",
    "        \n",
    "        print(\"\\nAutoencoder sequence:\")\n",
    "        ae_seq = UnsupervisedNFLSequence(X_all[:1000], batch_size=32, task='autoencoder')\n",
    "        x_batch, y_batch = ae_seq[0]\n",
    "        print(f\"Input shape: {x_batch.shape}\")\n",
    "        print(f\"Output shape: {y_batch.shape}\")\n",
    "        print(f\"Are input and output same? {np.array_equal(x_batch, y_batch)}\")\n",
    "        \n",
    "        print(\"\\nNext-step prediction sequence:\")\n",
    "        ns_seq = UnsupervisedNFLSequence(X_all[:1000], batch_size=32, task='next_step', prediction_steps=5)\n",
    "        x_batch, y_batch = ns_seq[0]\n",
    "        print(f\"Input shape: {x_batch.shape}\")\n",
    "        print(f\"Output shape: {y_batch.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised models architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:01:18.840318Z",
     "iopub.status.busy": "2025-11-29T14:01:18.840025Z",
     "iopub.status.idle": "2025-11-29T14:01:19.296128Z",
     "shell.execute_reply": "2025-11-29T14:01:19.295555Z",
     "shell.execute_reply.started": "2025-11-29T14:01:18.840297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Unsupervised Models ===\n",
      "\n",
      "1. Testing LSTM Autoencoder\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Autoencoder Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ autoencoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ autoencoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m128,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │       \u001b[38;5;34m134,162\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,994</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m262,994\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,994</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,994\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Encoder Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m75,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> (503.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,832\u001b[0m (503.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> (503.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,832\u001b[0m (503.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decoder Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reconstruction                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reconstruction                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m2,322\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> (524.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,162\u001b[0m (524.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> (524.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,162\u001b[0m (524.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Testing Next-Step Predictor\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"next_step_predictor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"next_step_predictor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ prediction_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m75,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ prediction_lstm (\u001b[38;5;33mLSTM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m)          │         \u001b[38;5;34m2,322\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,810</span> (882.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,810\u001b[0m (882.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,810</span> (882.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,810\u001b[0m (882.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Testing with dummy data\n",
      "--------------------------------------------------\n",
      "Autoencoder forward pass:\n",
      "Input shape: (32, 28, 18)\n",
      "Output shape: (32, 28, 18)\n",
      "\n",
      "Next-step predictor forward pass:\n",
      "Input shape: (32, 28, 18)\n",
      "Output shape: (32, 5, 18)\n",
      "\n",
      "Encoder output (latent representation):\n",
      "Latent shape: (32, 64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class LSTMAutoencoder:\n",
    "    \"\"\"LSTM Autoencoder for unsupervised representation learning on NFL sequences.\n",
    "    \n",
    "    The encoder learns to compress player movement sequences into a latent representation,\n",
    "    and the decoder reconstructs the original sequence. The encoder can then be used\n",
    "    to initialize supervised models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, latent_dim=128, lstm_units=[512, 256, 128, 64, 32]):\n",
    "        \"\"\"Initialize the LSTM Autoencoder.\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Shape of input (timesteps, features)\n",
    "            latent_dim: Dimension of latent representation\n",
    "            lstm_units: List of LSTM units for encoder layers\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.autoencoder = None\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        \"\"\"Build the encoder network.\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='encoder_input')\n",
    "        \n",
    "        x = inputs\n",
    "        # Stack LSTM layers\n",
    "        for i, units in enumerate(self.lstm_units[:-1]):\n",
    "            x = layers.LSTM(\n",
    "                units, \n",
    "                return_sequences=True,\n",
    "                name=f'encoder_lstm_{i+1}'\n",
    "            )(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Last LSTM layer doesn't return sequences\n",
    "        x = layers.LSTM(\n",
    "            self.lstm_units[-1],\n",
    "            return_sequences=False,\n",
    "            name=f'encoder_lstm_{len(self.lstm_units)}'\n",
    "        )(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Latent representation\n",
    "        latent = layers.Dense(self.latent_dim, activation='relu', name='latent')(x)\n",
    "        \n",
    "        self.encoder = Model(inputs, latent, name='encoder')\n",
    "        return self.encoder\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        \"\"\"Build the decoder network.\"\"\"\n",
    "        # Decoder input is the latent vector\n",
    "        latent_inputs = layers.Input(shape=(self.latent_dim,), name='decoder_input')\n",
    "        \n",
    "        # Repeat the latent vector for each timestep\n",
    "        x = layers.RepeatVector(self.input_shape[0])(latent_inputs)\n",
    "        \n",
    "        # Stack LSTM layers in reverse\n",
    "        for i, units in enumerate(reversed(self.lstm_units)):\n",
    "            x = layers.LSTM(\n",
    "                units,\n",
    "                return_sequences=True,\n",
    "                name=f'decoder_lstm_{i+1}'\n",
    "            )(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Output layer to reconstruct features\n",
    "        outputs = layers.TimeDistributed(\n",
    "            layers.Dense(self.input_shape[1], activation='linear'),\n",
    "            name='reconstruction'\n",
    "        )(x)\n",
    "        \n",
    "        self.decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "        return self.decoder\n",
    "    \n",
    "    def build_autoencoder(self):\n",
    "        \"\"\"Build the complete autoencoder.\"\"\"\n",
    "        if self.encoder is None:\n",
    "            self.build_encoder()\n",
    "        if self.decoder is None:\n",
    "            self.build_decoder()\n",
    "        \n",
    "        # Connect encoder and decoder\n",
    "        inputs = layers.Input(shape=self.input_shape, name='autoencoder_input')\n",
    "        latent = self.encoder(inputs)\n",
    "        outputs = self.decoder(latent)\n",
    "        \n",
    "        self.autoencoder = Model(inputs, outputs, name='autoencoder')\n",
    "        return self.autoencoder\n",
    "    \n",
    "    def compile(self, learning_rate=0.001):\n",
    "        \"\"\"Compile the autoencoder.\"\"\"\n",
    "        if self.autoencoder is None:\n",
    "            self.build_autoencoder()\n",
    "        \n",
    "        self.autoencoder.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "    def get_summary(self):\n",
    "        \"\"\"Print model summaries.\"\"\"\n",
    "        if self.autoencoder:\n",
    "            print(\"\\n=== Autoencoder Summary ===\")\n",
    "            self.autoencoder.summary()\n",
    "        if self.encoder:\n",
    "            print(\"\\n=== Encoder Summary ===\")\n",
    "            self.encoder.summary()\n",
    "        if self.decoder:\n",
    "            print(\"\\n=== Decoder Summary ===\")\n",
    "            self.decoder.summary()\n",
    "\n",
    "\n",
    "class NextStepPredictor:\n",
    "    \"\"\"LSTM model for self-supervised next-step prediction.\n",
    "    \n",
    "    Predicts future timesteps given past timesteps, which can be used\n",
    "    as a pre-training task for the supervised trajectory prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, output_steps=5, lstm_units=[256, 128], output_features=None):\n",
    "        \"\"\"Initialize the next-step predictor.\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Shape of input (timesteps, features)\n",
    "            output_steps: Number of future steps to predict\n",
    "            lstm_units: List of LSTM units\n",
    "            output_features: Number of output features (if None, same as input features)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.output_steps = output_steps\n",
    "        self.lstm_units = lstm_units\n",
    "        self.output_features = output_features or input_shape[1]\n",
    "        self.model = None\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"Build the next-step prediction model.\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        \n",
    "        x = inputs\n",
    "        # Stack LSTM layers\n",
    "        for i, units in enumerate(self.lstm_units):\n",
    "            return_seq = (i < len(self.lstm_units) - 1)\n",
    "            x = layers.LSTM(\n",
    "                units,\n",
    "                return_sequences=return_seq,\n",
    "                name=f'lstm_{i+1}'\n",
    "            )(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Prediction head\n",
    "        # Expand to output_steps timesteps\n",
    "        x = layers.RepeatVector(self.output_steps)(x)\n",
    "        x = layers.LSTM(128, return_sequences=True, name='prediction_lstm')(x)\n",
    "        \n",
    "        # Output for each timestep\n",
    "        outputs = layers.TimeDistributed(\n",
    "            layers.Dense(self.output_features, activation='linear'),\n",
    "            name='predictions'\n",
    "        )(x)\n",
    "        \n",
    "        self.model = Model(inputs, outputs, name='next_step_predictor')\n",
    "        return self.model\n",
    "    \n",
    "    def compile(self, learning_rate=0.001):\n",
    "        \"\"\"Compile the model.\"\"\"\n",
    "        if self.model is None:\n",
    "            self.build()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Print model summary.\"\"\"\n",
    "        if self.model:\n",
    "            self.model.summary()\n",
    "\n",
    "\n",
    "def create_training_callbacks(model_path, patience=10):\n",
    "    \"\"\"Create standard callbacks for training.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to save best model\n",
    "        patience: Patience for early stopping\n",
    "        \n",
    "    Returns:\n",
    "        List of callbacks\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            model_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def transfer_encoder_weights(pretrained_encoder, supervised_model, freeze_encoder=False):\n",
    "    \"\"\"Transfer weights from pretrained encoder to supervised model.\n",
    "    \n",
    "    Args:\n",
    "        pretrained_encoder: The pretrained encoder model\n",
    "        supervised_model: The supervised model to transfer weights to\n",
    "        freeze_encoder: Whether to freeze the transferred weights\n",
    "        \n",
    "    Returns:\n",
    "        The supervised model with transferred weights\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Transferring Encoder Weights ===\")\n",
    "    \n",
    "    # Get encoder layers from pretrained model\n",
    "    encoder_layer_names = [layer.name for layer in pretrained_encoder.layers]\n",
    "    \n",
    "    # Transfer weights to matching layers in supervised model\n",
    "    transferred_count = 0\n",
    "    for layer in supervised_model.layers:\n",
    "        if layer.name in encoder_layer_names:\n",
    "            try:\n",
    "                pretrained_layer = pretrained_encoder.get_layer(layer.name)\n",
    "                layer.set_weights(pretrained_layer.get_weights())\n",
    "                \n",
    "                if freeze_encoder:\n",
    "                    layer.trainable = False\n",
    "                \n",
    "                transferred_count += 1\n",
    "                print(f\"Transferred weights for layer: {layer.name} (frozen={freeze_encoder})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not transfer weights for {layer.name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nTransferred weights for {transferred_count} layers\")\n",
    "    return supervised_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Testing Unsupervised Models ===\\n\")\n",
    "    \n",
    "    # Test parameters\n",
    "    timesteps = 28\n",
    "    features = 18\n",
    "    latent_dim = 64\n",
    "    \n",
    "    print(\"1. Testing LSTM Autoencoder\")\n",
    "    print(\"-\" * 50)\n",
    "    ae = LSTMAutoencoder(\n",
    "        input_shape=(timesteps, features),\n",
    "        latent_dim=latent_dim,\n",
    "        lstm_units=[128, 64]\n",
    "    )\n",
    "    ae.build_autoencoder()\n",
    "    ae.compile()\n",
    "    ae.get_summary()\n",
    "    \n",
    "    print(\"\\n2. Testing Next-Step Predictor\")\n",
    "    print(\"-\" * 50)\n",
    "    predictor = NextStepPredictor(\n",
    "        input_shape=(timesteps, features),\n",
    "        output_steps=5,\n",
    "        lstm_units=[128, 64],\n",
    "        output_features=features\n",
    "    )\n",
    "    predictor.build()\n",
    "    predictor.compile()\n",
    "    predictor.get_summary()\n",
    "    \n",
    "    # Test with dummy data\n",
    "    print(\"\\n3. Testing with dummy data\")\n",
    "    print(\"-\" * 50)\n",
    "    dummy_input = tf.random.normal((32, timesteps, features))\n",
    "    \n",
    "    print(\"Autoencoder forward pass:\")\n",
    "    ae_output = ae.autoencoder(dummy_input)\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    print(f\"Output shape: {ae_output.shape}\")\n",
    "    \n",
    "    print(\"\\nNext-step predictor forward pass:\")\n",
    "    ns_output = predictor.model(dummy_input)\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    print(f\"Output shape: {ns_output.shape}\")\n",
    "    \n",
    "    print(\"\\nEncoder output (latent representation):\")\n",
    "    latent = ae.encoder(dummy_input)\n",
    "    print(f\"Latent shape: {latent.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:20:34.886707Z",
     "iopub.status.busy": "2025-11-26T08:20:34.886541Z",
     "iopub.status.idle": "2025-11-26T09:36:36.133955Z",
     "shell.execute_reply": "2025-11-26T09:36:36.132993Z",
     "shell.execute_reply.started": "2025-11-26T08:20:34.886692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unsupervised Pre-training Script for NFL Player Trajectory Prediction\n",
    "\n",
    "This script performs unsupervised pre-training using LSTM autoencoders on all available\n",
    "NFL player sequences (both labeled and unlabeled). The pretrained encoder can then be\n",
    "used to initialize supervised models for better performance.\n",
    "\n",
    "Usage:\n",
    "    python unsupervised_pretraining.py --task autoencoder --epochs 50\n",
    "    python unsupervised_pretraining.py --task next_step --epochs 50\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path\n",
    "# sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "# from unsupervised_data_loader import UnsupervisedNFLDataLoader, UnsupervisedNFLSequence\n",
    "# from unsupervised_models import (\n",
    "#     LSTMAutoencoder, \n",
    "#     NextStepPredictor, \n",
    "#     create_training_callbacks\n",
    "# )\n",
    "\n",
    "\n",
    "def train_autoencoder(train_seq, val_seq, epochs=50, latent_dim=128, model_save_path='autoencoder.keras'):\n",
    "    \"\"\"Train LSTM autoencoder for representation learning.\n",
    "    \n",
    "    Args:\n",
    "        train_seq: Training data sequence\n",
    "        val_seq: Validation data sequence\n",
    "        epochs: Number of training epochs\n",
    "        latent_dim: Dimension of latent space\n",
    "        model_save_path: Path to save the trained model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING LSTM AUTOENCODER\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get input shape from first batch\n",
    "    x_sample, _ = train_seq[0]\n",
    "    input_shape = (x_sample.shape[1], x_sample.shape[2])\n",
    "    \n",
    "    print(f\"\\nInput shape: {input_shape}\")\n",
    "    print(f\"Latent dimension: {latent_dim}\")\n",
    "    \n",
    "    # Build autoencoder\n",
    "    ae = LSTMAutoencoder(\n",
    "        input_shape=input_shape,\n",
    "        latent_dim=latent_dim,\n",
    "        lstm_units=[512, 256, 128, 64, 32]\n",
    "    )\n",
    "    ae.build_autoencoder()\n",
    "    ae.compile(learning_rate=0.0001)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    ae.get_summary()\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = create_training_callbacks(model_save_path, patience=10)\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Starting training...\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    history = ae.autoencoder.fit(\n",
    "        train_seq,\n",
    "        validation_data=val_seq,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save encoder separately\n",
    "    encoder_path = model_save_path.replace('.keras', '_encoder.keras')\n",
    "    ae.encoder.save(encoder_path)\n",
    "    print(f\"Encoder saved to: {encoder_path}\")\n",
    "    \n",
    "    return ae, history\n",
    "\n",
    "\n",
    "def train_next_step_predictor(train_seq, val_seq, epochs=50, prediction_steps=5, \n",
    "                               model_save_path='next_step_predictor.keras'):\n",
    "    \"\"\"Train next-step predictor for self-supervised learning.\n",
    "    \n",
    "    Args:\n",
    "        train_seq: Training data sequence\n",
    "        val_seq: Validation data sequence\n",
    "        epochs: Number of training epochs\n",
    "        prediction_steps: Number of steps to predict ahead\n",
    "        model_save_path: Path to save the trained model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING NEXT-STEP PREDICTOR\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get input shape from first batch\n",
    "    x_sample, y_sample = train_seq[0]\n",
    "    input_shape = (x_sample.shape[1], x_sample.shape[2])\n",
    "    output_features = y_sample.shape[2]\n",
    "    \n",
    "    print(f\"\\nInput shape: {input_shape}\")\n",
    "    print(f\"Output steps: {prediction_steps}\")\n",
    "    print(f\"Output features: {output_features}\")\n",
    "    \n",
    "    # Build model\n",
    "    predictor = NextStepPredictor(\n",
    "        input_shape=input_shape,\n",
    "        output_steps=prediction_steps,\n",
    "        lstm_units=[256, 128],\n",
    "        output_features=output_features\n",
    "    )\n",
    "    predictor.build()\n",
    "    predictor.compile(learning_rate=0.001)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    predictor.get_summary()\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = create_training_callbacks(model_save_path, patience=10)\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Starting training...\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    history = predictor.model.fit(\n",
    "        train_seq,\n",
    "        validation_data=val_seq,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return predictor, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    PREDICTION_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "    ANALYTICS_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train'\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"UNSUPERVISED PRE-TRAINING FOR NFL PLAYER TRAJECTORY PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    # print(f\"\\nTask: {args.task}\")\n",
    "    # print(f\"Epochs: {args.epochs}\")\n",
    "    # print(f\"Batch size: {args.batch_size}\")\n",
    "    # print(f\"Include labeled: {args.include_labeled}\")\n",
    "    # print(f\"Include unlabeled: {args.include_unlabeled}\")\n",
    "    # print(f\"Validation split: {args.val_split}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    loader = UnsupervisedNFLDataLoader()\n",
    "    loader.load_files(\n",
    "        [PREDICTION_TRAIN_DIR, ANALYTICS_TRAIN_DIR],\n",
    "        include_labeled=True,\n",
    "        include_unlabeled=True\n",
    "    )\n",
    "    X = loader.get_sequences()\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"ERROR: No data loaded!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal sequences loaded: {len(X)}\")\n",
    "    print(f\"Sample sequence length: {len(X[0])}\")\n",
    "    print(f\"Sample features: {len(X[0][0])}\")\n",
    "    \n",
    "    # Split into train/val\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_val = train_test_split(\n",
    "        X, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining sequences: {len(X_train)}\")\n",
    "    print(f\"Validation sequences: {len(X_val)}\")\n",
    "    \n",
    "    # Create data sequences based on task\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING DATA GENERATORS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    train_seq = UnsupervisedNFLSequence(\n",
    "        X_train,\n",
    "        batch_size=32,\n",
    "        maxlen=10,\n",
    "        shuffle=True,\n",
    "        task=\"autoencoder\",\n",
    "        prediction_steps=10\n",
    "    )\n",
    "    \n",
    "    val_seq = UnsupervisedNFLSequence(\n",
    "        X_val,\n",
    "        batch_size=32,\n",
    "        maxlen=10,\n",
    "        shuffle=False,\n",
    "        task=\"autoencoder\",\n",
    "        prediction_steps=10\n",
    "    )\n",
    "    \n",
    "    # Generate timestamp for model name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Train based on task\n",
    "    model_path = os.path.join(\"/kaggle/working/\", f'autoencoder_{timestamp}.keras')\n",
    "    model, history = train_autoencoder(\n",
    "        train_seq, \n",
    "        val_seq, \n",
    "        epochs=100,\n",
    "        latent_dim=256,\n",
    "        model_save_path=model_path\n",
    "    )\n",
    "    \n",
    "    # model_path = os.path.join(args.output_dir, f'next_step_{timestamp}.keras')\n",
    "    # model, history = train_next_step_predictor(\n",
    "    #     train_seq,\n",
    "    #     val_seq,\n",
    "    #     epochs=args.epochs,\n",
    "    #     prediction_steps=args.prediction_steps,\n",
    "    #     model_save_path=model_path\n",
    "    # )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "    print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "    \n",
    "    encoder_path = model_path.replace('.keras', '_encoder.keras')\n",
    "    print(f\"Encoder saved to: {encoder_path}\")\n",
    "    print(\"\\nTo use the pretrained encoder in your supervised model:\")\n",
    "    print(f\"  from tensorflow import keras\")\n",
    "    print(f\"  from unsupervised_models import transfer_encoder_weights\")\n",
    "    print(f\"  pretrained_encoder = keras.models.load_model('{encoder_path}')\")\n",
    "    print(f\"  supervised_model = transfer_encoder_weights(pretrained_encoder, supervised_model)\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"DONE!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:09:13.226439Z",
     "iopub.status.busy": "2025-11-29T14:09:13.225812Z",
     "iopub.status.idle": "2025-11-29T14:09:27.258944Z",
     "shell.execute_reply": "2025-11-29T14:09:27.257972Z",
     "shell.execute_reply.started": "2025-11-29T14:09:13.226415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NFL Big Data Bowl 2026 - Predictor Training\n",
      "============================================================\n",
      "\n",
      "[1/4] Loading data from CSV files...\n",
      "Loading and filtering 18 Input files...\n",
      "Loading 18 Output files...\n",
      "Aligning Input and Output sequences...\n",
      "Processing complete.\n",
      "Total Unique Sequences (Matches): 46045\n",
      "Converting to NumPy arrays...\n",
      "Initial X shape: (46045,)\n",
      "Initial y shape: (46045,)\n",
      "\n",
      "Data Summary:\n",
      "  Total sequences: 46045\n",
      "  Sample input sequence length: 26\n",
      "  Sample output sequence length: 21\n",
      "  Input features per timestep: 14\n",
      "  Output features per timestep: 2\n",
      "\n",
      "[2/4] Creating training and validation sequences (test_size=0.2)...\n",
      "\n",
      "--- Creating Keras Sequence Datasets with Padding ---\n",
      "Splitting data (test_size=0.2)...\n",
      "Train size: 36836\n",
      "Val size: 9209\n",
      "Creating Training Sequence...\n",
      "NFLDataSequence initialized: 36836 samples, batch_size=64\n",
      "Max sequence lengths - X: 10, y: 10\n",
      "Creating Validation Sequence...\n",
      "NFLDataSequence initialized: 9209 samples, batch_size=64\n",
      "Max sequence lengths - X: 10, y: 10\n",
      "Sequences created successfully.\n",
      "Training batches per epoch: 576\n",
      "Validation batches per epoch: 144\n",
      "\n",
      "Sequence Shapes:\n",
      "  Input: (batch_size, 10, 14)\n",
      "  Output: (batch_size, 10, 2)\n",
      "\n",
      "[3/4] Building sequence-to-sequence model...\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,079,296</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m14\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,079,296\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,680,640</span> (52.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,680,640\u001b[0m (52.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,680,640</span> (52.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,680,640\u001b[0m (52.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/4] Training model for 20 epochs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,087,488\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,688,832</span> (52.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,688,832\u001b[0m (52.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,688,832</span> (52.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,688,832\u001b[0m (52.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transferring Encoder Weights ===\n",
      "Transferred weights for layer: encoder_inputs (frozen=False)\n",
      "Could not transfer weights for enc_lstm_1: Layer enc_lstm_1 weight shape (14, 2048) is not compatible with provided weight shape (18, 2048).\n",
      "Transferred weights for layer: enc_dropout_1 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_1 (frozen=False)\n",
      "Transferred weights for layer: enc_lstm_2 (frozen=False)\n",
      "Transferred weights for layer: enc_dropout_2 (frozen=False)\n",
      "Transferred weights for layer: enc_res_2 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_2 (frozen=False)\n",
      "Transferred weights for layer: enc_lstm_3 (frozen=False)\n",
      "Transferred weights for layer: enc_dropout_3 (frozen=False)\n",
      "Transferred weights for layer: enc_res_3 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_3 (frozen=False)\n",
      "Transferred weights for layer: enc_lstm_4 (frozen=False)\n",
      "Transferred weights for layer: enc_dropout_4 (frozen=False)\n",
      "Transferred weights for layer: enc_res_4 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_4 (frozen=False)\n",
      "Transferred weights for layer: enc_lstm_5 (frozen=False)\n",
      "Transferred weights for layer: enc_dropout_5 (frozen=False)\n",
      "Transferred weights for layer: enc_res_5 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_5 (frozen=False)\n",
      "Transferred weights for layer: enc_lstm_6 (frozen=False)\n",
      "Transferred weights for layer: enc_dropout_6 (frozen=False)\n",
      "Transferred weights for layer: enc_res_6 (frozen=False)\n",
      "Transferred weights for layer: enc_norm_6 (frozen=False)\n",
      "Transferred weights for layer: latent (frozen=False)\n",
      "\n",
      "Transferred weights for 24 layers\n",
      "pretrained encoder\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,087,488\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,688,832</span> (52.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,688,832\u001b[0m (52.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,688,832</span> (52.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,688,832\u001b[0m (52.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,079,296</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc_norm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ enc_dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ enc_res_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ enc_norm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m14\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,079,296\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_2 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_3 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_4 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_5 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_dropout_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_res_6 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ enc_norm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ enc_dropout_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_norm_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ enc_res_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ enc_norm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,680,640</span> (52.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,680,640\u001b[0m (52.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,680,640</span> (52.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,680,640\u001b[0m (52.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 2 and 512 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, encoder_1/latent_1/Squeeze)' with input shapes: [?,10,2], [?,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/2866210211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_47/2866210211.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[4/4] Training model for {epochs} epochs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Save the final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47/2866210211.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_sequence, val_sequence, epochs, callbacks)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting model training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     history = supervised_model.fit(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mtrain_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 2 and 512 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, encoder_1/latent_1/Squeeze)' with input shapes: [?,10,2], [?,512]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics, models\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the manual_data_processing directory to the path\n",
    "# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'manual_data_processing'))\n",
    "\n",
    "# from csv_to_numpy import NFLDataLoader, create_tf_datasets\n",
    "\n",
    "def build_seq2seq_model(input_seq_length, input_features, output_seq_length, output_features, lstm_units=512):\n",
    "    \"\"\"\n",
    "    Builds a sequence-to-sequence model with LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        input_seq_length (int): The length of input sequences (time steps).\n",
    "        input_features (int): The number of input features per timestep.\n",
    "        output_seq_length (int): The length of output sequences (time steps).\n",
    "        output_features (int): The number of output features per timestep.\n",
    "        lstm_units (int): The number of units in the LSTM layers.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The compiled Keras model.\n",
    "    \"\"\"\n",
    "    dropout_rate = 0.2\n",
    "    SEED = 42\n",
    "\n",
    "    encoder_inputs = layers.Input(shape=(input_seq_length, input_features), name='encoder_inputs')\n",
    "    \n",
    "    enc_lstm_1 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_1')(encoder_inputs)\n",
    "    enc_dropout_1 = layers.Dropout(dropout_rate, name='enc_dropout_1')(enc_lstm_1)\n",
    "    enc_norm_1 = layers.LayerNormalization(name='enc_norm_1')(enc_dropout_1)\n",
    "    \n",
    "    enc_lstm_2 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_2')(enc_norm_1)\n",
    "    enc_dropout_2 = layers.Dropout(dropout_rate, name='enc_dropout_2')(enc_lstm_2)\n",
    "    enc_res_2 = layers.Add(name='enc_res_2')([enc_norm_1, enc_dropout_2])\n",
    "    enc_norm_2 = layers.LayerNormalization(name='enc_norm_2')(enc_res_2)\n",
    "    \n",
    "    enc_lstm_3 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_3')(enc_norm_2)\n",
    "    enc_dropout_3 = layers.Dropout(dropout_rate, name='enc_dropout_3')(enc_lstm_3)\n",
    "    enc_res_3 = layers.Add(name='enc_res_3')([enc_norm_2, enc_dropout_3])\n",
    "    enc_norm_3 = layers.LayerNormalization(name='enc_norm_3')(enc_res_3)\n",
    "    \n",
    "    enc_lstm_4 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_4')(enc_norm_3)\n",
    "    enc_dropout_4 = layers.Dropout(dropout_rate, name='enc_dropout_4')(enc_lstm_4)\n",
    "    enc_res_4 = layers.Add(name='enc_res_4')([enc_norm_3, enc_dropout_4])\n",
    "    enc_norm_4 = layers.LayerNormalization(name='enc_norm_4')(enc_res_4)\n",
    "    \n",
    "    enc_lstm_5 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_5')(enc_norm_4)\n",
    "    enc_dropout_5 = layers.Dropout(dropout_rate, name='enc_dropout_5')(enc_lstm_5)\n",
    "    enc_res_5 = layers.Add(name='enc_res_5')([enc_norm_4, enc_dropout_5])\n",
    "    enc_norm_5 = layers.LayerNormalization(name='enc_norm_5')(enc_res_5)\n",
    "    \n",
    "    enc_lstm_6 = layers.LSTM(lstm_units, return_sequences=True, name='enc_lstm_6')(enc_norm_5)\n",
    "    enc_dropout_6 = layers.Dropout(dropout_rate, name='enc_dropout_6')(enc_lstm_6)\n",
    "    enc_res_6 = layers.Add(name='enc_res_6')([enc_norm_5, enc_dropout_6])\n",
    "    enc_norm_6 = layers.LayerNormalization(name='enc_norm_6')(enc_res_6)\n",
    "    \n",
    "    latent = layers.LSTM(lstm_units, return_sequences=False, name='latent')(enc_norm_6)\n",
    "    \n",
    "    model = models.Model(inputs=encoder_inputs, outputs=latent, name='encoder')\n",
    "\n",
    "    cosine_decay = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=415000,\n",
    "    alpha=1e-5,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.00081926),\n",
    "        loss='mse',\n",
    "        metrics=[metrics.MeanSquaredError(), metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_sequence, val_sequence, epochs=10, callbacks=None):\n",
    "    \"\"\"\n",
    "    Trains the Keras model using Keras Sequence objects.\n",
    "    \n",
    "    Args:\n",
    "        model: The Keras model to train\n",
    "        train_sequence: Training data sequence (NFLDataSequence)\n",
    "        val_sequence: Validation data sequence (NFLDataSequence)\n",
    "        epochs (int): Number of training epochs\n",
    "        callbacks: List of Keras callbacks\n",
    "    \n",
    "    Returns:\n",
    "        history: Training history object\n",
    "    \"\"\"\n",
    "    pretrained_encoder = keras.models.load_model('/kaggle/working/best_hyperband_encoder.keras')\n",
    "    pretrained_encoder.summary()\n",
    "    supervised_model = transfer_encoder_weights(pretrained_encoder, model)\n",
    "    print(\"pretrained encoder\")\n",
    "    pretrained_encoder.summary()\n",
    "    print(\"supervised model\")\n",
    "    supervised_model.summary()\n",
    "    if callbacks is None:\n",
    "        callbacks = []\n",
    "    \n",
    "    # Add early stopping and model checkpoint callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks.extend([early_stopping, model_checkpoint])\n",
    "    \n",
    "    print(\"Starting model training...\")\n",
    "    history = supervised_model.fit(\n",
    "        train_sequence,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_sequence,\n",
    "        callbacks=model_checkpoint,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model training finished.\")\n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, build, and train the model.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    train_dir = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "    batch_size = 64\n",
    "    epochs = 20\n",
    "    test_size = 0.2\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NFL Big Data Bowl 2026 - Predictor Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\n[1/4] Loading data from CSV files...\")\n",
    "    loader = NFLDataLoader(train_dir)\n",
    "    X, y = loader.get_aligned_data()\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No data loaded. Please check the data directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"  Total sequences: {len(X)}\")\n",
    "    print(f\"  Sample input sequence length: {len(X[0])}\")\n",
    "    print(f\"  Sample output sequence length: {len(y[0])}\")\n",
    "    print(f\"  Input features per timestep: {len(X[0][0]) if len(X[0]) > 0 else 0}\")\n",
    "    print(f\"  Output features per timestep: {len(y[0][0]) if len(y[0]) > 0 else 0}\")\n",
    "    \n",
    "    # Create Keras Sequences with padding\n",
    "    print(f\"\\n[2/4] Creating training and validation sequences (test_size={test_size})...\")\n",
    "    train_seq, val_seq = create_tf_datasets(X, y, test_size=test_size, batch_size=batch_size)\n",
    "    \n",
    "    if train_seq is None:\n",
    "        print(\"Error: Failed to create training sequences.\")\n",
    "        return\n",
    "    \n",
    "    # Get one batch to determine shapes\n",
    "    x_sample, y_sample = train_seq[0]\n",
    "    input_seq_length = x_sample.shape[1]\n",
    "    input_features = x_sample.shape[2]\n",
    "    output_seq_length = y_sample.shape[1]\n",
    "    output_features = y_sample.shape[2]\n",
    "    \n",
    "    print(f\"\\nSequence Shapes:\")\n",
    "    print(f\"  Input: (batch_size, {input_seq_length}, {input_features})\")\n",
    "    print(f\"  Output: (batch_size, {output_seq_length}, {output_features})\")\n",
    "    \n",
    "    # Build model\n",
    "    print(f\"\\n[3/4] Building sequence-to-sequence model...\")\n",
    "    model = build_seq2seq_model(\n",
    "        input_seq_length=input_seq_length,\n",
    "        input_features=input_features,\n",
    "        output_seq_length=output_seq_length,\n",
    "        output_features=output_features,\n",
    "        lstm_units=512\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\n[4/4] Training model for {epochs} epochs...\")\n",
    "    history = train_model(model, train_seq, val_seq, epochs=epochs)\n",
    "    \n",
    "    # Save the final model\n",
    "    final_model_path = 'nfl_predictor_final.keras'\n",
    "    model.save(final_model_path)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Complete!\")\n",
    "    print(f\"Final model saved to: {final_model_path}\")\n",
    "    print(f\"Best model saved to: best_model.keras\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print training summary\n",
    "    print(f\"\\nTraining Summary:\")\n",
    "    print(f\"  Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "    print(f\"  Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final training MAE: {history.history['mae'][-1]:.4f}\")\n",
    "    print(f\"  Final validation MAE: {history.history['val_mae'][-1]:.4f}\")\n",
    "    print(f\"  Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:08:04.453489Z",
     "iopub.status.busy": "2025-11-29T14:08:04.453179Z",
     "iopub.status.idle": "2025-11-29T14:08:15.895235Z",
     "shell.execute_reply": "2025-11-29T14:08:15.894225Z",
     "shell.execute_reply.started": "2025-11-29T14:08:04.453466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and filtering 18 Input files...\n",
      "Loading 18 Output files...\n",
      "Aligning Input and Output sequences...\n",
      "Processing complete.\n",
      "Total Unique Sequences (Matches): 46045\n",
      "Initial X shape: (46045,)\n",
      "Initial y shape: (46045,)\n",
      "\n",
      "--- Final Data Shapes ---\n",
      "X (Input) Shape: (46045,)\n",
      "y (Output) Shape: (46045,)\n",
      "Sample Input Sequence Length: 38\n",
      "Sample Output Sequence Length: 12\n",
      "\n",
      "--- Creating Keras Sequence Datasets with Padding ---\n",
      "Splitting data (test_size=0.2)...\n",
      "Train size: 36836\n",
      "Val size: 9209\n",
      "Creating Training Sequence...\n",
      "NFLDataSequence initialized: 36836 samples, batch_size=32\n",
      "Max sequence lengths - X: 123, y: 94\n",
      "Creating Validation Sequence...\n",
      "NFLDataSequence initialized: 9209 samples, batch_size=32\n",
      "Max sequence lengths - X: 123, y: 94\n",
      "Sequences created successfully.\n",
      "Training batches per epoch: 1152\n",
      "Validation batches per epoch: 288\n",
      "\n",
      "Verifying Sequence Element:\n",
      "Batch X shape: (32, 123, 18)\n",
      "Batch y shape: (32, 94, 2)\n",
      "Max sequence lengths - X: 123, y: 94\n",
      "\n",
      "Data loading, alignment, and sequence creation complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class NFLDataLoader:\n",
    "    \"\"\"\n",
    "    Loads and processes NFL Big Data Bowl 2026 data from CSV files.\n",
    "    Filters input data for 'player_to_predict' == True and aligns with output data.\n",
    "    \n",
    "    Selected Input Features: ['x', 'y', 's', 'a', 'dir', 'o']\n",
    "    Selected Output Features: ['x', 'y']\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir):\n",
    "        self.train_dir = train_dir\n",
    "        self.input_sequences = {}\n",
    "        self.output_sequences = {}\n",
    "        self.input_header = []\n",
    "        self.output_header = []\n",
    "\n",
    "    def process_value(self, val):\n",
    "        \"\"\"\n",
    "        Converts a CSV string value into the appropriate type.\n",
    "        \"\"\"\n",
    "        val_lower = val.lower()\n",
    "\n",
    "        # Handle Booleans\n",
    "        if val_lower == 'true':\n",
    "            return 1.0\n",
    "        if val_lower == 'false':\n",
    "            return 0.0\n",
    "        \n",
    "        # Handle Direction (left/right)\n",
    "        if val_lower == 'left':\n",
    "            return 0.0\n",
    "        if val_lower == 'right':\n",
    "            return 1.0\n",
    "\n",
    "        # Handle Player Side (defense/offense)\n",
    "        if val_lower == 'defense':\n",
    "            return 0.0\n",
    "        if val_lower == 'offense':\n",
    "            return 1.0\n",
    "        \n",
    "        # Handle Numbers (Integers and Floats)\n",
    "        try:\n",
    "            return float(val)\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "        # Handle Strings (Object type)\n",
    "        return str(val)\n",
    "\n",
    "    def load_input_files(self):\n",
    "        \"\"\"\n",
    "        Loads and filters input CSV files.\n",
    "        Filters for 'player_to_predict' == True.\n",
    "        Selects all features matching the unsupervised loader format (18 features).\n",
    "        \"\"\"\n",
    "        input_files = sorted([f for f in os.listdir(self.train_dir) if f.startswith('input') and f.endswith('.csv')])\n",
    "        print(f\"Loading and filtering {len(input_files)} Input files...\")\n",
    "        \n",
    "        # Use the same features as unsupervised loader for consistency\n",
    "        # These match the 18 features from the unsupervised dataloader\n",
    "        id_cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'player_to_predict', 'time']\n",
    "\n",
    "        for input_file in input_files:\n",
    "            input_path = os.path.join(self.train_dir, input_file)\n",
    "            with open(input_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                first_row = True\n",
    "                \n",
    "                # Indices for ID columns\n",
    "                player_to_predict_idx = -1\n",
    "                game_id_idx = -1\n",
    "                play_id_idx = -1\n",
    "                nfl_id_idx = -1\n",
    "                \n",
    "                # Indices for feature columns (all non-ID columns)\n",
    "                feature_indices = []\n",
    "\n",
    "                for row in reader:\n",
    "                    if first_row:\n",
    "                        if not self.input_header:\n",
    "                            self.input_header = row\n",
    "                        \n",
    "                        try:\n",
    "                            player_to_predict_idx = row.index('player_to_predict')\n",
    "                            game_id_idx = row.index('game_id')\n",
    "                            play_id_idx = row.index('play_id')\n",
    "                            nfl_id_idx = row.index('nfl_id')\n",
    "                            \n",
    "                            # Get all feature columns (exclude ID columns)\n",
    "                            feature_indices = [i for i, col in enumerate(row) if col not in id_cols]\n",
    "                            \n",
    "                        except ValueError as e:\n",
    "                            print(f\"Error finding columns in {input_file}: {e}\")\n",
    "                            break\n",
    "                        \n",
    "                        first_row = False\n",
    "                        continue\n",
    "                    \n",
    "                    # Filter: Only keep rows where player_to_predict is True\n",
    "                    if player_to_predict_idx != -1:\n",
    "                        val = row[player_to_predict_idx].lower()\n",
    "                        if val != 'true':\n",
    "                            continue \n",
    "\n",
    "                    # Extract Key\n",
    "                    key = (row[game_id_idx], row[play_id_idx], row[nfl_id_idx])\n",
    "                    \n",
    "                    if key not in self.input_sequences:\n",
    "                        self.input_sequences[key] = []\n",
    "                    \n",
    "                    # Append all feature columns (should be 18 features like unsupervised)\n",
    "                    self.input_sequences[key].append([self.process_value(row[i]) for i in feature_indices])\n",
    "\n",
    "    def load_output_files(self):\n",
    "        \"\"\"\n",
    "        Loads output CSV files.\n",
    "        Selects specific features: ['x', 'y'].\n",
    "        \"\"\"\n",
    "        output_files = sorted([f for f in os.listdir(self.train_dir) if f.startswith('output') and f.endswith('.csv')])\n",
    "        print(f\"Loading {len(output_files)} Output files...\")\n",
    "        \n",
    "        features_to_keep = ['x', 'y']\n",
    "\n",
    "        for output_file in output_files:\n",
    "            output_path = os.path.join(self.train_dir, output_file)\n",
    "            with open(output_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                first_row = True\n",
    "                \n",
    "                # Indices for ID columns\n",
    "                game_id_idx = -1\n",
    "                play_id_idx = -1\n",
    "                nfl_id_idx = -1\n",
    "                \n",
    "                # Indices for feature columns\n",
    "                feature_indices = []\n",
    "\n",
    "                for row in reader:\n",
    "                    if first_row:\n",
    "                        if not self.output_header:\n",
    "                            self.output_header = row\n",
    "                        \n",
    "                        try:\n",
    "                            game_id_idx = row.index('game_id')\n",
    "                            play_id_idx = row.index('play_id')\n",
    "                            nfl_id_idx = row.index('nfl_id')\n",
    "                            \n",
    "                            # Find indices for the features we want to keep\n",
    "                            feature_indices = [row.index(feat) for feat in features_to_keep]\n",
    "                            \n",
    "                        except ValueError as e:\n",
    "                            print(f\"Error finding columns in {output_file}: {e}\")\n",
    "                            break\n",
    "\n",
    "                        first_row = False\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract Key\n",
    "                    key = (row[game_id_idx], row[play_id_idx], row[nfl_id_idx])\n",
    "                    \n",
    "                    if key not in self.output_sequences:\n",
    "                        self.output_sequences[key] = []\n",
    "                    \n",
    "                    # Append only the selected features (x, y)\n",
    "                    self.output_sequences[key].append([float(row[i]) for i in feature_indices])\n",
    "\n",
    "    def get_aligned_data(self):\n",
    "        \"\"\"\n",
    "        Aligns input and output sequences and returns NumPy arrays.\n",
    "        Returns:\n",
    "            X (np.ndarray): Input sequences with features ['x', 'y', 's', 'a', 'dir', 'o']\n",
    "            y (np.ndarray): Output sequences with features ['x', 'y']\n",
    "        \"\"\"\n",
    "        self.load_input_files()\n",
    "        self.load_output_files()\n",
    "\n",
    "        print(\"Aligning Input and Output sequences...\")\n",
    "        common_keys = sorted(list(set(self.input_sequences.keys()).intersection(set(self.output_sequences.keys()))))\n",
    "\n",
    "        aligned_X = []\n",
    "        aligned_y = []\n",
    "\n",
    "        for key in common_keys:\n",
    "            aligned_X.append(self.input_sequences[key])\n",
    "            aligned_y.append(self.output_sequences[key])\n",
    "\n",
    "        print(f\"Processing complete.\")\n",
    "        print(f\"Total Unique Sequences (Matches): {len(common_keys)}\")\n",
    "\n",
    "        if not aligned_X:\n",
    "            print(\"No matching data found.\")\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        # Using dtype=object to handle potential variable lengths or mixed types safely\n",
    "        try:\n",
    "            X = np.array(aligned_X, dtype=object)\n",
    "            print(f\"Initial X shape: {X.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating X array: {e}\")\n",
    "            X = np.array([])\n",
    "\n",
    "        try:\n",
    "            y = np.array(aligned_y, dtype=object)\n",
    "            print(f\"Initial y shape: {y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating y array: {e}\")\n",
    "            y = np.array([])\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class NFLDataSequence(Sequence):\n",
    "    \"\"\"\n",
    "    Keras Sequence for NFL data with automatic padding of variable-length sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size=32, maxlen_x=None, maxlen_y=None, shuffle=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (list): List of input sequences (each sequence is a list of time steps)\n",
    "            y (list): List of output sequences (each sequence is a list of time steps)\n",
    "            batch_size (int): Batch size\n",
    "            maxlen_x (int, optional): Maximum length for input sequences. If None, uses max length in data.\n",
    "            maxlen_y (int, optional): Maximum length for output sequences. If None, uses max length in data.\n",
    "            shuffle (bool): Whether to shuffle data at the end of each epoch\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        \n",
    "        # Determine max lengths if not provided\n",
    "        if maxlen_x is None:\n",
    "            self.maxlen_x = max(len(seq) for seq in X)\n",
    "        else:\n",
    "            self.maxlen_x = maxlen_x\n",
    "            \n",
    "        if maxlen_y is None:\n",
    "            self.maxlen_y = max(len(seq) for seq in y)\n",
    "        else:\n",
    "            self.maxlen_y = maxlen_y\n",
    "        \n",
    "        print(f\"NFLDataSequence initialized: {len(self.X)} samples, batch_size={batch_size}\")\n",
    "        print(f\"Max sequence lengths - X: {self.maxlen_x}, y: {self.maxlen_y}\")\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch\"\"\"\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generate one batch of data\n",
    "        \"\"\"\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Get batch data\n",
    "        batch_X = [self.X[i] for i in batch_indices]\n",
    "        batch_y = [self.y[i] for i in batch_indices]\n",
    "        \n",
    "        # Process X sequences: handle mixed types\n",
    "        # The data from process_value() should already have numeric types as floats\n",
    "        # and strings as strings. We need to filter out or encode string columns.\n",
    "        batch_X_numeric = []\n",
    "        for seq in batch_X:\n",
    "            seq_numeric = []\n",
    "            for frame in seq:\n",
    "                frame_numeric = []\n",
    "                for item in frame:\n",
    "                    # If item is already a float or int (from process_value), keep it\n",
    "                    if isinstance(item, (int, float)):\n",
    "                        frame_numeric.append(float(item))\n",
    "                    # If it's a string, we need to handle it\n",
    "                    # For now, let's use a hash or skip it\n",
    "                    # Better approach: filter these columns out or use proper encoding\n",
    "                    elif isinstance(item, str):\n",
    "                        # Try to convert to float, if fails, use hash or 0\n",
    "                        try:\n",
    "                            frame_numeric.append(float(item))\n",
    "                        except ValueError:\n",
    "                            # For non-numeric strings, use a simple hash-based encoding\n",
    "                            # This is a simple placeholder - ideally use proper categorical encoding\n",
    "                            frame_numeric.append(float(hash(item) % 10000))\n",
    "                    else:\n",
    "                        frame_numeric.append(0.0)\n",
    "                seq_numeric.append(frame_numeric)\n",
    "            batch_X_numeric.append(seq_numeric)\n",
    "        \n",
    "        # Use pad_sequences for both X and y\n",
    "        # pad_sequences expects sequences of shape (n_samples, n_timesteps) for 2D\n",
    "        # For 3D (n_samples, n_timesteps, n_features), we need to pad manually or use padding='post'\n",
    "        \n",
    "        # Method: Pad each sequence to maxlen, filling with zeros\n",
    "        X_padded = pad_sequences(\n",
    "            batch_X_numeric, \n",
    "            maxlen=self.maxlen_x, \n",
    "            dtype='float32',\n",
    "            padding='post',\n",
    "            truncating='post',\n",
    "            value=0.0\n",
    "        )\n",
    "        \n",
    "        y_padded = pad_sequences(\n",
    "            batch_y,\n",
    "            maxlen=self.maxlen_y,\n",
    "            dtype='float32',\n",
    "            padding='post',\n",
    "            truncating='post',\n",
    "            value=0.0\n",
    "        )\n",
    "        \n",
    "        return X_padded, y_padded\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle indices after each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "def create_tf_datasets(X, y, test_size=0.2, batch_size=64, maxlen_x=None, maxlen_y=None):\n",
    "    \"\"\"\n",
    "    Splits X and y into training and validation sets and creates Keras Sequence datasets.\n",
    "    Uses keras.utils.Sequence with padding to handle variable-length sequences.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Input data (object array of variable-length sequences).\n",
    "        y (np.ndarray): Output data (object array of variable-length sequences).\n",
    "        test_size (float): Proportion of the dataset to include in the validation split.\n",
    "        batch_size (int): Batch size for the datasets.\n",
    "        maxlen_x (int, optional): Maximum length for input sequences. If None, auto-detects.\n",
    "        maxlen_y (int, optional): Maximum length for output sequences. If None, auto-detects.\n",
    "        \n",
    "    Returns:\n",
    "        train_sequence (NFLDataSequence): Training data sequence.\n",
    "        val_sequence (NFLDataSequence): Validation data sequence.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Keras Sequence Datasets with Padding ---\")\n",
    "    \n",
    "    try:\n",
    "        # Convert object arrays to lists\n",
    "        X_list = X.tolist()\n",
    "        y_list = y.tolist()\n",
    "        \n",
    "        # Split into train and validation\n",
    "        print(f\"Splitting data (test_size={test_size})...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_list, y_list, \n",
    "            test_size=test_size, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"Train size: {len(X_train)}\")\n",
    "        print(f\"Val size: {len(X_val)}\")\n",
    "        \n",
    "        # Create Sequence objects\n",
    "        print(\"Creating Training Sequence...\")\n",
    "        train_sequence = NFLDataSequence(\n",
    "            X_train, y_train, \n",
    "            batch_size=batch_size,\n",
    "            maxlen_x=maxlen_x,\n",
    "            maxlen_y=maxlen_y,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        print(\"Creating Validation Sequence...\")\n",
    "        val_sequence = NFLDataSequence(\n",
    "            X_val, y_val,\n",
    "            batch_size=batch_size,\n",
    "            maxlen_x=train_sequence.maxlen_x,  # Use same max lengths as training\n",
    "            maxlen_y=train_sequence.maxlen_y,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        print(\"Sequences created successfully.\")\n",
    "        print(f\"Training batches per epoch: {len(train_sequence)}\")\n",
    "        print(f\"Validation batches per epoch: {len(val_sequence)}\")\n",
    "        \n",
    "        return train_sequence, val_sequence\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Keras sequences: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_DIR = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/train/'\n",
    "    \n",
    "    loader = NFLDataLoader(TRAIN_DIR)\n",
    "    X, y = loader.get_aligned_data()\n",
    "\n",
    "    print(\"\\n--- Final Data Shapes ---\")\n",
    "    print(f\"X (Input) Shape: {X.shape}\")\n",
    "    print(f\"y (Output) Shape: {y.shape}\")\n",
    "\n",
    "    if len(X) > 0:\n",
    "        print(f\"Sample Input Sequence Length: {len(X[0])}\")\n",
    "        print(f\"Sample Output Sequence Length: {len(y[0])}\")\n",
    "\n",
    "    # Create Keras Sequences with padding\n",
    "    train_seq, val_seq = create_tf_datasets(X, y, batch_size=32)\n",
    "    \n",
    "    if train_seq:\n",
    "        print(\"\\nVerifying Sequence Element:\")\n",
    "        # Get one batch to verify shapes\n",
    "        x_batch, y_batch = train_seq[0]\n",
    "        print(f\"Batch X shape: {x_batch.shape}\")\n",
    "        print(f\"Batch y shape: {y_batch.shape}\")\n",
    "        print(f\"Max sequence lengths - X: {train_seq.maxlen_x}, y: {train_seq.maxlen_y}\")\n",
    "\n",
    "    print(\"\\nData loading, alignment, and sequence creation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-26T04:52:12.825Z",
     "iopub.execute_input": "2025-11-26T04:32:10.631764Z",
     "iopub.status.busy": "2025-11-26T04:32:10.631345Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 26m 48s]\n",
      "val_loss: 566.2125854492188\n",
      "\n",
      "Best val_loss So Far: 480.52069091796875\n",
      "Total elapsed time: 00h 33m 22s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.00081926        |3.6117e-05        |lr\n",
      "696               |192               |lu\n",
      "3.7001e-06        |1.1033e-08        |kr\n",
      "sigmoid           |hard_sigmoid      |af\n",
      "0.00052148        |0.00015039        |wd\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m 756/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 356ms/step - loss: 530.3284 - mean_absolute_error: 12.0249"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 205\u001b[0m\n\u001b[1;32m    202\u001b[0m train_seq, val_seq \u001b[38;5;241m=\u001b[39m create_tf_datasets(X, y, test_size\u001b[38;5;241m=\u001b[39mtest_size, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Run the hyperparameter experimentation\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m \u001b[43mexperimenting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 166\u001b[0m, in \u001b[0;36mexperimenting\u001b[0;34m(training_dataset, validation_data)\u001b[0m\n\u001b[1;32m    162\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch_space_summary() \u001b[38;5;66;03m# Print a summary of the hyperparameter search space\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# NFLDataSequence is already batched, no need to call batch() again\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Run the hyperparameter search experiments\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m tuner\u001b[38;5;241m.\u001b[39mresults_summary()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    398\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[0;32m--> 399\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    239\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    240\u001b[0m     ):\n\u001b[0;32m--> 241\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import sys\n",
    "import keras_tuner\n",
    "\n",
    "# Add the manual_data_processing directory to the path\n",
    "# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'manual_data_processing'))\n",
    "\n",
    "# from csv_to_numpy import NFLDataLoader, create_tf_datasets\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds a compiled Keras LSTM model with hyperparameters to be experimented on.\n",
    "\n",
    "    This function defines the architecture of the LSTM model for sequence-to-sequence prediction.\n",
    "    It incorporates hyperparameter search spaces for key model parameters like learning rate,\n",
    "    number of LSTM units, kernel regularization, and activation functions.\n",
    "\n",
    "    Args:\n",
    "        hp (keras_tuner.HyperParameters): An instance of Keras Tuner's HyperParameters class,\n",
    "                                          used to define the search space for hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The compiled Keras LSTM model with hyperparameters set by Keras Tuner.\n",
    "    \"\"\"\n",
    "    k_init = keras.initializers.RandomNormal(mean=1503.17, \n",
    "    stddev=2755.38, \n",
    "    seed=42)\n",
    "    SEED = 42\n",
    "    # Define hyperparameter search spaces for tuning\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-7, max_value=1e-3, sampling=\"log\")\n",
    "    layer_u = hp.Int(\"lu\", min_value=160, max_value=1024, step=8)\n",
    "    kernel_r = hp.Float(\"kr\", min_value=1e-10, max_value=1e-5, sampling=\"log\")\n",
    "    acti_f = hp.Choice(\"af\", [\"sigmoid\", \"hard_sigmoid\", \"tanh\", \"relu\", \"softmax\", \"linear\"])\n",
    "    weight_d = hp.Float(\"wd\", min_value=1e-10, max_value=0.0009, sampling=\"log\")\n",
    "\n",
    "    # Define the model structure using Keras Sequential API\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        keras.layers.Input(shape=(input_seq_length, input_features)),\n",
    "        \n",
    "        # Encoder LSTM layers\n",
    "        keras.layers.LSTM(\n",
    "            units=layer_u,\n",
    "            activation=acti_f,\n",
    "            kernel_initializer=k_init,\n",
    "            return_sequences=True,\n",
    "            # kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        keras.layers.LSTM(\n",
    "            units=layer_u // 2,\n",
    "            activation=acti_f,\n",
    "            kernel_initializer=k_init,\n",
    "            return_sequences=True,\n",
    "            # kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        # keras.layers.LSTM(\n",
    "        #     units=layer_u // 2,\n",
    "        #     activation=acti_f,\n",
    "        #     kernel_initializer=k_init,\n",
    "        #     return_sequences=True,\n",
    "        #     # kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n",
    "        #     seed=SEED,\n",
    "        # ),\n",
    "        # keras.layers.LSTM(\n",
    "        #     units=layer_u // 2,\n",
    "        #     activation=acti_f,\n",
    "        #     kernel_initializer=k_init,\n",
    "        #     return_sequences=True,\n",
    "        #     # kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n",
    "        #     seed=SEED,\n",
    "        # ),\n",
    "        # keras.layers.LSTM(\n",
    "        #     units=layer_u // 2,\n",
    "        #     activation=acti_f,\n",
    "        #     kernel_initializer=k_init,\n",
    "        #     return_sequences=True,\n",
    "        #     # kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n",
    "        #     seed=SEED,\n",
    "        # ),\n",
    "        # layers.RepeatVector(output_seq_length),\n",
    "        keras.layers.LSTM(\n",
    "            units=32,\n",
    "            activation=\"sigmoid\",\n",
    "            kernel_initializer=k_init,\n",
    "            return_sequences=True,\n",
    "            # kernel_regularizer=keras.regularizers.L2(l2=0.00000195),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        # Crop or slice to match output sequence length\n",
    "        # layers.Lambda(lambda x: x[:, :output_seq_length, :]),\n",
    "        # TimeDistributed dense layer for output features\n",
    "        layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=output_features, activation=\"linear\")\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Compile the model with a tunable optimizer and metrics\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "            global_clipnorm=1,\n",
    "            amsgrad=False,\n",
    "            weight_decay=weight_d, # Tunable weight decay\n",
    "        ),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def experimenting(training_dataset, validation_data):\n",
    "    \"\"\"\n",
    "    Runs Keras Tuner experiments for the LSTM model using the RandomSearch algorithm.\n",
    "\n",
    "    This function initializes a `RandomSearch` tuner with the `build_model` function,\n",
    "    configures the search objective (minimizing validation loss), and then executes\n",
    "    the hyperparameter search across the defined search spaces. It prints summaries\n",
    "    of the search space and the results.\n",
    "\n",
    "    Args:\n",
    "        training_dataset: NFLDataSequence object for training data\n",
    "        validation_data: NFLDataSequence object for validation data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    hp = keras_tuner.HyperParameters()\n",
    "    \n",
    "    # Get a batch from the sequence to determine shapes\n",
    "    x_batch, y_batch = training_dataset[0]\n",
    "    global input_features, input_seq_length, output_seq_length, output_features\n",
    "    input_seq_length = x_batch.shape[1]\n",
    "    input_features = x_batch.shape[2]\n",
    "    output_seq_length = y_batch.shape[1]\n",
    "    output_features = y_batch.shape[2]\n",
    "    \n",
    "    print(f\"\\nDetected shapes:\")\n",
    "    print(f\"  Input: ({input_seq_length}, {input_features})\")\n",
    "    print(f\"  Output: ({output_seq_length}, {output_features})\")\n",
    "    \n",
    "    build_model(hp) # Instantiate a dummy model to build the search space\n",
    "\n",
    "    # Initialize Keras Tuner's RandomSearch algorithm\n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        hypermodel=build_model,\n",
    "        max_trials=10, # Maximum number of hyperparameter combinations to try\n",
    "        objective=keras_tuner.Objective(\"val_loss\", \"min\"),   # Objective is to minimize validation loss\n",
    "        executions_per_trial=1, # Number of models to train for each trial (1 for efficiency)\n",
    "        overwrite=True, # Overwrite previous results in the directory\n",
    "        directory=os.getenv(\"KERAS_TUNER_EXPERIMENTS_DIR\", \"./tuner_results\"), # Directory to save experiment logs and checkpoints\n",
    "        project_name=\"nfl_prediction\", # Name of the Keras Tuner project\n",
    "        seed = 42,\n",
    "        max_consecutive_failed_trials=5,\n",
    "    )\n",
    "\n",
    "    tuner.search_space_summary() # Print a summary of the hyperparameter search space\n",
    "\n",
    "    # NFLDataSequence is already batched, no need to call batch() again\n",
    "    # Run the hyperparameter search experiments\n",
    "    tuner.search(\n",
    "        training_dataset, \n",
    "        validation_data=validation_data, \n",
    "        epochs=5\n",
    "    )\n",
    "\n",
    "    tuner.results_summary() # Print a summary of the best performing trials\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dir = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/train'\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    test_size = 0.2\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NFL Big Data Bowl 2026 - Predictor Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\n[1/4] Loading data from CSV files...\")\n",
    "    loader = NFLDataLoader(train_dir)\n",
    "    X, y = loader.get_aligned_data()\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No data loaded. Please check the data directory.\")\n",
    "    \n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"  Total sequences: {len(X)}\")\n",
    "    print(f\"  Sample input sequence length: {len(X[0])}\")\n",
    "    print(f\"  Sample output sequence length: {len(y[0])}\")\n",
    "    print(f\"  Input features per timestep: {len(X[0][0]) if len(X[0]) > 0 else 0}\")\n",
    "    print(f\"  Output features per timestep: {len(y[0][0]) if len(y[0]) > 0 else 0}\")\n",
    "    \n",
    "    # Create Keras Sequences with padding\n",
    "    print(f\"\\n[2/4] Creating training and validation sequences (test_size={test_size})...\")\n",
    "    train_seq, val_seq = create_tf_datasets(X, y, test_size=test_size, batch_size=batch_size)\n",
    "    \n",
    "    # Run the hyperparameter experimentation\n",
    "    experimenting(train_seq, val_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Hyperband training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:46:02.056581Z",
     "iopub.status.busy": "2025-11-29T09:46:02.056173Z",
     "iopub.status.idle": "2025-11-29T09:46:02.397101Z",
     "shell.execute_reply": "2025-11-29T09:46:02.396309Z",
     "shell.execute_reply.started": "2025-11-29T09:46:02.056557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers, losses, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_seq2seq_model(hp, \n",
    "                        input_seq_length, input_features,\n",
    "                        output_seq_length, output_features):\n",
    "    \"\"\"\n",
    "    Returns a compiled Keras model.\n",
    "    hp – HyperParameters object supplied by Keras‑Tuner.\n",
    "    \"\"\"\n",
    "    # ---------- Hyper‑parameters ----------\n",
    "    # Number of LSTM layers (encoder + decoder)\n",
    "    n_encoder_layers = hp.Int('enc_layers', 2, 6, step=1)\n",
    "    n_decoder_layers = hp.Int('dec_layers', 2, 6, step=1)\n",
    "\n",
    "    # LSTM units per layer (same for all layers for simplicity)\n",
    "    lstm_units = hp.Choice('lstm_units', [64, 128, 256, 384, 512])\n",
    "\n",
    "    # Dropout rate\n",
    "    dropout_rate = hp.Float('dropout', 0.0, 0.3, step=0.05)\n",
    "\n",
    "    # Learning‑rate schedule\n",
    "    init_lr = hp.Float('init_lr', 1e-5, 5e-3, sampling='log')\n",
    "    \n",
    "    # ---------- Model ----------\n",
    "    # Encoder\n",
    "    encoder_inputs = layers.Input(shape=(input_seq_length, input_features),\n",
    "                                  name='encoder_inputs')\n",
    "    x = encoder_inputs\n",
    "    for i in range(n_encoder_layers):\n",
    "        # Residual LSTM block\n",
    "        lstm_out = layers.LSTM(lstm_units,\n",
    "                               return_sequences=True,\n",
    "                               name=f'enc_lstm_{i+1}')(x)\n",
    "        lstm_out = layers.Dropout(dropout_rate,\n",
    "                                  name=f'enc_dropout_{i+1}')(lstm_out)\n",
    "        # Add residual connection (if dimensions match)\n",
    "        if lstm_out.shape[-1] == x.shape[-1]:\n",
    "            lstm_out = layers.Add(name=f'enc_res_{i+1}')([x, lstm_out])\n",
    "        # Normalise\n",
    "        lstm_out = layers.LayerNormalization(name=f'enc_norm_{i+1}')(lstm_out)\n",
    "        x = lstm_out\n",
    "\n",
    "    # Grab the final hidden state as the latent vector\n",
    "    latent = layers.LSTM(lstm_units,\n",
    "                         return_sequences=False,\n",
    "                         name='latent')(x)\n",
    "\n",
    "    # Decoder – repeat latent vector for each output timestep\n",
    "    decoder_inputs = layers.RepeatVector(output_seq_length,\n",
    "                                         name='repeat_latent')(latent)\n",
    "    y = decoder_inputs\n",
    "    for i in range(n_decoder_layers):\n",
    "        lstm_out = layers.LSTM(lstm_units,\n",
    "                               return_sequences=True,\n",
    "                               name=f'dec_lstm_{i+1}')(y)\n",
    "        lstm_out = layers.Dropout(dropout_rate,\n",
    "                                  name=f'dec_dropout_{i+1}')(lstm_out)\n",
    "        # Residual connection (again only when shapes match)\n",
    "        if lstm_out.shape[-1] == y.shape[-1]:\n",
    "            lstm_out = layers.Add(name=f'dec_res_{i+1}')([y, lstm_out])\n",
    "        lstm_out = layers.LayerNormalization(name=f'dec_norm_{i+1}')(lstm_out)\n",
    "        y = lstm_out\n",
    "\n",
    "    # Final TimeDistributed dense layer\n",
    "    decoder_outputs = layers.TimeDistributed(\n",
    "        layers.Dense(output_features, activation='linear'),\n",
    "        name='decoder_output')(y)\n",
    "\n",
    "    model = models.Model(inputs=encoder_inputs, outputs=decoder_outputs,\n",
    "                         name='tunable_seq2seq')\n",
    "\n",
    "    # ---------- Learning‑rate schedule ----------\n",
    "    # Simplified to just CosineDecay to avoid TypeError\n",
    "    total_steps = hp.Int('total_steps', 1, 100000, step=1)\n",
    "    learning_rate = optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=init_lr,\n",
    "        decay_steps=total_steps,\n",
    "        alpha=1e-5)\n",
    "\n",
    "    optimizer = optimizers.AdamW(learning_rate=learning_rate, global_clipnorm=1.0)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=losses.Huber(),\n",
    "                  metrics=[metrics.MeanSquaredError(), metrics.MeanAbsoluteError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:46:06.070314Z",
     "iopub.status.busy": "2025-11-29T09:46:06.070022Z",
     "iopub.status.idle": "2025-11-29T09:46:06.077180Z",
     "shell.execute_reply": "2025-11-29T09:46:06.076474Z",
     "shell.execute_reply.started": "2025-11-29T09:46:06.070292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def tuner_search(train_seq, val_seq,\n",
    "                 input_seq_len, input_feat,\n",
    "                 output_seq_len, output_feat,\n",
    "                 max_trials=30, epochs_per_trial=5):\n",
    "    \"\"\"\n",
    "    Runs Hyperband and returns the best model + history.\n",
    "    \"\"\"\n",
    "    # Define the hypermodel function\n",
    "    def make_model(hp):\n",
    "        return build_seq2seq_model(\n",
    "            hp,\n",
    "            input_seq_length=input_seq_len,\n",
    "            input_features=input_feat,\n",
    "            output_seq_length=output_seq_len,\n",
    "            output_features=output_feat)\n",
    "    \n",
    "    # Check for distribution strategy\n",
    "    if 'strategy' in globals() and strategy is not None:\n",
    "        print(f\"Using distribution strategy: {strategy}\")\n",
    "        distribution = strategy\n",
    "    else:\n",
    "        print(\"No distribution strategy found, using default.\")\n",
    "        distribution = tf.distribute.get_strategy()\n",
    "        \n",
    "    # Initialize tuner with distribution strategy\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=make_model,\n",
    "        objective='val_loss',\n",
    "        max_epochs=epochs_per_trial,\n",
    "        factor=3,\n",
    "        directory='kt_tuner',\n",
    "        project_name='nfl_seq2seq',\n",
    "        overwrite=True,\n",
    "        distribution_strategy=distribution)\n",
    "\n",
    "    # Early-stopping inside each trial\n",
    "    stop_early = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "    tuner.search(train_seq,\n",
    "                 validation_data=val_seq,\n",
    "                 callbacks=[stop_early],\n",
    "                 verbose=1)\n",
    "\n",
    "    # Retrieve the best hyper-parameters & model\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Train the best model a little longer (optional)\n",
    "    # Ensure training also uses the strategy if needed (model is already compiled with it)\n",
    "    final_history = best_model.fit(\n",
    "        train_seq,\n",
    "        validation_data=val_seq,\n",
    "        epochs=epochs_per_trial * 2,   # give it more epochs now that we know the arch.\n",
    "        callbacks=[callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=5,\n",
    "                                           restore_best_weights=True)],\n",
    "        verbose=1)\n",
    "\n",
    "    return best_model, final_history, best_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:46:09.234249Z",
     "iopub.status.busy": "2025-11-29T09:46:09.233948Z",
     "iopub.status.idle": "2025-11-29T13:17:15.748239Z",
     "shell.execute_reply": "2025-11-29T13:17:15.747440Z",
     "shell.execute_reply.started": "2025-11-29T09:46:09.234226Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 13m 08s]\n",
      "val_loss: 79.6121597290039\n",
      "\n",
      "Best val_loss So Far: 49.87461471557617\n",
      "Total elapsed time: 02h 47m 34s\n",
      "Epoch 1/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 49ms/step - loss: 36.0317 - mean_absolute_error: 36.4028 - mean_squared_error: 16112.9053 - val_loss: 52.0851 - val_mean_absolute_error: 52.4998 - val_mean_squared_error: 18105.3262\n",
      "Epoch 2/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 35.7299 - mean_absolute_error: 36.0986 - mean_squared_error: 16770.8281 - val_loss: 49.2926 - val_mean_absolute_error: 49.7057 - val_mean_squared_error: 17073.5156\n",
      "Epoch 3/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 34.1220 - mean_absolute_error: 34.4919 - mean_squared_error: 15664.5459 - val_loss: 58.6852 - val_mean_absolute_error: 59.1017 - val_mean_squared_error: 24714.9590\n",
      "Epoch 4/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 33.6196 - mean_absolute_error: 33.9896 - mean_squared_error: 16457.9336 - val_loss: 59.6823 - val_mean_absolute_error: 60.1025 - val_mean_squared_error: 27601.8340\n",
      "Epoch 5/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 32.9603 - mean_absolute_error: 33.3304 - mean_squared_error: 14901.7773 - val_loss: 49.6457 - val_mean_absolute_error: 50.0618 - val_mean_squared_error: 17903.4336\n",
      "Epoch 6/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 30.4188 - mean_absolute_error: 30.7868 - mean_squared_error: 13259.0654 - val_loss: 42.6858 - val_mean_absolute_error: 43.1046 - val_mean_squared_error: 12567.7344\n",
      "Epoch 7/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 28.9700 - mean_absolute_error: 29.3388 - mean_squared_error: 11722.2910 - val_loss: 46.1494 - val_mean_absolute_error: 46.5713 - val_mean_squared_error: 15950.6133\n",
      "Epoch 8/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 28.2031 - mean_absolute_error: 28.5705 - mean_squared_error: 11340.9688 - val_loss: 43.5739 - val_mean_absolute_error: 43.9981 - val_mean_squared_error: 13207.5898\n",
      "Epoch 9/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 27.4619 - mean_absolute_error: 27.8299 - mean_squared_error: 11339.8398 - val_loss: 41.7602 - val_mean_absolute_error: 42.1779 - val_mean_squared_error: 13456.2803\n",
      "Epoch 10/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 27.2104 - mean_absolute_error: 27.5772 - mean_squared_error: 11190.1494 - val_loss: 44.7407 - val_mean_absolute_error: 45.1655 - val_mean_squared_error: 15292.8018\n",
      "Epoch 11/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 26.8944 - mean_absolute_error: 27.2611 - mean_squared_error: 10992.8311 - val_loss: 37.3907 - val_mean_absolute_error: 37.8085 - val_mean_squared_error: 9842.1182\n",
      "Epoch 12/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 25.3712 - mean_absolute_error: 25.7394 - mean_squared_error: 9738.9258 - val_loss: 43.3001 - val_mean_absolute_error: 43.7278 - val_mean_squared_error: 18549.4336\n",
      "Epoch 13/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 24.4547 - mean_absolute_error: 24.8213 - mean_squared_error: 9293.0557 - val_loss: 36.6303 - val_mean_absolute_error: 37.0482 - val_mean_squared_error: 9859.6641\n",
      "Epoch 14/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 23.6939 - mean_absolute_error: 24.0597 - mean_squared_error: 9536.3467 - val_loss: 38.3853 - val_mean_absolute_error: 38.8055 - val_mean_squared_error: 16348.4697\n",
      "Epoch 15/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 25.8180 - mean_absolute_error: 26.1823 - mean_squared_error: 15861.7578 - val_loss: 36.7576 - val_mean_absolute_error: 37.1746 - val_mean_squared_error: 14597.0713\n",
      "Epoch 16/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 24.7414 - mean_absolute_error: 25.1061 - mean_squared_error: 13845.4902 - val_loss: 34.9590 - val_mean_absolute_error: 35.3780 - val_mean_squared_error: 13019.2197\n",
      "Epoch 17/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 22.9321 - mean_absolute_error: 23.2964 - mean_squared_error: 12303.0098 - val_loss: 34.0726 - val_mean_absolute_error: 34.4899 - val_mean_squared_error: 11437.1680\n",
      "Epoch 18/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 22.6318 - mean_absolute_error: 22.9938 - mean_squared_error: 11550.4199 - val_loss: 31.0795 - val_mean_absolute_error: 31.5008 - val_mean_squared_error: 8293.7939\n",
      "Epoch 19/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 21.7074 - mean_absolute_error: 22.0699 - mean_squared_error: 9984.3037 - val_loss: 30.7935 - val_mean_absolute_error: 31.2091 - val_mean_squared_error: 7683.0337\n",
      "Epoch 20/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 20.6309 - mean_absolute_error: 20.9923 - mean_squared_error: 8864.5830 - val_loss: 31.1938 - val_mean_absolute_error: 31.6214 - val_mean_squared_error: 8168.8545\n",
      "Epoch 21/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 19.5862 - mean_absolute_error: 19.9478 - mean_squared_error: 7816.6509 - val_loss: 31.9561 - val_mean_absolute_error: 32.3828 - val_mean_squared_error: 9321.4590\n",
      "Epoch 22/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 19.2994 - mean_absolute_error: 19.6616 - mean_squared_error: 7867.4194 - val_loss: 28.7737 - val_mean_absolute_error: 29.1877 - val_mean_squared_error: 6284.5674\n",
      "Epoch 23/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 17.9539 - mean_absolute_error: 18.3120 - mean_squared_error: 6458.6602 - val_loss: 28.0193 - val_mean_absolute_error: 28.4337 - val_mean_squared_error: 5984.6401\n",
      "Epoch 24/24\n",
      "\u001b[1m2165/2165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 49ms/step - loss: 17.0348 - mean_absolute_error: 17.3930 - mean_squared_error: 5606.4282 - val_loss: 27.3760 - val_mean_absolute_error: 27.7908 - val_mean_squared_error: 5910.7358\n",
      "\n",
      "=== Best hyper‑parameters ===\n",
      "enc_layers: 6\n",
      "dec_layers: 2\n",
      "lstm_units: 512\n",
      "dropout: 0.2\n",
      "init_lr: 0.0007976042571981798\n",
      "total_steps: 86898\n",
      "tuner/epochs: 12\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0014\n",
      "Best model saved to best_hyperband_unsupervised_model.keras\n",
      "Encoder model saved to best_hyperband_encoder.keras\n"
     ]
    }
   ],
   "source": [
    "def save_encoder_from_model(model, path):\n",
    "    \"\"\"\n",
    "    Extracts and saves the encoder part of the seq2seq model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The encoder input is the model input\n",
    "        encoder_inputs = model.input\n",
    "        \n",
    "        # The latent vector is the output of the layer named 'latent'\n",
    "        latent_layer = model.get_layer('latent')\n",
    "        latent_output = latent_layer.output\n",
    "        \n",
    "        # Create encoder model\n",
    "        encoder_model = models.Model(inputs=encoder_inputs, outputs=latent_output, name='encoder')\n",
    "        \n",
    "        # Save\n",
    "        encoder_model.save(path)\n",
    "        print(f\"Encoder model saved to {path}\")\n",
    "        return encoder_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving encoder: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1️⃣  Load Unsupervised Data & Prepare Sequences\n",
    "    # ------------------------------------------------------------------\n",
    "    PREDICTION_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "    ANALYTICS_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train'\n",
    "\n",
    "    print(\"Loading unsupervised data...\")\n",
    "    # Initialize loader\n",
    "    loader = UnsupervisedNFLDataLoader()\n",
    "    # Load from both directories\n",
    "    loader.load_files(\n",
    "        [PREDICTION_TRAIN_DIR, ANALYTICS_TRAIN_DIR],\n",
    "        include_labeled=True,\n",
    "        include_unlabeled=True\n",
    "    )\n",
    "    X_unsupervised = loader.get_sequences()\n",
    "\n",
    "    if len(X_unsupervised) == 0:\n",
    "        print(\"ERROR: No unsupervised data loaded!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total unsupervised sequences: {len(X_unsupervised)}\")\n",
    "    \n",
    "    # Split into train/val\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val = train_test_split(X_unsupervised, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create sequences for Next-Step Prediction (Self-Supervised)\n",
    "    task = 'next_step'\n",
    "    prediction_steps = 5  # Predict next 5 steps\n",
    "    \n",
    "    train_seq = UnsupervisedNFLSequence(\n",
    "        X_train,\n",
    "        batch_size=64,\n",
    "        maxlen=10, \n",
    "        shuffle=False,\n",
    "        task=task,\n",
    "        prediction_steps=prediction_steps\n",
    "    )\n",
    "    \n",
    "    val_seq = UnsupervisedNFLSequence(\n",
    "        X_val,\n",
    "        batch_size=64,\n",
    "        maxlen=10,\n",
    "        shuffle=False,\n",
    "        task=task,\n",
    "        prediction_steps=prediction_steps\n",
    "    )\n",
    "\n",
    "    # Get shapes from a batch to configure the model\n",
    "    x_batch, y_batch = train_seq[0]\n",
    "    input_seq_len = x_batch.shape[1]\n",
    "    input_feat = x_batch.shape[2]\n",
    "    output_seq_len = y_batch.shape[1]\n",
    "    output_feat = y_batch.shape[2]\n",
    "\n",
    "    print(f\"Input shape: ({input_seq_len}, {input_feat})\")\n",
    "    print(f\"Output shape: ({output_seq_len}, {output_feat})\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2️⃣  Launch the tuner\n",
    "    # ------------------------------------------------------------------\n",
    "    best_model, best_history, best_hp = tuner_search(\n",
    "            train_seq=train_seq,\n",
    "            val_seq=val_seq,\n",
    "            input_seq_len=input_seq_len,\n",
    "            input_feat=input_feat,\n",
    "            output_seq_len=output_seq_len,\n",
    "            output_feat=output_feat,\n",
    "            max_trials=30,          # increase if you have more time\n",
    "            epochs_per_trial=12)    # short trials for speed\n",
    "\n",
    "    print(\"\\n=== Best hyper‑parameters ===\")\n",
    "    for name, value in best_hp.values.items():\n",
    "        print(f\"{name}: {value}\")\n",
    "        \n",
    "    # Save best model\n",
    "    best_model.save('best_hyperband_unsupervised_model.keras')\n",
    "    print(\"Best model saved to best_hyperband_unsupervised_model.keras\")\n",
    "\n",
    "    # Save encoder separately\n",
    "    save_encoder_from_model(best_model, 'best_hyperband_encoder.keras')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(best_history.history['loss'], label='Training loss')\n",
    "plt.plot(best_history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Best model – Training & Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NFL Big Data Bowl 2026 - Predictor Training\n",
      "============================================================\n",
      "\n",
      "[1/4] Loading data from CSV files...\n",
      "Loading and filtering 18 Input files...\n",
      "Loading 18 Output files...\n",
      "Aligning Input and Output sequences...\n",
      "Processing complete.\n",
      "Total Unique Sequences (Matches): 46045\n",
      "Converting to NumPy arrays...\n",
      "Initial X shape: (46045,)\n",
      "Initial y shape: (46045,)\n",
      "\n",
      "Data Summary:\n",
      "  Total sequences: 46045\n",
      "  Sample input sequence length: 26\n",
      "  Sample output sequence length: 21\n",
      "  Input features per timestep: 18\n",
      "  Output features per timestep: 2\n",
      "\n",
      "[2/4] Creating training and validation sequences (test_size=0.2)...\n",
      "\n",
      "--- Creating Keras Sequence Datasets with Padding ---\n",
      "Splitting data (test_size=0.2)...\n",
      "Train size: 36836\n",
      "Val size: 9209\n",
      "Creating Training Sequence...\n",
      "NFLDataSequence initialized: 36836 samples, batch_size=32\n",
      "Max sequence lengths - X: 1, y: 1\n",
      "Creating Validation Sequence...\n",
      "NFLDataSequence initialized: 9209 samples, batch_size=32\n",
      "Max sequence lengths - X: 1, y: 1\n",
      "Sequences created successfully.\n",
      "Training batches per epoch: 1152\n",
      "Validation batches per epoch: 288\n",
      "\n",
      "Sequence Shapes:\n",
      "  Input: (batch_size, 1, 18)\n",
      "  Output: (batch_size, 1, 2)\n",
      "\n",
      "[3/4] Building sequence-to-sequence model...\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">696</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,990,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">348</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,454,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">348</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">970,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">348</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">970,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">348</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">970,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m696\u001b[0m)         │     \u001b[38;5;34m1,990,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m348\u001b[0m)         │     \u001b[38;5;34m1,454,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m348\u001b[0m)         │       \u001b[38;5;34m970,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m348\u001b[0m)         │       \u001b[38;5;34m970,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m348\u001b[0m)         │       \u001b[38;5;34m970,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m48,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │            \u001b[38;5;34m66\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,404,706</span> (24.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,404,706\u001b[0m (24.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,404,706</span> (24.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,404,706\u001b[0m (24.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/4] Training model for 20 epochs...\n",
      "Starting model training...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 730/1152\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2267.3192 - mae: 40.4973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 17:21:21.286350: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_163', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-11-26 17:21:22.077779: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_163', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2187.1285 - mae: 39.4973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 17:21:28.981750: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 1597.72180, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 1975.0459 - mae: 36.8037 - val_loss: 1597.7218 - val_mae: 31.8607\n",
      "Epoch 2/20\n",
      "\u001b[1m1146/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1462.1113 - mae: 30.0195\n",
      "Epoch 2: val_loss improved from 1597.72180 to 1067.50989, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1327.8428 - mae: 28.1716 - val_loss: 1067.5099 - val_mae: 24.7425\n",
      "Epoch 3/20\n",
      "\u001b[1m1140/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 970.0174 - mae: 23.4465\n",
      "Epoch 3: val_loss improved from 1067.50989 to 722.47778, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 883.0762 - mae: 22.2754 - val_loss: 722.4778 - val_mae: 20.0996\n",
      "Epoch 4/20\n",
      "\u001b[1m1148/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 676.5377 - mae: 19.4557\n",
      "Epoch 4: val_loss improved from 722.47778 to 524.41815, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 618.2572 - mae: 18.6354 - val_loss: 524.4182 - val_mae: 17.2776\n",
      "Epoch 5/20\n",
      "\u001b[1m1148/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495.3516 - mae: 16.8796\n",
      "Epoch 5: val_loss improved from 524.41815 to 408.59558, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 460.1112 - mae: 16.3368 - val_loss: 408.5956 - val_mae: 15.5951\n",
      "Epoch 6/20\n",
      "\u001b[1m1149/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 395.6571 - mae: 15.4418\n",
      "Epoch 6: val_loss improved from 408.59558 to 365.05060, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 380.8065 - mae: 15.2027 - val_loss: 365.0506 - val_mae: 14.9750\n",
      "Epoch 7/20\n",
      "\u001b[1m1145/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 361.8782 - mae: 14.9279\n",
      "Epoch 7: val_loss improved from 365.05060 to 361.00616, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 362.6019 - mae: 14.9500 - val_loss: 361.0062 - val_mae: 14.9203\n",
      "Epoch 8/20\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 361.3613 - mae: 14.9319\n",
      "Epoch 8: val_loss improved from 361.00616 to 360.87573, saving model to best_model.keras\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1461 - mae: 14.9353 - val_loss: 360.8757 - val_mae: 14.9210\n",
      "Epoch 9/20\n",
      "\u001b[1m1150/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 363.8518 - mae: 14.9823\n",
      "Epoch 9: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.0975 - mae: 14.9344 - val_loss: 360.9245 - val_mae: 14.9220\n",
      "Epoch 10/20\n",
      "\u001b[1m1149/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 358.5309 - mae: 14.8929\n",
      "Epoch 10: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1055 - mae: 14.9357 - val_loss: 360.8939 - val_mae: 14.9199\n",
      "Epoch 11/20\n",
      "\u001b[1m1139/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 365.9842 - mae: 15.0182\n",
      "Epoch 11: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1100 - mae: 14.9351 - val_loss: 360.8952 - val_mae: 14.9212\n",
      "Epoch 12/20\n",
      "\u001b[1m1142/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 363.7170 - mae: 15.0018\n",
      "Epoch 12: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1081 - mae: 14.9353 - val_loss: 360.8990 - val_mae: 14.9208\n",
      "Epoch 13/20\n",
      "\u001b[1m1150/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 363.2665 - mae: 14.9762\n",
      "Epoch 13: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1060 - mae: 14.9349 - val_loss: 360.8821 - val_mae: 14.9214\n",
      "Epoch 14/20\n",
      "\u001b[1m1142/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364.6276 - mae: 14.9817\n",
      "Epoch 14: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1019 - mae: 14.9351 - val_loss: 360.8993 - val_mae: 14.9202\n",
      "Epoch 15/20\n",
      "\u001b[1m1149/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 362.4890 - mae: 14.9522\n",
      "Epoch 15: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1021 - mae: 14.9350 - val_loss: 360.8890 - val_mae: 14.9205\n",
      "Epoch 16/20\n",
      "\u001b[1m1141/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359.9898 - mae: 14.9490\n",
      "Epoch 16: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1117 - mae: 14.9351 - val_loss: 360.8842 - val_mae: 14.9201\n",
      "Epoch 17/20\n",
      "\u001b[1m1149/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 361.9279 - mae: 14.9393\n",
      "Epoch 17: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1089 - mae: 14.9348 - val_loss: 360.8918 - val_mae: 14.9201\n",
      "Epoch 18/20\n",
      "\u001b[1m1150/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 358.5100 - mae: 14.9038\n",
      "Epoch 18: val_loss did not improve from 360.87573\n",
      "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 361.1001 - mae: 14.9351 - val_loss: 360.9150 - val_mae: 14.9213\n",
      "Epoch 19/20\n",
      "\u001b[1m 406/1152\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 366.6267 - mae: 15.0407"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 228\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Best validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 208\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[4/4] Training model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 208\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[1;32m    211\u001b[0m final_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfl_predictor_final.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 134\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_sequence, val_sequence, epochs, callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mextend([early_stopping, model_checkpoint])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting model training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    398\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[0;32m--> 399\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:242\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    239\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    240\u001b[0m ):\n\u001b[1;32m    241\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the manual_data_processing directory to the path\n",
    "# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'manual_data_processing'))\n",
    "\n",
    "# from csv_to_numpy import NFLDataLoader, create_tf_datasets\n",
    "\n",
    "def build_seq2seq_model(input_seq_length, input_features, output_seq_length, output_features, lstm_units=128):\n",
    "    \"\"\"\n",
    "    Builds a sequence-to-sequence model with LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        input_seq_length (int): The length of input sequences (time steps).\n",
    "        input_features (int): The number of input features per timestep.\n",
    "        output_seq_length (int): The length of output sequences (time steps).\n",
    "        output_features (int): The number of output features per timestep.\n",
    "        lstm_units (int): The number of units in the LSTM layers.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    SEED = 42\n",
    "    # Encoder-decoder architecture for sequence-to-sequence prediction\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        keras.layers.Input(shape=(input_seq_length, input_features)),\n",
    "        \n",
    "        # Encoder LSTM layers\n",
    "        keras.layers.LSTM(\n",
    "            units=696,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        keras.layers.LSTM(\n",
    "            units=696 // 2,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        keras.layers.LSTM(\n",
    "            units=696 // 2,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        keras.layers.LSTM(\n",
    "            units=696 // 2,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        keras.layers.LSTM(\n",
    "            units=696 // 2,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        # layers.RepeatVector(output_seq_length),\n",
    "        keras.layers.LSTM(\n",
    "            units=32,\n",
    "            activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            # kernel_regularizer=keras.regularizers.L2(l2=0.00000195),\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        # Crop or slice to match output sequence length\n",
    "        # layers.Lambda(lambda x: x[:, :output_seq_length, :]),\n",
    "        # TimeDistributed dense layer for output features\n",
    "        layers.TimeDistributed(\n",
    "            keras.layers.Dense(units=output_features, activation=\"linear\")\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    cosine_decay = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=415000,\n",
    "    alpha=1e-5,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.00081926),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_sequence, val_sequence, epochs=10, callbacks=None):\n",
    "    \"\"\"\n",
    "    Trains the Keras model using Keras Sequence objects.\n",
    "    \n",
    "    Args:\n",
    "        model: The Keras model to train\n",
    "        train_sequence: Training data sequence (NFLDataSequence)\n",
    "        val_sequence: Validation data sequence (NFLDataSequence)\n",
    "        epochs (int): Number of training epochs\n",
    "        callbacks: List of Keras callbacks\n",
    "    \n",
    "    Returns:\n",
    "        history: Training history object\n",
    "    \"\"\"\n",
    "    if callbacks is None:\n",
    "        callbacks = []\n",
    "    \n",
    "    # Add early stopping and model checkpoint callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks.extend([early_stopping, model_checkpoint])\n",
    "    \n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        train_sequence,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_sequence,\n",
    "        callbacks=model_checkpoint,\n",
    "        verbose=1\n",
    "    )\n",
    "    # -------------------------------------------------\n",
    "    # Visualize training & validation loss\n",
    "    # -------------------------------------------------\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'],      label='Training loss')\n",
    "    plt.plot(history.history['val_loss'],  label='Validation loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"Model training finished.\")\n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, build, and train the model.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    train_dir = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/train'\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    test_size = 0.2\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NFL Big Data Bowl 2026 - Predictor Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"\\n[1/4] Loading data from CSV files...\")\n",
    "    loader = NFLDataLoader(train_dir)\n",
    "    X, y = loader.get_aligned_data()\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No data loaded. Please check the data directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"  Total sequences: {len(X)}\")\n",
    "    print(f\"  Sample input sequence length: {len(X[0])}\")\n",
    "    print(f\"  Sample output sequence length: {len(y[0])}\")\n",
    "    print(f\"  Input features per timestep: {len(X[0][0]) if len(X[0]) > 0 else 0}\")\n",
    "    print(f\"  Output features per timestep: {len(y[0][0]) if len(y[0]) > 0 else 0}\")\n",
    "    \n",
    "    # Create Keras Sequences with padding\n",
    "    print(f\"\\n[2/4] Creating training and validation sequences (test_size={test_size})...\")\n",
    "    train_seq, val_seq = create_tf_datasets(X, y, test_size=test_size, batch_size=batch_size)\n",
    "    \n",
    "    if train_seq is None:\n",
    "        print(\"Error: Failed to create training sequences.\")\n",
    "        return\n",
    "    \n",
    "    # Get one batch to determine shapes\n",
    "    x_sample, y_sample = train_seq[0]\n",
    "    input_seq_length = x_sample.shape[1]\n",
    "    input_features = x_sample.shape[2]\n",
    "    output_seq_length = y_sample.shape[1]\n",
    "    output_features = y_sample.shape[2]\n",
    "    \n",
    "    print(f\"\\nSequence Shapes:\")\n",
    "    print(f\"  Input: (batch_size, {input_seq_length}, {input_features})\")\n",
    "    print(f\"  Output: (batch_size, {output_seq_length}, {output_features})\")\n",
    "    \n",
    "    # Build model\n",
    "    print(f\"\\n[3/4] Building sequence-to-sequence model...\")\n",
    "    model = build_seq2seq_model(\n",
    "        input_seq_length=input_seq_length,\n",
    "        input_features=input_features,\n",
    "        output_seq_length=output_seq_length,\n",
    "        output_features=output_features,\n",
    "        lstm_units=128\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\n[4/4] Training model for {epochs} epochs...\")\n",
    "    history = train_model(model, train_seq, val_seq, epochs=epochs)\n",
    "    \n",
    "    # Save the final model\n",
    "    final_model_path = 'nfl_predictor_final.keras'\n",
    "    model.save(final_model_path)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Complete!\")\n",
    "    print(f\"Final model saved to: {final_model_path}\")\n",
    "    print(f\"Best model saved to: best_model.keras\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print training summary\n",
    "    print(f\"\\nTraining Summary:\")\n",
    "    print(f\"  Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "    print(f\"  Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final training MAE: {history.history['mae'][-1]:.4f}\")\n",
    "    print(f\"  Final validation MAE: {history.history['val_mae'][-1]:.4f}\")\n",
    "    print(f\"  Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
