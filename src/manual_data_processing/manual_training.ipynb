{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Unsupervised dataloader","metadata":{}},{"cell_type":"code","source":"!pip install polars\n!pip install keras-tuner\n\nimport polars as pl\nimport numpy as np\nimport os\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import Sequence\n\n\nclass UnsupervisedNFLDataLoader:\n    \"\"\"Loads NFL data for unsupervised learning (no trajectory labels needed).\n    \n    This loader processes ALL player sequences (player_to_predict=True and False)\n    to maximize the amount of training data for representation learning.\n    \"\"\"\n    \n    def __init__(self):\n        self.input_sequences = None\n        \n    def load_files(self, directories, include_labeled=True, include_unlabeled=True):\n        \"\"\"Load input files from specified directories.\n        \n        Args:\n            directories (list): List of directory paths to load from\n            include_labeled (bool): Include player_to_predict=True sequences\n            include_unlabeled (bool): Include player_to_predict=False sequences\n        \"\"\"\n        input_dfs = []\n        \n        print(f\"Loading unsupervised data from {len(directories)} directories...\")\n        print(f\"Include labeled: {include_labeled}, Include unlabeled: {include_unlabeled}\")\n        \n        for d in directories:\n            if not os.path.exists(d):\n                print(f\"Warning: Directory not found: {d}\")\n                continue\n                \n            input_files = sorted([f for f in os.listdir(d) if f.startswith('input') and f.endswith('.csv')])\n            print(f\"  Found {len(input_files)} input files in {d}\")\n            \n            for f in input_files:\n                try:\n                    df = pl.read_csv(os.path.join(d, f), infer_schema_length=10000)\n                    \n                    initial_rows = len(df)\n                    \n                    # Filter based on player_to_predict flag\n                    if \"player_to_predict\" in df.columns:\n                        if include_labeled and not include_unlabeled:\n                            # Only labeled\n                            if df[\"player_to_predict\"].dtype == pl.Boolean:\n                                df = df.filter(pl.col(\"player_to_predict\") == True)\n                            else:\n                                df = df.filter(pl.col(\"player_to_predict\").cast(pl.Utf8).str.to_lowercase() == \"true\")\n                        elif include_unlabeled and not include_labeled:\n                            # Only unlabeled\n                            if df[\"player_to_predict\"].dtype == pl.Boolean:\n                                df = df.filter(pl.col(\"player_to_predict\") == False)\n                            else:\n                                df = df.filter(pl.col(\"player_to_predict\").cast(pl.Utf8).str.to_lowercase() == \"false\")\n                        # If both True, include all (no filtering)\n                    \n                    if len(df) > 0:\n                        input_dfs.append(df)\n                        print(f\"    {f}: {initial_rows} -> {len(df)} rows\")\n                        \n                except Exception as e:\n                    print(f\"Error loading {f}: {e}\")\n        \n        if not input_dfs:\n            print(\"No data found.\")\n            self.input_sequences = pl.DataFrame()\n            return\n        \n        # Concatenate all dataframes\n        print(\"Concatenating dataframes...\")\n        full_input = pl.concat(input_dfs, how=\"vertical_relaxed\")\n        \n        # Deduplicate\n        full_input = full_input.unique(subset=[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n        \n        # Process features\n        print(\"Processing features...\")\n        id_cols = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"player_to_predict\", \"time\"]\n        feature_cols = [c for c in full_input.columns if c not in id_cols]\n        \n        expressions = []\n        for col in feature_cols:\n            if full_input[col].dtype == pl.Utf8:\n                expr = (\n                    pl.when(pl.col(col).str.to_lowercase() == \"true\").then(1.0)\n                    .when(pl.col(col).str.to_lowercase() == \"false\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"left\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"right\").then(1.0)\n                    .when(pl.col(col).str.to_lowercase() == \"defense\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"offense\").then(1.0)\n                    .otherwise(\n                        pl.col(col).cast(pl.Float64, strict=False).fill_null(\n                            pl.col(col).hash() % 10000\n                        )\n                    ).cast(pl.Float64).alias(col)\n                )\n                expressions.append(expr)\n            else:\n                expressions.append(pl.col(col).cast(pl.Float64).alias(col))\n        \n        full_input = full_input.with_columns(expressions)\n        \n        # Sort by frame_id\n        if \"frame_id\" in full_input.columns:\n            full_input = full_input.sort([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n        \n        # Group into sequences\n        agg_exprs = [pl.col(c) for c in feature_cols]\n        self.input_sequences = full_input.group_by(\n            [\"game_id\", \"play_id\", \"nfl_id\"], \n            maintain_order=True\n        ).agg(agg_exprs)\n        \n        print(f\"Total sequences: {len(self.input_sequences)}\")\n        \n    def get_sequences(self):\n        \"\"\"Convert sequences to numpy arrays.\n        \n        Returns:\n            np.ndarray: Array of input sequences (object array)\n        \"\"\"\n        if self.input_sequences is None or self.input_sequences.is_empty():\n            return np.array([])\n        \n        print(\"Converting to NumPy arrays...\")\n        \n        # Get feature columns (exclude keys)\n        input_cols = [c for c in self.input_sequences.columns \n                     if c not in [\"game_id\", \"play_id\", \"nfl_id\"]]\n        \n        # Convert to sequences\n        input_col_indices = [self.input_sequences.columns.index(c) for c in input_cols]\n        rows = self.input_sequences.iter_rows()\n        \n        X_list = []\n        for row in rows:\n            feature_seqs = [row[i] for i in input_col_indices]\n            X_seq = list(zip(*feature_seqs))\n            X_list.append(X_seq)\n        \n        X = np.array(X_list, dtype=object)\n        print(f\"Loaded {len(X)} sequences\")\n        \n        return X\n\n\nclass UnsupervisedNFLSequence(Sequence):\n    \"\"\"Keras Sequence for unsupervised learning on NFL data.\n    \n    For autoencoder: input and output are the same (reconstruction)\n    For next-step prediction: input is sequence[:-n], output is sequence[n:]\n    \"\"\"\n    \n    def __init__(self, X, batch_size=32, maxlen=10, shuffle=True, \n                 task='autoencoder', prediction_steps=1):\n        \"\"\"Initialize the sequence.\n        \n        Args:\n            X: Input sequences\n            batch_size: Batch size\n            maxlen: Maximum sequence length (fixed to 10 by default)\n            shuffle: Whether to shuffle\n            task: 'autoencoder' or 'next_step'\n            prediction_steps: For next_step, how many steps ahead to predict\n        \"\"\"\n        self.X = X\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.task = task\n        self.prediction_steps = prediction_steps\n        self.indices = np.arange(len(self.X))\n        \n        # Fixed sequence length to 10\n        self.maxlen = 10\n        \n        print(f\"UnsupervisedNFLSequence initialized:\")\n        print(f\"  Samples: {len(self.X)}\")\n        print(f\"  Batch size: {batch_size}\")\n        print(f\"  Max length: {self.maxlen} (FIXED)\")\n        print(f\"  Task: {task}\")\n        \n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch_size))\n    \n    def __getitem__(self, idx):\n        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_X = [self.X[i] for i in batch_indices]\n        \n        if self.task == 'autoencoder':\n            # Input and output are the same (reconstruction task)\n            X_padded = pad_sequences(\n                batch_X,\n                maxlen=self.maxlen,\n                dtype='float32',\n                padding='post',\n                truncating='post',\n                value=0.0\n            )\n            return X_padded, X_padded\n            \n        elif self.task == 'next_step':\n            # Input: sequence up to -prediction_steps\n            # Output: last prediction_steps frames\n            batch_X_input = []\n            batch_y_output = []\n            \n            for seq in batch_X:\n                if len(seq) > self.prediction_steps:\n                    batch_X_input.append(seq[:-self.prediction_steps])\n                    batch_y_output.append(seq[-self.prediction_steps:])\n                else:\n                    # If sequence too short, use full sequence for both\n                    batch_X_input.append(seq)\n                    batch_y_output.append(seq)\n            \n            X_padded = pad_sequences(\n                batch_X_input,\n                maxlen=10,\n                dtype='float32',\n                padding='post',\n                truncating='post',\n                value=0.0\n            )\n            \n            y_padded = pad_sequences(\n                batch_y_output,\n                maxlen=10,\n                dtype='float32',\n                padding='post',\n                truncating='post',\n                value=0.0\n            )\n            \n            return X_padded, y_padded\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n\nif __name__ == \"__main__\":\n    # Test the loader\n    PREDICTION_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n    \n    print(\"=== Testing Unsupervised Data Loader ===\\n\")\n    \n    # Test 1: Load only unlabeled data\n    print(\"Test 1: Loading UNLABELED data only\")\n    loader = UnsupervisedNFLDataLoader()\n    loader.load_files([PREDICTION_TRAIN_DIR], include_labeled=False, include_unlabeled=True)\n    X_unlabeled = loader.get_sequences()\n    print(f\"Unlabeled sequences: {len(X_unlabeled)}\\n\")\n    \n    # Test 2: Load ALL data\n    print(\"Test 2: Loading ALL data (labeled + unlabeled)\")\n    loader_all = UnsupervisedNFLDataLoader()\n    loader_all.load_files([PREDICTION_TRAIN_DIR], include_labeled=True, include_unlabeled=True)\n    X_all = loader_all.get_sequences()\n    print(f\"Total sequences: {len(X_all)}\\n\")\n    \n    if len(X_all) > 0:\n        print(f\"Sample sequence length: {len(X_all[0])}\")\n        print(f\"Sample features per timestep: {len(X_all[0][0])}\")\n        \n        # Test sequence generators\n        print(\"\\n=== Testing Sequence Generators ===\")\n        \n        print(\"\\nAutoencoder sequence:\")\n        ae_seq = UnsupervisedNFLSequence(X_all[:1000], batch_size=32, task='autoencoder')\n        x_batch, y_batch = ae_seq[0]\n        print(f\"Input shape: {x_batch.shape}\")\n        print(f\"Output shape: {y_batch.shape}\")\n        print(f\"Are input and output same? {np.array_equal(x_batch, y_batch)}\")\n        \n        print(\"\\nNext-step prediction sequence:\")\n        ns_seq = UnsupervisedNFLSequence(X_all[:1000], batch_size=32, task='next_step', prediction_steps=5)\n        x_batch, y_batch = ns_seq[0]\n        print(f\"Input shape: {x_batch.shape}\")\n        print(f\"Output shape: {y_batch.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:19:09.030147Z","iopub.execute_input":"2025-11-26T08:19:09.030425Z","iopub.status.idle":"2025-11-26T08:20:34.116314Z","shell.execute_reply.started":"2025-11-26T08:19:09.030398Z","shell.execute_reply":"2025-11-26T08:20:34.115244Z"}},"outputs":[{"name":"stdout","text":"Collecting polars\n  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\nCollecting polars-runtime-32==1.35.2 (from polars)\n  Downloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nDownloading polars-1.35.2-py3-none-any.whl (783 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: polars-runtime-32, polars\nSuccessfully installed polars-1.35.2 polars-runtime-32-1.35.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting keras-tuner\n  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: keras in /usr/local/lib/python3.12/site-packages (from keras-tuner) (3.12.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from keras-tuner) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from keras-tuner) (2.32.5)\nCollecting kt-legacy (from keras-tuner)\n  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\nRequirement already satisfied: grpcio in /usr/local/lib/python3.12/site-packages (from keras-tuner) (1.76.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/site-packages (from keras-tuner) (6.33.0)\nRequirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/site-packages (from grpcio->keras-tuner) (4.15.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (2.3.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (2.3.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (0.1.0)\nRequirement already satisfied: h5py in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (3.15.1)\nRequirement already satisfied: optree in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (0.17.0)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/site-packages (from keras->keras-tuner) (0.5.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->keras-tuner) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->keras-tuner) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->keras-tuner) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->keras-tuner) (2025.10.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich->keras->keras-tuner) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich->keras->keras-tuner) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\nDownloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\nDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.4.8 kt-legacy-1.0.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"=== Testing Unsupervised Data Loader ===\n\nTest 1: Loading UNLABELED data only\nLoading unsupervised data from 1 directories...\nInclude labeled: False, Include unlabeled: True\n  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-prediction/train\n    input_2023_w01.csv: 285714 -> 209315 rows\n    input_2023_w02.csv: 288586 -> 212680 rows\n    input_2023_w03.csv: 297757 -> 217215 rows\n    input_2023_w04.csv: 272475 -> 201138 rows\n    input_2023_w05.csv: 254779 -> 185674 rows\n    input_2023_w06.csv: 270676 -> 198064 rows\n    input_2023_w07.csv: 233597 -> 169527 rows\n    input_2023_w08.csv: 281011 -> 205643 rows\n    input_2023_w09.csv: 252796 -> 187479 rows\n    input_2023_w10.csv: 260372 -> 191043 rows\n    input_2023_w11.csv: 243413 -> 178645 rows\n    input_2023_w12.csv: 294940 -> 218379 rows\n    input_2023_w13.csv: 233755 -> 168963 rows\n    input_2023_w14.csv: 279972 -> 204595 rows\n    input_2023_w15.csv: 281820 -> 205578 rows\n    input_2023_w16.csv: 316417 -> 231710 rows\n    input_2023_w17.csv: 277582 -> 203035 rows\n    input_2023_w18.csv: 254917 -> 188456 rows\nConcatenating dataframes...\nProcessing features...\nTotal sequences: 127105\nConverting to NumPy arrays...\nLoaded 127105 sequences\nUnlabeled sequences: 127105\n\nTest 2: Loading ALL data (labeled + unlabeled)\nLoading unsupervised data from 1 directories...\nInclude labeled: True, Include unlabeled: True\n  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-prediction/train\n    input_2023_w01.csv: 285714 -> 285714 rows\n    input_2023_w02.csv: 288586 -> 288586 rows\n    input_2023_w03.csv: 297757 -> 297757 rows\n    input_2023_w04.csv: 272475 -> 272475 rows\n    input_2023_w05.csv: 254779 -> 254779 rows\n    input_2023_w06.csv: 270676 -> 270676 rows\n    input_2023_w07.csv: 233597 -> 233597 rows\n    input_2023_w08.csv: 281011 -> 281011 rows\n    input_2023_w09.csv: 252796 -> 252796 rows\n    input_2023_w10.csv: 260372 -> 260372 rows\n    input_2023_w11.csv: 243413 -> 243413 rows\n    input_2023_w12.csv: 294940 -> 294940 rows\n    input_2023_w13.csv: 233755 -> 233755 rows\n    input_2023_w14.csv: 279972 -> 279972 rows\n    input_2023_w15.csv: 281820 -> 281820 rows\n    input_2023_w16.csv: 316417 -> 316417 rows\n    input_2023_w17.csv: 277582 -> 277582 rows\n    input_2023_w18.csv: 254917 -> 254917 rows\nConcatenating dataframes...\nProcessing features...\nTotal sequences: 173150\nConverting to NumPy arrays...\nLoaded 173150 sequences\nTotal sequences: 173150\n\nSample sequence length: 26\nSample features per timestep: 18\n\n=== Testing Sequence Generators ===\n\nAutoencoder sequence:\nUnsupervisedNFLSequence initialized:\n  Samples: 1000\n  Batch size: 32\n  Max length: 10 (FIXED)\n  Task: autoencoder\nInput shape: (32, 10, 18)\nOutput shape: (32, 10, 18)\nAre input and output same? True\n\nNext-step prediction sequence:\nUnsupervisedNFLSequence initialized:\n  Samples: 1000\n  Batch size: 32\n  Max length: 10 (FIXED)\n  Task: next_step\nInput shape: (32, 10, 18)\nOutput shape: (32, 10, 18)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Unsupervised models architectures","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n\nclass LSTMAutoencoder:\n    \"\"\"LSTM Autoencoder for unsupervised representation learning on NFL sequences.\n    \n    The encoder learns to compress player movement sequences into a latent representation,\n    and the decoder reconstructs the original sequence. The encoder can then be used\n    to initialize supervised models.\n    \"\"\"\n    \n    def __init__(self, input_shape, latent_dim=128, lstm_units=[512, 256, 128, 64, 32]):\n        \"\"\"Initialize the LSTM Autoencoder.\n        \n        Args:\n            input_shape: Shape of input (timesteps, features)\n            latent_dim: Dimension of latent representation\n            lstm_units: List of LSTM units for encoder layers\n        \"\"\"\n        self.input_shape = input_shape\n        self.latent_dim = latent_dim\n        self.lstm_units = lstm_units\n        self.encoder = None\n        self.decoder = None\n        self.autoencoder = None\n        \n    def build_encoder(self):\n        \"\"\"Build the encoder network.\"\"\"\n        inputs = layers.Input(shape=self.input_shape, name='encoder_input')\n        \n        x = inputs\n        # Stack LSTM layers\n        for i, units in enumerate(self.lstm_units[:-1]):\n            x = layers.LSTM(\n                units, \n                return_sequences=True,\n                name=f'encoder_lstm_{i+1}'\n            )(x)\n            x = layers.Dropout(0.2)(x)\n        \n        # Last LSTM layer doesn't return sequences\n        x = layers.LSTM(\n            self.lstm_units[-1],\n            return_sequences=False,\n            name=f'encoder_lstm_{len(self.lstm_units)}'\n        )(x)\n        x = layers.Dropout(0.2)(x)\n        \n        # Latent representation\n        latent = layers.Dense(self.latent_dim, activation='relu', name='latent')(x)\n        \n        self.encoder = Model(inputs, latent, name='encoder')\n        return self.encoder\n    \n    def build_decoder(self):\n        \"\"\"Build the decoder network.\"\"\"\n        # Decoder input is the latent vector\n        latent_inputs = layers.Input(shape=(self.latent_dim,), name='decoder_input')\n        \n        # Repeat the latent vector for each timestep\n        x = layers.RepeatVector(self.input_shape[0])(latent_inputs)\n        \n        # Stack LSTM layers in reverse\n        for i, units in enumerate(reversed(self.lstm_units)):\n            x = layers.LSTM(\n                units,\n                return_sequences=True,\n                name=f'decoder_lstm_{i+1}'\n            )(x)\n            x = layers.Dropout(0.2)(x)\n        \n        # Output layer to reconstruct features\n        outputs = layers.TimeDistributed(\n            layers.Dense(self.input_shape[1], activation='linear'),\n            name='reconstruction'\n        )(x)\n        \n        self.decoder = Model(latent_inputs, outputs, name='decoder')\n        return self.decoder\n    \n    def build_autoencoder(self):\n        \"\"\"Build the complete autoencoder.\"\"\"\n        if self.encoder is None:\n            self.build_encoder()\n        if self.decoder is None:\n            self.build_decoder()\n        \n        # Connect encoder and decoder\n        inputs = layers.Input(shape=self.input_shape, name='autoencoder_input')\n        latent = self.encoder(inputs)\n        outputs = self.decoder(latent)\n        \n        self.autoencoder = Model(inputs, outputs, name='autoencoder')\n        return self.autoencoder\n    \n    def compile(self, learning_rate=0.001):\n        \"\"\"Compile the autoencoder.\"\"\"\n        if self.autoencoder is None:\n            self.build_autoencoder()\n        \n        self.autoencoder.compile(\n            optimizer=keras.optimizers.Adam(learning_rate),\n            loss='mse',\n            metrics=['mae']\n        )\n        \n    def get_summary(self):\n        \"\"\"Print model summaries.\"\"\"\n        if self.autoencoder:\n            print(\"\\n=== Autoencoder Summary ===\")\n            self.autoencoder.summary()\n        if self.encoder:\n            print(\"\\n=== Encoder Summary ===\")\n            self.encoder.summary()\n        if self.decoder:\n            print(\"\\n=== Decoder Summary ===\")\n            self.decoder.summary()\n\n\nclass NextStepPredictor:\n    \"\"\"LSTM model for self-supervised next-step prediction.\n    \n    Predicts future timesteps given past timesteps, which can be used\n    as a pre-training task for the supervised trajectory prediction.\n    \"\"\"\n    \n    def __init__(self, input_shape, output_steps=5, lstm_units=[256, 128], output_features=None):\n        \"\"\"Initialize the next-step predictor.\n        \n        Args:\n            input_shape: Shape of input (timesteps, features)\n            output_steps: Number of future steps to predict\n            lstm_units: List of LSTM units\n            output_features: Number of output features (if None, same as input features)\n        \"\"\"\n        self.input_shape = input_shape\n        self.output_steps = output_steps\n        self.lstm_units = lstm_units\n        self.output_features = output_features or input_shape[1]\n        self.model = None\n        \n    def build(self):\n        \"\"\"Build the next-step prediction model.\"\"\"\n        inputs = layers.Input(shape=self.input_shape, name='input')\n        \n        x = inputs\n        # Stack LSTM layers\n        for i, units in enumerate(self.lstm_units):\n            return_seq = (i < len(self.lstm_units) - 1)\n            x = layers.LSTM(\n                units,\n                return_sequences=return_seq,\n                name=f'lstm_{i+1}'\n            )(x)\n            x = layers.Dropout(0.2)(x)\n        \n        # Prediction head\n        # Expand to output_steps timesteps\n        x = layers.RepeatVector(self.output_steps)(x)\n        x = layers.LSTM(128, return_sequences=True, name='prediction_lstm')(x)\n        \n        # Output for each timestep\n        outputs = layers.TimeDistributed(\n            layers.Dense(self.output_features, activation='linear'),\n            name='predictions'\n        )(x)\n        \n        self.model = Model(inputs, outputs, name='next_step_predictor')\n        return self.model\n    \n    def compile(self, learning_rate=0.001):\n        \"\"\"Compile the model.\"\"\"\n        if self.model is None:\n            self.build()\n        \n        self.model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate),\n            loss='mse',\n            metrics=['mae']\n        )\n    \n    def get_summary(self):\n        \"\"\"Print model summary.\"\"\"\n        if self.model:\n            self.model.summary()\n\n\ndef create_training_callbacks(model_path, patience=10):\n    \"\"\"Create standard callbacks for training.\n    \n    Args:\n        model_path: Path to save best model\n        patience: Patience for early stopping\n        \n    Returns:\n        List of callbacks\n    \"\"\"\n    callbacks = [\n        EarlyStopping(\n            monitor='val_loss',\n            patience=patience,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        ModelCheckpoint(\n            model_path,\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n    return callbacks\n\n\ndef transfer_encoder_weights(pretrained_encoder, supervised_model, freeze_encoder=False):\n    \"\"\"Transfer weights from pretrained encoder to supervised model.\n    \n    Args:\n        pretrained_encoder: The pretrained encoder model\n        supervised_model: The supervised model to transfer weights to\n        freeze_encoder: Whether to freeze the transferred weights\n        \n    Returns:\n        The supervised model with transferred weights\n    \"\"\"\n    print(\"\\n=== Transferring Encoder Weights ===\")\n    \n    # Get encoder layers from pretrained model\n    encoder_layer_names = [layer.name for layer in pretrained_encoder.layers]\n    \n    # Transfer weights to matching layers in supervised model\n    transferred_count = 0\n    for layer in supervised_model.layers:\n        if layer.name in encoder_layer_names:\n            try:\n                pretrained_layer = pretrained_encoder.get_layer(layer.name)\n                layer.set_weights(pretrained_layer.get_weights())\n                \n                if freeze_encoder:\n                    layer.trainable = False\n                \n                transferred_count += 1\n                print(f\"Transferred weights for layer: {layer.name} (frozen={freeze_encoder})\")\n            except Exception as e:\n                print(f\"Could not transfer weights for {layer.name}: {e}\")\n    \n    print(f\"\\nTransferred weights for {transferred_count} layers\")\n    return supervised_model\n\n\nif __name__ == \"__main__\":\n    print(\"=== Testing Unsupervised Models ===\\n\")\n    \n    # Test parameters\n    timesteps = 28\n    features = 18\n    latent_dim = 64\n    \n    print(\"1. Testing LSTM Autoencoder\")\n    print(\"-\" * 50)\n    ae = LSTMAutoencoder(\n        input_shape=(timesteps, features),\n        latent_dim=latent_dim,\n        lstm_units=[128, 64]\n    )\n    ae.build_autoencoder()\n    ae.compile()\n    ae.get_summary()\n    \n    print(\"\\n2. Testing Next-Step Predictor\")\n    print(\"-\" * 50)\n    predictor = NextStepPredictor(\n        input_shape=(timesteps, features),\n        output_steps=5,\n        lstm_units=[128, 64],\n        output_features=features\n    )\n    predictor.build()\n    predictor.compile()\n    predictor.get_summary()\n    \n    # Test with dummy data\n    print(\"\\n3. Testing with dummy data\")\n    print(\"-\" * 50)\n    dummy_input = tf.random.normal((32, timesteps, features))\n    \n    print(\"Autoencoder forward pass:\")\n    ae_output = ae.autoencoder(dummy_input)\n    print(f\"Input shape: {dummy_input.shape}\")\n    print(f\"Output shape: {ae_output.shape}\")\n    \n    print(\"\\nNext-step predictor forward pass:\")\n    ns_output = predictor.model(dummy_input)\n    print(f\"Input shape: {dummy_input.shape}\")\n    print(f\"Output shape: {ns_output.shape}\")\n    \n    print(\"\\nEncoder output (latent representation):\")\n    latent = ae.encoder(dummy_input)\n    print(f\"Latent shape: {latent.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:34.117068Z","iopub.execute_input":"2025-11-26T08:20:34.117462Z","iopub.status.idle":"2025-11-26T08:20:34.885884Z","shell.execute_reply.started":"2025-11-26T08:20:34.117443Z","shell.execute_reply":"2025-11-26T08:20:34.884948Z"}},"outputs":[{"name":"stdout","text":"=== Testing Unsupervised Models ===\n\n1. Testing LSTM Autoencoder\n--------------------------------------------------\n\n=== Autoencoder Summary ===\n","output_type":"stream"},{"name":"stderr","text":"2025-11-26 08:20:34.139034: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"autoencoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ autoencoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m128,832\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │       \u001b[38;5;34m134,162\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ autoencoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m262,994\u001b[0m (1.00 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,994</span> (1.00 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,994\u001b[0m (1.00 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,994</span> (1.00 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n=== Encoder Summary ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m75,264\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,832\u001b[0m (503.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> (503.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,832\u001b[0m (503.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,832</span> (503.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n=== Decoder Summary ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"decoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reconstruction                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m2,322\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reconstruction                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,162\u001b[0m (524.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> (524.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,162\u001b[0m (524.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,162</span> (524.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n2. Testing Next-Step Predictor\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"next_step_predictor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"next_step_predictor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m75,264\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ prediction_lstm (\u001b[38;5;33mLSTM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ predictions (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m)          │         \u001b[38;5;34m2,322\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ prediction_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,810\u001b[0m (882.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,810</span> (882.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,810\u001b[0m (882.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,810</span> (882.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n3. Testing with dummy data\n--------------------------------------------------\nAutoencoder forward pass:\nInput shape: (32, 28, 18)\nOutput shape: (32, 28, 18)\n\nNext-step predictor forward pass:\nInput shape: (32, 28, 18)\nOutput shape: (32, 5, 18)\n\nEncoder output (latent representation):\nLatent shape: (32, 64)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## unsupervised training","metadata":{}},{"cell_type":"code","source":"\"\"\"\nUnsupervised Pre-training Script for NFL Player Trajectory Prediction\n\nThis script performs unsupervised pre-training using LSTM autoencoders on all available\nNFL player sequences (both labeled and unlabeled). The pretrained encoder can then be\nused to initialize supervised models for better performance.\n\nUsage:\n    python unsupervised_pretraining.py --task autoencoder --epochs 50\n    python unsupervised_pretraining.py --task next_step --epochs 50\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nfrom datetime import datetime\n\n# Add parent directory to path\n# sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\n# from unsupervised_data_loader import UnsupervisedNFLDataLoader, UnsupervisedNFLSequence\n# from unsupervised_models import (\n#     LSTMAutoencoder, \n#     NextStepPredictor, \n#     create_training_callbacks\n# )\n\n\ndef train_autoencoder(train_seq, val_seq, epochs=50, latent_dim=128, model_save_path='autoencoder.keras'):\n    \"\"\"Train LSTM autoencoder for representation learning.\n    \n    Args:\n        train_seq: Training data sequence\n        val_seq: Validation data sequence\n        epochs: Number of training epochs\n        latent_dim: Dimension of latent space\n        model_save_path: Path to save the trained model\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING LSTM AUTOENCODER\")\n    print(\"=\"*70)\n    \n    # Get input shape from first batch\n    x_sample, _ = train_seq[0]\n    input_shape = (x_sample.shape[1], x_sample.shape[2])\n    \n    print(f\"\\nInput shape: {input_shape}\")\n    print(f\"Latent dimension: {latent_dim}\")\n    \n    # Build autoencoder\n    ae = LSTMAutoencoder(\n        input_shape=input_shape,\n        latent_dim=latent_dim,\n        lstm_units=[512, 256, 128, 64, 32]\n    )\n    ae.build_autoencoder()\n    ae.compile(learning_rate=0.0001)\n    \n    print(\"\\n\" + \"-\"*70)\n    ae.get_summary()\n    \n    # Create callbacks\n    callbacks = create_training_callbacks(model_save_path, patience=10)\n    \n    # Train\n    print(\"\\n\" + \"-\"*70)\n    print(\"Starting training...\")\n    print(\"-\"*70)\n    \n    history = ae.autoencoder.fit(\n        train_seq,\n        validation_data=val_seq,\n        epochs=epochs,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"Training completed!\")\n    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"Model saved to: {model_save_path}\")\n    print(\"=\"*70)\n    \n    # Save encoder separately\n    encoder_path = model_save_path.replace('.keras', '_encoder.keras')\n    ae.encoder.save(encoder_path)\n    print(f\"Encoder saved to: {encoder_path}\")\n    \n    return ae, history\n\n\ndef train_next_step_predictor(train_seq, val_seq, epochs=50, prediction_steps=5, \n                               model_save_path='next_step_predictor.keras'):\n    \"\"\"Train next-step predictor for self-supervised learning.\n    \n    Args:\n        train_seq: Training data sequence\n        val_seq: Validation data sequence\n        epochs: Number of training epochs\n        prediction_steps: Number of steps to predict ahead\n        model_save_path: Path to save the trained model\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING NEXT-STEP PREDICTOR\")\n    print(\"=\"*70)\n    \n    # Get input shape from first batch\n    x_sample, y_sample = train_seq[0]\n    input_shape = (x_sample.shape[1], x_sample.shape[2])\n    output_features = y_sample.shape[2]\n    \n    print(f\"\\nInput shape: {input_shape}\")\n    print(f\"Output steps: {prediction_steps}\")\n    print(f\"Output features: {output_features}\")\n    \n    # Build model\n    predictor = NextStepPredictor(\n        input_shape=input_shape,\n        output_steps=prediction_steps,\n        lstm_units=[256, 128],\n        output_features=output_features\n    )\n    predictor.build()\n    predictor.compile(learning_rate=0.001)\n    \n    print(\"\\n\" + \"-\"*70)\n    predictor.get_summary()\n    \n    # Create callbacks\n    callbacks = create_training_callbacks(model_save_path, patience=10)\n    \n    # Train\n    print(\"\\n\" + \"-\"*70)\n    print(\"Starting training...\")\n    print(\"-\"*70)\n    \n    history = predictor.model.fit(\n        train_seq,\n        validation_data=val_seq,\n        epochs=epochs,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"Training completed!\")\n    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"Model saved to: {model_save_path}\")\n    print(\"=\"*70)\n    \n    return predictor, history\n\n\n\n\ndef main():\n    \n    PREDICTION_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n    ANALYTICS_TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train'\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"UNSUPERVISED PRE-TRAINING FOR NFL PLAYER TRAJECTORY PREDICTION\")\n    print(\"=\"*70)\n    # print(f\"\\nTask: {args.task}\")\n    # print(f\"Epochs: {args.epochs}\")\n    # print(f\"Batch size: {args.batch_size}\")\n    # print(f\"Include labeled: {args.include_labeled}\")\n    # print(f\"Include unlabeled: {args.include_unlabeled}\")\n    # print(f\"Validation split: {args.val_split}\")\n    \n    # Load data\n    print(\"\\n\" + \"=\"*70)\n    print(\"LOADING DATA\")\n    print(\"=\"*70)\n    \n    loader = UnsupervisedNFLDataLoader()\n    loader.load_files(\n        [PREDICTION_TRAIN_DIR, ANALYTICS_TRAIN_DIR],\n        include_labeled=True,\n        include_unlabeled=True\n    )\n    X = loader.get_sequences()\n    \n    if len(X) == 0:\n        print(\"ERROR: No data loaded!\")\n        return\n    \n    print(f\"\\nTotal sequences loaded: {len(X)}\")\n    print(f\"Sample sequence length: {len(X[0])}\")\n    print(f\"Sample features: {len(X[0][0])}\")\n    \n    # Split into train/val\n    from sklearn.model_selection import train_test_split\n    \n    X_train, X_val = train_test_split(\n        X, \n        test_size=0.2, \n        random_state=42\n    )\n    \n    print(f\"\\nTraining sequences: {len(X_train)}\")\n    print(f\"Validation sequences: {len(X_val)}\")\n    \n    # Create data sequences based on task\n    print(\"\\n\" + \"=\"*70)\n    print(\"CREATING DATA GENERATORS\")\n    print(\"=\"*70)\n    \n    train_seq = UnsupervisedNFLSequence(\n        X_train,\n        batch_size=32,\n        maxlen=10,\n        shuffle=True,\n        task=\"autoencoder\",\n        prediction_steps=10\n    )\n    \n    val_seq = UnsupervisedNFLSequence(\n        X_val,\n        batch_size=32,\n        maxlen=10,\n        shuffle=False,\n        task=\"autoencoder\",\n        prediction_steps=10\n    )\n    \n    # Generate timestamp for model name\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    # Train based on task\n    model_path = os.path.join(\"/kaggle/working/\", f'autoencoder_{timestamp}.keras')\n    model, history = train_autoencoder(\n        train_seq, \n        val_seq, \n        epochs=100,\n        latent_dim=256,\n        model_save_path=model_path\n    )\n    \n    # model_path = os.path.join(args.output_dir, f'next_step_{timestamp}.keras')\n    # model, history = train_next_step_predictor(\n    #     train_seq,\n    #     val_seq,\n    #     epochs=args.epochs,\n    #     prediction_steps=args.prediction_steps,\n    #     model_save_path=model_path\n    # )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Final training loss: {history.history['loss'][-1]:.4f}\")\n    print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"\\nModel saved to: {model_path}\")\n    \n    encoder_path = model_path.replace('.keras', '_encoder.keras')\n    print(f\"Encoder saved to: {encoder_path}\")\n    print(\"\\nTo use the pretrained encoder in your supervised model:\")\n    print(f\"  from tensorflow import keras\")\n    print(f\"  from unsupervised_models import transfer_encoder_weights\")\n    print(f\"  pretrained_encoder = keras.models.load_model('{encoder_path}')\")\n    print(f\"  supervised_model = transfer_encoder_weights(pretrained_encoder, supervised_model)\")\n\n    print(\"=\"*70)\n    print(\"DONE!\")\n    print(\"=\"*70)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:34.886541Z","iopub.execute_input":"2025-11-26T08:20:34.886707Z","iopub.status.idle":"2025-11-26T09:36:36.133955Z","shell.execute_reply.started":"2025-11-26T08:20:34.886692Z","shell.execute_reply":"2025-11-26T09:36:36.132993Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nUNSUPERVISED PRE-TRAINING FOR NFL PLAYER TRAJECTORY PREDICTION\n======================================================================\n\n======================================================================\nLOADING DATA\n======================================================================\nLoading unsupervised data from 2 directories...\nInclude labeled: True, Include unlabeled: True\n  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-prediction/train\n    input_2023_w01.csv: 285714 -> 285714 rows\n    input_2023_w02.csv: 288586 -> 288586 rows\n    input_2023_w03.csv: 297757 -> 297757 rows\n    input_2023_w04.csv: 272475 -> 272475 rows\n    input_2023_w05.csv: 254779 -> 254779 rows\n    input_2023_w06.csv: 270676 -> 270676 rows\n    input_2023_w07.csv: 233597 -> 233597 rows\n    input_2023_w08.csv: 281011 -> 281011 rows\n    input_2023_w09.csv: 252796 -> 252796 rows\n    input_2023_w10.csv: 260372 -> 260372 rows\n    input_2023_w11.csv: 243413 -> 243413 rows\n    input_2023_w12.csv: 294940 -> 294940 rows\n    input_2023_w13.csv: 233755 -> 233755 rows\n    input_2023_w14.csv: 279972 -> 279972 rows\n    input_2023_w15.csv: 281820 -> 281820 rows\n    input_2023_w16.csv: 316417 -> 316417 rows\n    input_2023_w17.csv: 277582 -> 277582 rows\n    input_2023_w18.csv: 254917 -> 254917 rows\n  Found 18 input files in /kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train\n    input_2023_w01.csv: 285714 -> 285714 rows\n    input_2023_w02.csv: 288586 -> 288586 rows\n    input_2023_w03.csv: 297757 -> 297757 rows\n    input_2023_w04.csv: 272475 -> 272475 rows\n    input_2023_w05.csv: 254779 -> 254779 rows\n    input_2023_w06.csv: 270676 -> 270676 rows\n    input_2023_w07.csv: 233597 -> 233597 rows\n    input_2023_w08.csv: 281011 -> 281011 rows\n    input_2023_w09.csv: 252796 -> 252796 rows\n    input_2023_w10.csv: 260372 -> 260372 rows\n    input_2023_w11.csv: 243413 -> 243413 rows\n    input_2023_w12.csv: 294940 -> 294940 rows\n    input_2023_w13.csv: 233755 -> 233755 rows\n    input_2023_w14.csv: 279972 -> 279972 rows\n    input_2023_w15.csv: 281820 -> 281820 rows\n    input_2023_w16.csv: 316417 -> 316417 rows\n    input_2023_w17.csv: 277582 -> 277582 rows\n    input_2023_w18.csv: 254917 -> 254917 rows\nConcatenating dataframes...\nProcessing features...\nTotal sequences: 173150\nConverting to NumPy arrays...\nLoaded 173150 sequences\n\nTotal sequences loaded: 173150\nSample sequence length: 26\nSample features: 18\n\nTraining sequences: 138520\nValidation sequences: 34630\n\n======================================================================\nCREATING DATA GENERATORS\n======================================================================\nUnsupervisedNFLSequence initialized:\n  Samples: 138520\n  Batch size: 32\n  Max length: 10 (FIXED)\n  Task: autoencoder\nUnsupervisedNFLSequence initialized:\n  Samples: 34630\n  Batch size: 32\n  Max length: 10 (FIXED)\n  Task: autoencoder\n\n======================================================================\nTRAINING LSTM AUTOENCODER\n======================================================================\n\nInput shape: (10, 18)\nLatent dimension: 256\n\n----------------------------------------------------------------------\n\n=== Autoencoder Summary ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"autoencoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ autoencoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,142,336\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │     \u001b[38;5;34m2,139,026\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ autoencoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,139,026</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,281,362\u001b[0m (16.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,281,362</span> (16.33 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,281,362\u001b[0m (16.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,281,362</span> (16.33 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n=== Encoder Summary ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,087,488\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m8,448\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n=== Decoder Summary ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"decoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector_2 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m36,992\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,832\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m394,240\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,574,912\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reconstruction                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m9,234\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ repeat_vector_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reconstruction                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,234</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,139,026\u001b[0m (8.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,139,026</span> (8.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,139,026\u001b[0m (8.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,139,026</span> (8.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n----------------------------------------------------------------------\nStarting training...\n----------------------------------------------------------------------\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 8686537.8540 - mae: 1364.6222\nEpoch 1: val_loss improved from None to 8266713.50000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 103ms/step - loss: 8539652.0000 - mae: 1342.9291 - val_loss: 8266713.5000 - val_mae: 1307.7711 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 8125447.1317 - mae: 1293.0010\nEpoch 2: val_loss improved from 8266713.50000 to 7732307.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 103ms/step - loss: 7986655.5000 - mae: 1279.0676 - val_loss: 7732307.0000 - val_mae: 1253.2311 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 7602904.9029 - mae: 1240.7759\nEpoch 3: val_loss improved from 7732307.00000 to 7224278.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 103ms/step - loss: 7465897.0000 - mae: 1227.2473 - val_loss: 7224278.0000 - val_mae: 1203.3867 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 7089961.0628 - mae: 1190.1463\nEpoch 4: val_loss improved from 7224278.00000 to 6741403.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 103ms/step - loss: 6970690.0000 - mae: 1178.2688 - val_loss: 6741403.0000 - val_mae: 1155.0330 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 6601904.0917 - mae: 1140.6210\nEpoch 5: val_loss improved from 6741403.00000 to 6284318.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 103ms/step - loss: 6501050.0000 - mae: 1131.1565 - val_loss: 6284318.0000 - val_mae: 1110.3341 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 6167740.7546 - mae: 1099.3765\nEpoch 6: val_loss improved from 6284318.00000 to 5853231.50000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 103ms/step - loss: 6057460.0000 - mae: 1089.1307 - val_loss: 5853231.5000 - val_mae: 1071.2795 - learning_rate: 1.0000e-04\nEpoch 7/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 5735220.0085 - mae: 1060.7115\nEpoch 7: val_loss improved from 5853231.50000 to 5447275.50000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 103ms/step - loss: 5639112.0000 - mae: 1052.7201 - val_loss: 5447275.5000 - val_mae: 1036.6469 - learning_rate: 1.0000e-04\nEpoch 8/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 5352321.8778 - mae: 1028.4879\nEpoch 8: val_loss improved from 5447275.50000 to 5067007.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 103ms/step - loss: 5246643.0000 - mae: 1018.8520 - val_loss: 5067007.0000 - val_mae: 1003.4191 - learning_rate: 1.0000e-04\nEpoch 9/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4967616.6007 - mae: 994.3469\nEpoch 9: val_loss improved from 5067007.00000 to 4712259.00000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 103ms/step - loss: 4879477.0000 - mae: 986.3233 - val_loss: 4712259.0000 - val_mae: 971.5870 - learning_rate: 1.0000e-04\nEpoch 10/10\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4608422.5843 - mae: 961.3527\nEpoch 10: val_loss improved from 4712259.00000 to 4382553.50000, saving model to /kaggle/working/autoencoder_20251126_082108.keras\n\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 103ms/step - loss: 4537530.5000 - mae: 955.0665 - val_loss: 4382553.5000 - val_mae: 940.8353 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 10.\n\n======================================================================\nTraining completed!\nBest validation loss: 4382553.5000\nModel saved to: /kaggle/working/autoencoder_20251126_082108.keras\n======================================================================\nEncoder saved to: /kaggle/working/autoencoder_20251126_082108_encoder.keras\n\n======================================================================\nTRAINING SUMMARY\n======================================================================\nFinal training loss: 4537530.5000\nFinal validation loss: 4382553.5000\nBest validation loss: 4382553.5000\n\nModel saved to: /kaggle/working/autoencoder_20251126_082108.keras\nEncoder saved to: /kaggle/working/autoencoder_20251126_082108_encoder.keras\n\nTo use the pretrained encoder in your supervised model:\n  from tensorflow import keras\n  from unsupervised_models import transfer_encoder_weights\n  pretrained_encoder = keras.models.load_model('/kaggle/working/autoencoder_20251126_082108_encoder.keras')\n  supervised_model = transfer_encoder_weights(pretrained_encoder, supervised_model)\n======================================================================\nDONE!\n======================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Supervised dataloader","metadata":{}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import Sequence\n\nclass NFLDataLoader:\n    \"\"\"Loads and processes NFL Big Data Bowl 2026 data from CSV files using Polars.\n\n    This class handles the loading of input and output CSV files, filtering for\n    specific players, and aligning input sequences with their corresponding\n    output sequences based on game, play, and NFL IDs.\n\n    Attributes:\n        train_dir (str): The directory containing the training CSV files.\n        input_sequences (pl.DataFrame): DataFrame containing input sequences.\n        output_sequences (pl.DataFrame): DataFrame containing output sequences.\n    \"\"\"\n    def __init__(self, train_dir):\n        self.train_dir = train_dir\n        self.input_sequences = None\n        self.output_sequences = None\n\n    def load_input_files(self):\n        \"\"\"Loads and filters input CSV files from the training directory using Polars.\n\n        Iterates through files starting with 'input' and ending with '.csv'.\n        Filters rows where 'player_to_predict' is True and groups them by\n        (game_id, play_id, nfl_id) to form sequences.\n        \"\"\"\n        input_files = sorted([f for f in os.listdir(self.train_dir) if f.startswith('input') and f.endswith('.csv')])\n        print(f\"Loading and filtering {len(input_files)} Input files...\")\n        \n        dataframes = []\n        for input_file in input_files:\n            input_path = os.path.join(self.train_dir, input_file)\n            try:\n                # Lazy load for efficiency, though read_csv is fine for smaller files\n                # Using read_csv to ensure we catch errors immediately\n                df = pl.read_csv(input_path, infer_schema_length=10000)\n                \n                # Filter for player_to_predict == True (case insensitive)\n                if \"player_to_predict\" in df.columns:\n                    df = df.filter(\n                        pl.col(\"player_to_predict\").cast(pl.Utf8).str.to_lowercase() == \"true\"\n                    )\n                \n                if df.height > 0:\n                    dataframes.append(df)\n            except Exception as e:\n                print(f\"Error loading {input_file}: {e}\")\n\n        if not dataframes:\n            print(\"No valid input data found.\")\n            self.input_sequences = pl.DataFrame()\n            return\n\n        # Concatenate all input dataframes\n        full_df = pl.concat(dataframes, how=\"vertical_relaxed\")\n\n        # Process columns (Vectorized)\n        # Handle Booleans, Directions, Sides, etc.\n        \n        # Helper expression for boolean strings\n        def to_bool_float(col_name):\n            return (\n                pl.when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"true\").then(1.0)\n                .when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"false\").then(0.0)\n                .otherwise(0.0) # Default or handle errors\n            )\n\n        # Helper for direction\n        def to_dir_float(col_name):\n            return (\n                pl.when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"left\").then(0.0)\n                .when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"right\").then(1.0)\n                .otherwise(0.0)\n            )\n\n        # Helper for side\n        def to_side_float(col_name):\n            return (\n                pl.when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"defense\").then(0.0)\n                .when(pl.col(col_name).cast(pl.Utf8).str.to_lowercase() == \"offense\").then(1.0)\n                .otherwise(0.0)\n            )\n            \n        # Apply transformations\n        # We need to identify columns to transform. Based on previous code:\n        # Booleans: player_to_predict (already filtered, but maybe others?)\n        # Direction: play_direction? (Not explicitly named in previous code but handled in generic process_value)\n        # Side: player_side?\n        \n        # For generic handling, we can inspect types, but for performance, explicit is better.\n        # Let's assume standard columns or iterate if needed.\n        # The previous code iterated every cell. Here we want vectorization.\n        # We will cast all remaining columns to float, hashing strings if needed.\n        \n        # Identify ID columns to exclude from feature processing\n        id_cols = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"player_to_predict\", \"time\"]\n        feature_cols = [c for c in full_df.columns if c not in id_cols]\n        \n        expressions = []\n        for col in feature_cols:\n            # Check if column is string type\n            if full_df[col].dtype == pl.Utf8:\n                # Try specific conversions first\n                # We can't easily check content of every row efficiently without scanning\n                # So we apply a complex expression:\n                # If 'true'/'false' -> 1/0\n                # If 'left'/'right' -> 0/1\n                # If 'defense'/'offense' -> 0/1\n                # Else try cast float\n                # Else hash\n                \n                expr = (\n                    pl.when(pl.col(col).str.to_lowercase() == \"true\").then(1.0)\n                    .when(pl.col(col).str.to_lowercase() == \"false\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"left\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"right\").then(1.0)\n                    .when(pl.col(col).str.to_lowercase() == \"defense\").then(0.0)\n                    .when(pl.col(col).str.to_lowercase() == \"offense\").then(1.0)\n                    .otherwise(\n                        # Try cast to float, if null (failed), then hash\n                        pl.col(col).cast(pl.Float64, strict=False).fill_null(\n                            pl.col(col).hash() % 10000\n                        )\n                    ).cast(pl.Float64).alias(col)\n                )\n                expressions.append(expr)\n            else:\n                # Already numeric (int or float), cast to float\n                expressions.append(pl.col(col).cast(pl.Float64).alias(col))\n\n        # Select IDs and processed features\n        full_df = full_df.with_columns(expressions)\n        \n        # Group by keys and aggregate into lists\n        # We assume the order is defined by frame_id or file order. \n        # If frame_id exists, sort by it.\n        if \"frame_id\" in full_df.columns:\n            full_df = full_df.sort([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n        \n        # Group and aggregate features into lists\n        # We want a list of lists (sequence of steps, where each step is a list of features)\n        # Polars agg_list creates a list of values for a column.\n        # We need to combine these columns into a single \"features\" column which is a list of lists?\n        # Or just keep them as separate columns of lists.\n        # The previous code produced: [[f1, f2, ...], [f1, f2, ...], ...] for each sequence.\n        \n        # Let's aggregate each feature column into a list\n        agg_exprs = [pl.col(c) for c in feature_cols]\n        \n        grouped = full_df.group_by([\"game_id\", \"play_id\", \"nfl_id\"], maintain_order=True).agg(agg_exprs)\n        \n        # Now we have:\n        # game_id, play_id, nfl_id, col1_list, col2_list, ...\n        # We need to transpose this to:\n        # game_id, play_id, nfl_id, [[col1_t0, col2_t0, ...], [col1_t1, col2_t1, ...]]\n        # This is hard in Polars directly.\n        # Easier: Convert to numpy/pandas later or iterate.\n        \n        # Actually, for Keras, we usually want (samples, timesteps, features).\n        # If we have separate columns of lists:\n        # col1: [t0, t1, t2]\n        # col2: [t0, t1, t2]\n        # We can stack them.\n        \n        self.input_sequences = grouped\n\n    def load_output_files(self):\n        \"\"\"Loads output CSV files from the training directory using Polars.\n\n        Iterates through files starting with 'output' and ending with '.csv'.\n        Extracts 'x' and 'y' features, grouping them by (game_id, play_id, nfl_id)\n        to form sequences.\n        \"\"\"\n        output_files = sorted([f for f in os.listdir(self.train_dir) if f.startswith('output') and f.endswith('.csv')])\n        print(f\"Loading {len(output_files)} Output files...\")\n        \n        features_to_keep = ['x', 'y']\n        dataframes = []\n        \n        for output_file in output_files:\n            output_path = os.path.join(self.train_dir, output_file)\n            try:\n                df = pl.read_csv(output_path, columns=['game_id', 'play_id', 'nfl_id'] + features_to_keep, infer_schema_length=10000)\n                dataframes.append(df)\n            except Exception as e:\n                print(f\"Error loading {output_file}: {e}\")\n\n        if not dataframes:\n            print(\"No valid output data found.\")\n            self.output_sequences = pl.DataFrame()\n            return\n\n        full_df = pl.concat(dataframes, how=\"vertical_relaxed\")\n        \n        # Ensure float type\n        full_df = full_df.with_columns([\n            pl.col(c).cast(pl.Float64) for c in features_to_keep\n        ])\n        \n        # Sort if frame info is implicit (usually matches input)\n        # We don't have frame_id in output usually? Assuming same order.\n        # Ideally we should sort by something, but without frame_id we rely on file order.\n        \n        grouped = full_df.group_by([\"game_id\", \"play_id\", \"nfl_id\"], maintain_order=True).agg([\n            pl.col('x'),\n            pl.col('y')\n        ])\n        \n        self.output_sequences = grouped\n\n    def get_aligned_data(self):\n        \"\"\"Aligns input and output sequences based on common keys.\n\n        Loads both input and output files, finds the intersection of keys,\n        and creates aligned lists of sequences.\n\n        Returns:\n            tuple: A tuple containing:\n                - X (np.ndarray): Array of input sequences (object array).\n                - y (np.ndarray): Array of output sequences (object array).\n        \"\"\"\n        self.load_input_files()\n        self.load_output_files()\n\n        print(\"Aligning Input and Output sequences...\")\n        \n        if self.input_sequences is None or self.input_sequences.is_empty():\n            print(\"Input sequences empty.\")\n            return np.array([]), np.array([])\n            \n        if self.output_sequences is None or self.output_sequences.is_empty():\n            print(\"Output sequences empty.\")\n            return np.array([]), np.array([])\n\n        # Join on keys\n        # Inner join to keep only matching sequences\n        joined = self.input_sequences.join(\n            self.output_sequences, \n            on=[\"game_id\", \"play_id\", \"nfl_id\"], \n            how=\"inner\",\n            suffix=\"_out\"\n        )\n        \n        print(f\"Processing complete.\")\n        print(f\"Total Unique Sequences (Matches): {len(joined)}\")\n\n        if len(joined) == 0:\n            print(\"No matching data found.\")\n            return np.array([]), np.array([])\n\n        # Convert to the format expected by NFLDataSequence\n        # X: list of [ [f1, f2, ...], [f1, f2, ...] ]\n        # y: list of [ [x, y], [x, y] ... ]\n        \n        # The joined dataframe has columns:\n        # game_id, play_id, nfl_id, feat1_list, feat2_list, ..., x_list, y_list\n        \n        # We need to identify feature columns vs output columns\n        # Output columns are 'x' and 'y' (from output_sequences, might be renamed if collision)\n        # Actually, input also has 'x' and 'y' usually.\n        # In load_output_files, we aggregated 'x' and 'y'.\n        # In load_input_files, we aggregated all features.\n        # If input has 'x', 'y', they will collide.\n        # The join suffix=\"_out\" handles this. Output cols will be 'x_out', 'y_out'.\n        \n        # Input feature columns: all columns from input_sequences except keys\n        input_cols = [c for c in self.input_sequences.columns if c not in [\"game_id\", \"play_id\", \"nfl_id\"]]\n        output_cols = [\"x_out\" if \"x\" in input_cols else \"x\", \"y_out\" if \"y\" in input_cols else \"y\"]\n        \n        # Check if output cols exist\n        if output_cols[0] not in joined.columns:\n            # Maybe input didn't have x/y, so no suffix\n            output_cols = [\"x\", \"y\"]\n            \n        # Convert to numpy\n        # This is the heavy part.\n        # We can iterate rows or use map_elements?\n        # Ideally we want to stack the feature lists.\n        \n        # Let's extract input features as a list of arrays\n        # Each row i has [feat1_seq, feat2_seq, ...]\n        # We want [[feat1_t0, feat2_t0], [feat1_t1, feat2_t1], ...]\n        \n        # Efficient way:\n        # 1. Convert relevant columns to a dict of lists or similar\n        # 2. Iterate and stack\n        \n        print(\"Converting to NumPy arrays...\")\n        \n        # Extract input data\n        # shape: (n_samples, n_features, n_timesteps) roughly, but variable timesteps\n        # We want (n_samples, n_timesteps, n_features)\n        \n        # Get all input feature lists as a list of lists of lists?\n        # joined.select(input_cols).to_dict(as_series=False) gives {col: [seq1, seq2...]}\n        \n        # This might be memory intensive.\n        # Let's try row iteration with a generator or list comp\n        \n        # Pre-fetch column indices for speed\n        input_col_indices = [joined.columns.index(c) for c in input_cols]\n        output_col_indices = [joined.columns.index(c) for c in output_cols]\n        \n        rows = joined.iter_rows()\n        \n        X_list = []\n        y_list = []\n        \n        for row in rows:\n            # Input\n            # row[i] is a list of values for feature i for this sequence\n            # We want to stack them: [[val_0_0, val_1_0...], [val_0_1, val_1_1...]]\n            # Zip is useful here\n            \n            # Get all feature sequences for this row\n            feature_seqs = [row[i] for i in input_col_indices]\n            # feature_seqs is [ [t0, t1...], [t0, t1...] ... ] (n_features, n_timesteps)\n            # We want (n_timesteps, n_features)\n            # zip(*feature_seqs) does exactly this transpose\n            \n            # Note: Polars lists might be None if empty? Assuming data is clean.\n            # Also assuming all feature lists have same length (they should if from same rows)\n            \n            X_seq = list(zip(*feature_seqs))\n            X_list.append(X_seq)\n            \n            # Output\n            out_seqs = [row[i] for i in output_col_indices]\n            y_seq = list(zip(*out_seqs))\n            y_list.append(y_seq)\n            \n        X = np.array(X_list, dtype=object)\n        y = np.array(y_list, dtype=object)\n        \n        print(f\"Initial X shape: {X.shape}\")\n        print(f\"Initial y shape: {y.shape}\")\n            \n        return X, y\n\n\nclass NFLDataSequence(Sequence):\n    \"\"\"Keras Sequence for NFL data with automatic padding of variable-length sequences.\n\n    Inherits from `tensorflow.keras.utils.Sequence` to provide a data generator\n    that can be used with Keras models. Handles batching, shuffling, and\n    padding of sequences to a uniform length.\n    \"\"\"\n    def __init__(self, X, y, batch_size=32, maxlen_x=None, maxlen_y=None, shuffle=True):\n        \"\"\"Initializes the NFLDataSequence.\n\n        Args:\n            X (list or np.ndarray): List of input sequences, where each sequence\n                is a list of time steps.\n            y (list or np.ndarray): List of output sequences, where each sequence\n                is a list of time steps.\n            batch_size (int, optional): Number of samples per batch. Defaults to 32.\n            maxlen_x (int, optional): Maximum length for input sequences. If None,\n                it is calculated from the data. Defaults to None.\n            maxlen_y (int, optional): Maximum length for output sequences. If None,\n                it is calculated from the data. Defaults to None.\n            shuffle (bool, optional): Whether to shuffle the data at the end of\n                each epoch. Defaults to True.\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indices = np.arange(len(self.X))\n        \n        # Determine max lengths if not provided\n        if maxlen_x is None:\n            self.maxlen_x = max(len(seq) for seq in X)\n        else:\n            self.maxlen_x = maxlen_x\n            \n        if maxlen_y is None:\n            self.maxlen_y = max(len(seq) for seq in y)\n        else:\n            self.maxlen_y = maxlen_y\n        \n        print(f\"NFLDataSequence initialized: {len(self.X)} samples, batch_size={batch_size}\")\n        print(f\"Max sequence lengths - X: {self.maxlen_x}, y: {self.maxlen_y}\")\n        \n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def __len__(self):\n        \"\"\"Computes the number of batches per epoch.\n\n        Returns:\n            int: The number of batches.\n        \"\"\"\n        return int(np.ceil(len(self.X) / self.batch_size))\n    \n    def __getitem__(self, idx):\n        \"\"\"Generates one batch of data.\n\n        Args:\n            idx (int): The index of the batch.\n\n        Returns:\n            tuple: A tuple (X_padded, y_padded) containing the padded input and\n                output sequences for the batch.\n        \"\"\"\n        # Get batch indices\n        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        # Get batch data\n        batch_X = [self.X[i] for i in batch_indices]\n        batch_y = [self.y[i] for i in batch_indices]\n        \n        # Process X sequences: handle mixed types\n        # With Polars preprocessing, data should already be numeric floats\n        # But let's ensure it's a list of lists of floats\n        \n        # batch_X is a list of sequences. Each sequence is a list of frames. Each frame is a list of features.\n        # We need to convert this to a 3D numpy array or list of 2D arrays for pad_sequences\n        \n        # Since we did the conversion in get_aligned_data, batch_X elements should be lists of tuples/lists of floats.\n        # We can directly pass this to pad_sequences if they are numeric.\n        \n        # Use pad_sequences for both X and y\n        # pad_sequences expects sequences of shape (n_samples, n_timesteps) for 2D\n        # For 3D (n_samples, n_timesteps, n_features), we need to pad manually or use padding='post'\n        \n        # Method: Pad each sequence to maxlen, filling with zeros\n        X_padded = pad_sequences(\n            batch_X, \n            maxlen=self.maxlen_x, \n            dtype='float32',\n            padding='post',\n            truncating='post',\n            value=0.0\n        )\n        \n        y_padded = pad_sequences(\n            batch_y,\n            maxlen=self.maxlen_y,\n            dtype='float32',\n            padding='post',\n            truncating='post',\n            value=0.0\n        )\n        \n        return X_padded, y_padded\n    \n    def on_epoch_end(self):\n        \"\"\"Updates indexes after each epoch.\n\n        If `self.shuffle` is True, the data indices are shuffled to ensure\n        random batch composition in the next epoch.\n        \"\"\"\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n\ndef create_tf_datasets(X, y, test_size=0.2, batch_size=32, maxlen_x=10, maxlen_y=10):\n    \"\"\"Splits data into training and validation sets and creates Keras Sequence datasets.\n\n    Uses `train_test_split` to divide the data and then wraps the resulting\n    sets in `NFLDataSequence` objects, which handle padding and batching.\n\n    Args:\n        X (np.ndarray): Input data (object array of variable-length sequences).\n        y (np.ndarray): Output data (object array of variable-length sequences).\n        test_size (float, optional): Proportion of the dataset to include in the\n            validation split. Defaults to 0.2.\n        batch_size (int, optional): Batch size for the datasets. Defaults to 32.\n        maxlen_x (int, optional): Maximum length for input sequences. If None,\n            auto-detects from the training set. Defaults to 10.\n        maxlen_y (int, optional): Maximum length for output sequences. If None,\n            auto-detects from the training set. Defaults to 10.\n\n    Returns:\n        tuple: A tuple containing:\n            - train_sequence (NFLDataSequence): The training data sequence.\n            - val_sequence (NFLDataSequence): The validation data sequence.\n            Returns (None, None) if an error occurs.\n    \"\"\"\n    print(\"\\n--- Creating Keras Sequence Datasets with Padding ---\")\n    \n    try:\n        # Convert object arrays to lists\n        X_list = X.tolist()\n        y_list = y.tolist()\n        \n        # Split into train and validation\n        print(f\"Splitting data (test_size={test_size})...\")\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_list, y_list, \n            test_size=test_size, \n            random_state=42\n        )\n        \n        print(f\"Train size: {len(X_train)}\")\n        print(f\"Val size: {len(X_val)}\")\n        \n        # Create Sequence objects\n        print(\"Creating Training Sequence...\")\n        train_sequence = NFLDataSequence(\n            X_train, y_train, \n            batch_size=batch_size,\n            maxlen_x=maxlen_x,\n            maxlen_y=maxlen_y,\n            shuffle=True\n        )\n        \n        print(\"Creating Validation Sequence...\")\n        val_sequence = NFLDataSequence(\n            X_val, y_val,\n            batch_size=batch_size,\n            maxlen_x=train_sequence.maxlen_x,  # Use same max lengths as training\n            maxlen_y=train_sequence.maxlen_y,\n            shuffle=False\n        )\n        \n        print(\"Sequences created successfully.\")\n        print(f\"Training batches per epoch: {len(train_sequence)}\")\n        print(f\"Validation batches per epoch: {len(val_sequence)}\")\n        \n        return train_sequence, val_sequence\n\n    except Exception as e:\n        print(f\"Error creating Keras sequences: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None, None\n\nif __name__ == \"__main__\":\n    TRAIN_DIR = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n    \n    loader = NFLDataLoader(TRAIN_DIR)\n    X, y = loader.get_aligned_data()\n\n    print(\"\\n--- Final Data Shapes ---\")\n    print(f\"X (Input) Shape: {X.shape}\")\n    print(f\"y (Output) Shape: {y.shape}\")\n\n    if len(X) > 0:\n        print(f\"Sample Input Sequence Length: {len(X[0])}\")\n        print(f\"Sample Output Sequence Length: {len(y[0])}\")\n\n    # Create Keras Sequences with padding\n    train_seq, val_seq = create_tf_datasets(X, y, batch_size=32)\n    \n    if train_seq:\n        print(\"\\nVerifying Sequence Element:\")\n        # Get one batch to verify shapes\n        x_batch, y_batch = train_seq[0]\n        print(f\"Batch X shape: {x_batch.shape}\")\n        print(f\"Batch y shape: {y_batch.shape}\")\n        print(f\"Max sequence lengths - X: {train_seq.maxlen_x}, y: {train_seq.maxlen_y}\")\n\n    print(\"\\nData loading, alignment, and sequence creation complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:50.141291Z","iopub.execute_input":"2025-11-26T09:37:50.141579Z","iopub.status.idle":"2025-11-26T09:38:00.022608Z","shell.execute_reply.started":"2025-11-26T09:37:50.141559Z","shell.execute_reply":"2025-11-26T09:38:00.021392Z"}},"outputs":[{"name":"stdout","text":"Loading and filtering 18 Input files...\nLoading 18 Output files...\nAligning Input and Output sequences...\nProcessing complete.\nTotal Unique Sequences (Matches): 46045\nConverting to NumPy arrays...\nInitial X shape: (46045,)\nInitial y shape: (46045,)\n\n--- Final Data Shapes ---\nX (Input) Shape: (46045,)\ny (Output) Shape: (46045,)\nSample Input Sequence Length: 26\nSample Output Sequence Length: 21\n\n--- Creating Keras Sequence Datasets with Padding ---\nSplitting data (test_size=0.2)...\nTrain size: 36836\nVal size: 9209\nCreating Training Sequence...\nNFLDataSequence initialized: 36836 samples, batch_size=32\nMax sequence lengths - X: 10, y: 10\nCreating Validation Sequence...\nNFLDataSequence initialized: 9209 samples, batch_size=32\nMax sequence lengths - X: 10, y: 10\nSequences created successfully.\nTraining batches per epoch: 1152\nValidation batches per epoch: 288\n\nVerifying Sequence Element:\nBatch X shape: (32, 10, 18)\nBatch y shape: (32, 10, 2)\nMax sequence lengths - X: 10, y: 10\n\nData loading, alignment, and sequence creation complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Supervised keras-tuner","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport sys\nimport keras_tuner\n\n# Add the manual_data_processing directory to the path\n# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'manual_data_processing'))\n\n# from csv_to_numpy import NFLDataLoader, create_tf_datasets\n\n\ndef build_model(hp):\n    \"\"\"\n    Builds a compiled Keras LSTM model with hyperparameters to be experimented on.\n\n    This function defines the architecture of the LSTM model for sequence-to-sequence prediction.\n    It incorporates hyperparameter search spaces for key model parameters like learning rate,\n    number of LSTM units, kernel regularization, and activation functions.\n\n    Args:\n        hp (keras_tuner.HyperParameters): An instance of Keras Tuner's HyperParameters class,\n                                          used to define the search space for hyperparameters.\n\n    Returns:\n        keras.Model: The compiled Keras LSTM model with hyperparameters set by Keras Tuner.\n    \"\"\"\n    \n    SEED = 42\n    # Define hyperparameter search spaces for tuning\n    learning_rate = hp.Float(\"lr\", min_value=1e-7, max_value=1e-3, sampling=\"log\")\n    layer_u = hp.Int(\"lu\", min_value=160, max_value=1024, step=8)\n    kernel_r = hp.Float(\"kr\", min_value=1e-10, max_value=1e-5, sampling=\"log\")\n    acti_f = hp.Choice(\"af\", [\"sigmoid\", \"hard_sigmoid\", \"tanh\", \"relu\", \"softmax\", \"linear\"])\n    weight_d = hp.Float(\"wd\", min_value=1e-10, max_value=0.0009, sampling=\"log\")\n\n    # Define the model structure using Keras Sequential API\n    model = keras.Sequential([\n        # Input layer\n        keras.layers.Input(shape=(input_seq_length, input_features)),\n        \n        # Encoder LSTM layers\n        keras.layers.LSTM(\n            units=layer_u,\n            activation=acti_f,\n            return_sequences=True,\n            kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n            seed=SEED,\n        ),\n        keras.layers.LSTM(\n            units=layer_u // 2,\n            activation=acti_f,\n            return_sequences=True,\n            kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n            seed=SEED,\n        ),\n        keras.layers.LSTM(\n            units=layer_u // 2,\n            activation=acti_f,\n            return_sequences=True,\n            kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n            seed=SEED,\n        ),\n        keras.layers.LSTM(\n            units=layer_u // 2,\n            activation=acti_f,\n            return_sequences=True,\n            kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n            seed=SEED,\n        ),\n        keras.layers.LSTM(\n            units=layer_u // 2,\n            activation=acti_f,\n            return_sequences=False,\n            kernel_regularizer=keras.regularizers.L2(l2=kernel_r),\n            seed=SEED,\n        ),\n        layers.RepeatVector(output_seq_length),\n        keras.layers.LSTM(\n            units=32,\n            activation=\"sigmoid\",\n            return_sequences=True,\n            # kernel_regularizer=keras.regularizers.L2(l2=0.00000195),\n            seed=SEED,\n        ),\n        # Crop or slice to match output sequence length\n        # layers.Lambda(lambda x: x[:, :output_seq_length, :]),\n        # TimeDistributed dense layer for output features\n        layers.TimeDistributed(\n            keras.layers.Dense(units=output_features, activation=\"linear\")\n        ),\n    ])\n\n    # Compile the model with a tunable optimizer and metrics\n    model.compile(\n        loss=keras.losses.MeanSquaredError(),\n        optimizer=keras.optimizers.Adam(\n            learning_rate=learning_rate,\n            global_clipnorm=1,\n            amsgrad=False,\n            # weight_decay=weight_d, # Tunable weight decay\n        ),\n        metrics=[tf.keras.metrics.MeanAbsoluteError()],\n    )\n\n    return model\n\n\ndef experimenting(training_dataset, validation_data):\n    \"\"\"\n    Runs Keras Tuner experiments for the LSTM model using the RandomSearch algorithm.\n\n    This function initializes a `RandomSearch` tuner with the `build_model` function,\n    configures the search objective (minimizing validation loss), and then executes\n    the hyperparameter search across the defined search spaces. It prints summaries\n    of the search space and the results.\n\n    Args:\n        training_dataset: NFLDataSequence object for training data\n        validation_data: NFLDataSequence object for validation data\n\n    \"\"\"\n\n    hp = keras_tuner.HyperParameters()\n    \n    # Get a batch from the sequence to determine shapes\n    x_batch, y_batch = training_dataset[0]\n    global input_features, input_seq_length, output_seq_length, output_features\n    input_seq_length = x_batch.shape[1]\n    input_features = x_batch.shape[2]\n    output_seq_length = y_batch.shape[1]\n    output_features = y_batch.shape[2]\n    \n    print(f\"\\nDetected shapes:\")\n    print(f\"  Input: ({input_seq_length}, {input_features})\")\n    print(f\"  Output: ({output_seq_length}, {output_features})\")\n    \n    build_model(hp) # Instantiate a dummy model to build the search space\n\n    # Initialize Keras Tuner's RandomSearch algorithm\n    tuner = keras_tuner.RandomSearch(\n        hypermodel=build_model,\n        max_trials=100, # Maximum number of hyperparameter combinations to try\n        objective=keras_tuner.Objective(\"val_loss\", \"min\"),   # Objective is to minimize validation loss\n        executions_per_trial=1, # Number of models to train for each trial (1 for efficiency)\n        overwrite=True, # Overwrite previous results in the directory\n        directory=os.getenv(\"KERAS_TUNER_EXPERIMENTS_DIR\", \"/kaggle/working/tuner_results\"), # Directory to save experiment logs and checkpoints\n        project_name=\"nfl_prediction\", # Name of the Keras Tuner project\n        seed = 42,\n        max_consecutive_failed_trials=5,\n    )\n\n    tuner.search_space_summary() # Print a summary of the hyperparameter search space\n\n    # NFLDataSequence is already batched, no need to call batch() again\n    # Run the hyperparameter search experiments\n    tuner.search(\n        training_dataset, \n        validation_data=validation_data, \n        epochs=5\n    )\n\n    tuner.results_summary() # Print a summary of the best performing trials\n\n\nif __name__ == \"__main__\":\n    train_dir = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n    batch_size = 32\n    epochs = 50\n    test_size = 0.2\n    \n    print(\"=\"*60)\n    print(\"NFL Big Data Bowl 2026 - Predictor Training\")\n    print(\"=\"*60)\n    \n    # Load and prepare data\n    print(\"\\n[1/4] Loading data from CSV files...\")\n    loader = NFLDataLoader(train_dir)\n    X, y = loader.get_aligned_data()\n    \n    if len(X) == 0:\n        print(\"Error: No data loaded. Please check the data directory.\")\n    \n    print(f\"\\nData Summary:\")\n    print(f\"  Total sequences: {len(X)}\")\n    print(f\"  Sample input sequence length: {len(X[0])}\")\n    print(f\"  Sample output sequence length: {len(y[0])}\")\n    print(f\"  Input features per timestep: {len(X[0][0]) if len(X[0]) > 0 else 0}\")\n    print(f\"  Output features per timestep: {len(y[0][0]) if len(y[0]) > 0 else 0}\")\n    \n    # Create Keras Sequences with padding\n    print(f\"\\n[2/4] Creating training and validation sequences (test_size={test_size})...\")\n    train_seq, val_seq = create_tf_datasets(X, y, test_size=test_size, batch_size=batch_size)\n    \n    # Run the hyperparameter experimentation\n    experimenting(train_seq, val_seq)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T04:32:10.631345Z","iopub.execute_input":"2025-11-26T04:32:10.631764Z","execution_failed":"2025-11-26T04:52:12.825Z"}},"outputs":[{"name":"stdout","text":"Trial 2 Complete [00h 09m 19s]\nval_loss: 2090.77001953125\n\nBest val_loss So Far: 1955.6044921875\nTotal elapsed time: 00h 12m 11s\n\nSearch: Running Trial #3\n\nValue             |Best Value So Far |Hyperparameter\n0.00081926        |3.6117e-05        |lr\n696               |192               |lu\n3.7001e-06        |1.1033e-08        |kr\nsigmoid           |hard_sigmoid      |af\n0.00052148        |0.00015039        |wd\n\nEpoch 1/5\n\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 116ms/step - loss: 1616.4753 - mean_absolute_error: 31.7516 - val_loss: 1165.9841 - val_mean_absolute_error: 26.4632\nEpoch 2/5\n\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 116ms/step - loss: 889.1203 - mean_absolute_error: 23.0944 - val_loss: 653.6121 - val_mean_absolute_error: 19.9865\nEpoch 3/5\n\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 116ms/step - loss: 572.7606 - mean_absolute_error: 18.6430 - val_loss: 547.8101 - val_mean_absolute_error: 18.1746\nEpoch 4/5\n\u001b[1m 510/1152\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 106ms/step - loss: 542.4927 - mean_absolute_error: 18.0890","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Supervised model training","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport sys\n\n# Add the manual_data_processing directory to the path\n# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'manual_data_processing'))\n\n# from csv_to_numpy import NFLDataLoader, create_tf_datasets\n\ndef build_seq2seq_model(input_seq_length, input_features, output_seq_length, output_features, lstm_units=128):\n    \"\"\"\n    Builds a sequence-to-sequence model with LSTM layers.\n\n    Args:\n        input_seq_length (int): The length of input sequences (time steps).\n        input_features (int): The number of input features per timestep.\n        output_seq_length (int): The length of output sequences (time steps).\n        output_features (int): The number of output features per timestep.\n        lstm_units (int): The number of units in the LSTM layers.\n\n    Returns:\n        keras.Model: The compiled Keras model.\n    \"\"\"\n\n    SEED = 42\n    # Encoder-decoder architecture for sequence-to-sequence prediction\n    # model = keras.Sequential([\n    #     # Input layer\n    #     keras.layers.Input(shape=(input_seq_length, input_features)),\n        \n    #     # Encoder LSTM layers\n    #     keras.layers.LSTM(\n    #         units=696,\n    #         activation=\"sigmoid\",\n    #         return_sequences=True,\n    #         kernel_regularizer=keras.regularizers.L2(l2=3.7001e-06),\n    #         seed=SEED,\n    #     ),\n    inputs = layers.Input(shape=(input_seq_length, input_features), name='encoder_input')\n    \n    x = inputs\n    # Stack LSTM layers\n\n    x = layers.LSTM(\n        512, \n        return_sequences=True,\n        name=\"encoder_lstm_1\"\n    )(x)\n    x = layers.Dropout(0.2, name=\"dropout_6\")(x)\n\n    x = layers.LSTM(\n        256, \n        return_sequences=True,\n        name=\"encoder_lstm_2\"\n    )(x)\n    x = layers.Dropout(0.2, name=\"dropout_7\")(x)\n\n    x = layers.LSTM(\n        128, \n        return_sequences=True,\n        name=\"encoder_lstm_3\"\n    )(x)\n    x = layers.Dropout(0.2, name=\"dropout_8\")(x)\n\n    x = layers.LSTM(\n        64, \n        return_sequences=True,\n        name=\"encoder_lstm_4\"\n    )(x)\n    x = layers.Dropout(0.2, name=\"dropout_9\")(x)\n\n    # Last LSTM layer doesn't return sequences\n    x = layers.LSTM(\n        32,\n        return_sequences=False,\n        name=\"encoder_lstm_5\"\n    )(x)\n    x = layers.Dropout(0.2, name=\"dropout_10\")(x)\n    \n    # Latent representation\n    latent = layers.Dense(256, activation='relu', name='latent')(x)\n    \n    model = Model(inputs, latent, name='encoder')\n\n    cosine_decay = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=415000,\n    alpha=1e-5,\n    )\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.00081926),\n        loss='mse',\n        metrics=['mae']\n    )\n    \n    return model\n\ndef train_model(model, train_sequence, val_sequence, epochs=10, callbacks=None):\n    \"\"\"\n    Trains the Keras model using Keras Sequence objects.\n    \n    Args:\n        model: The Keras model to train\n        train_sequence: Training data sequence (NFLDataSequence)\n        val_sequence: Validation data sequence (NFLDataSequence)\n        epochs (int): Number of training epochs\n        callbacks: List of Keras callbacks\n    \n    Returns:\n        history: Training history object\n    \"\"\"\n    pretrained_encoder = keras.models.load_model('/kaggle/working/autoencoder_20251126_082108_encoder.keras')\n    supervised_model = transfer_encoder_weights(pretrained_encoder, model)\n    print(\"pretrained encoder\")\n    pretrained_encoder.summary()\n    print(\"supervised model\")\n    supervised_model.summary()\n    if callbacks is None:\n        callbacks = []\n    \n    # Add early stopping and model checkpoint callbacks\n    early_stopping = keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    )\n    \n    model_checkpoint = keras.callbacks.ModelCheckpoint(\n        'best_model.keras',\n        monitor='val_loss',\n        save_best_only=True,\n        verbose=1\n    )\n    \n    callbacks.extend([early_stopping, model_checkpoint])\n    \n    print(\"Starting model training...\")\n    history = supervised_model.fit(\n        train_sequence,\n        epochs=epochs,\n        validation_data=val_sequence,\n        callbacks=model_checkpoint,\n        verbose=1\n    )\n    print(\"Model training finished.\")\n    return history\n\ndef main():\n    \"\"\"\n    Main function to load data, build, and train the model.\n    \"\"\"\n    # Configuration\n    train_dir = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n    batch_size = 32\n    epochs = 20\n    test_size = 0.2\n    \n    print(\"=\"*60)\n    print(\"NFL Big Data Bowl 2026 - Predictor Training\")\n    print(\"=\"*60)\n    \n    # Load and prepare data\n    print(\"\\n[1/4] Loading data from CSV files...\")\n    loader = NFLDataLoader(train_dir)\n    X, y = loader.get_aligned_data()\n    \n    if len(X) == 0:\n        print(\"Error: No data loaded. Please check the data directory.\")\n        return\n    \n    print(f\"\\nData Summary:\")\n    print(f\"  Total sequences: {len(X)}\")\n    print(f\"  Sample input sequence length: {len(X[0])}\")\n    print(f\"  Sample output sequence length: {len(y[0])}\")\n    print(f\"  Input features per timestep: {len(X[0][0]) if len(X[0]) > 0 else 0}\")\n    print(f\"  Output features per timestep: {len(y[0][0]) if len(y[0]) > 0 else 0}\")\n    \n    # Create Keras Sequences with padding\n    print(f\"\\n[2/4] Creating training and validation sequences (test_size={test_size})...\")\n    train_seq, val_seq = create_tf_datasets(X, y, test_size=test_size, batch_size=batch_size)\n    \n    if train_seq is None:\n        print(\"Error: Failed to create training sequences.\")\n        return\n    \n    # Get one batch to determine shapes\n    x_sample, y_sample = train_seq[0]\n    input_seq_length = x_sample.shape[1]\n    input_features = x_sample.shape[2]\n    output_seq_length = y_sample.shape[1]\n    output_features = y_sample.shape[2]\n    \n    print(f\"\\nSequence Shapes:\")\n    print(f\"  Input: (batch_size, {input_seq_length}, {input_features})\")\n    print(f\"  Output: (batch_size, {output_seq_length}, {output_features})\")\n    \n    # Build model\n    print(f\"\\n[3/4] Building sequence-to-sequence model...\")\n    model = build_seq2seq_model(\n        input_seq_length=input_seq_length,\n        input_features=input_features,\n        output_seq_length=output_seq_length,\n        output_features=output_features,\n        lstm_units=128\n    )\n    \n    print(\"\\nModel Architecture:\")\n    model.summary()\n    \n    # Train model\n    print(f\"\\n[4/4] Training model for {epochs} epochs...\")\n    history = train_model(model, train_seq, val_seq, epochs=epochs)\n    \n    # Save the final model\n    final_model_path = 'nfl_predictor_final.keras'\n    model.save(final_model_path)\n    print(f\"\\n{'='*60}\")\n    print(f\"Training Complete!\")\n    print(f\"Final model saved to: {final_model_path}\")\n    print(f\"Best model saved to: best_model.keras\")\n    print(f\"{'='*60}\")\n    \n    # Print training summary\n    print(f\"\\nTraining Summary:\")\n    print(f\"  Final training loss: {history.history['loss'][-1]:.4f}\")\n    print(f\"  Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n    print(f\"  Final training MAE: {history.history['mae'][-1]:.4f}\")\n    print(f\"  Final validation MAE: {history.history['val_mae'][-1]:.4f}\")\n    print(f\"  Best validation loss: {min(history.history['val_loss']):.4f}\")\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:19:11.563471Z","iopub.execute_input":"2025-11-26T10:19:11.563717Z","iopub.status.idle":"2025-11-26T10:19:21.740531Z","shell.execute_reply.started":"2025-11-26T10:19:11.563700Z","shell.execute_reply":"2025-11-26T10:19:21.739362Z"}},"outputs":[{"name":"stdout","text":"============================================================\nNFL Big Data Bowl 2026 - Predictor Training\n============================================================\n\n[1/4] Loading data from CSV files...\nLoading and filtering 18 Input files...\nLoading 18 Output files...\nAligning Input and Output sequences...\nProcessing complete.\nTotal Unique Sequences (Matches): 46045\nConverting to NumPy arrays...\nInitial X shape: (46045,)\nInitial y shape: (46045,)\n\nData Summary:\n  Total sequences: 46045\n  Sample input sequence length: 26\n  Sample output sequence length: 21\n  Input features per timestep: 18\n  Output features per timestep: 2\n\n[2/4] Creating training and validation sequences (test_size=0.2)...\n\n--- Creating Keras Sequence Datasets with Padding ---\nSplitting data (test_size=0.2)...\nTrain size: 36836\nVal size: 9209\nCreating Training Sequence...\nNFLDataSequence initialized: 36836 samples, batch_size=32\nMax sequence lengths - X: 10, y: 10\nCreating Validation Sequence...\nNFLDataSequence initialized: 9209 samples, batch_size=32\nMax sequence lengths - X: 10, y: 10\nSequences created successfully.\nTraining batches per epoch: 1152\nValidation batches per epoch: 288\n\nSequence Shapes:\n  Input: (batch_size, 10, 18)\n  Output: (batch_size, 10, 2)\n\n[3/4] Building sequence-to-sequence model...\n\nModel Architecture:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,087,488\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m8,448\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n[4/4] Training model for 20 epochs...\n\n=== Transferring Encoder Weights ===\nTransferred weights for layer: encoder_input (frozen=False)\nTransferred weights for layer: encoder_lstm_1 (frozen=False)\nTransferred weights for layer: dropout_6 (frozen=False)\nTransferred weights for layer: encoder_lstm_2 (frozen=False)\nTransferred weights for layer: dropout_7 (frozen=False)\nTransferred weights for layer: encoder_lstm_3 (frozen=False)\nTransferred weights for layer: dropout_8 (frozen=False)\nTransferred weights for layer: encoder_lstm_4 (frozen=False)\nTransferred weights for layer: dropout_9 (frozen=False)\nTransferred weights for layer: encoder_lstm_5 (frozen=False)\nTransferred weights for layer: dropout_10 (frozen=False)\nTransferred weights for layer: latent (frozen=False)\n\nTransferred weights for 12 layers\npretrained encoder\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,087,488\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m8,448\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"supervised model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,087,488\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m8,448\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,488</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,142,336\u001b[0m (8.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,336</span> (8.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Starting model training...\nEpoch 1/20\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 236\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Best validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(history.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 216\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[4/4] Training model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epochs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[32m    219\u001b[39m final_model_path = \u001b[33m'\u001b[39m\u001b[33mnfl_predictor_final.keras\u001b[39m\u001b[33m'\u001b[39m\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_sequence, val_sequence, epochs, callbacks)\u001b[39m\n\u001b[32m    139\u001b[39m callbacks.extend([early_stopping, model_checkpoint])\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting model training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m history = \u001b[43msupervised_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    148\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel training finished.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/keras/src/losses/losses.py:1763\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m   1761\u001b[39m y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n\u001b[32m   1762\u001b[39m y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.mean(ops.square(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis=-\u001b[32m1\u001b[39m)\n","\u001b[31mValueError\u001b[39m: Dimensions must be equal, but are 2 and 256 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, encoder_1/latent_1/Relu)' with input shapes: [?,10,2], [?,256]."],"ename":"ValueError","evalue":"Dimensions must be equal, but are 2 and 256 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, encoder_1/latent_1/Relu)' with input shapes: [?,10,2], [?,256].","output_type":"error"}],"execution_count":10}]}