{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8085e128",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2026 - Submission Notebook\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides the inference pipeline for the NFL Big Data Bowl 2026 Prediction Track. It loads a pre-trained Keras model to predict player trajectory coordinates (x, y) given contextual play information.\n",
    "\n",
    "### Workflow\n",
    "1. **Environment Setup**: Configure Protobuf and import all required libraries.\n",
    "2. **Model Loading**: Lazy-load the trained Keras model on first inference call.\n",
    "3. **Preprocessing**: Transform raw input data to match the feature engineering used during training.\n",
    "4. **Inference**: Generate (x, y) coordinate predictions for each player in a play.\n",
    "5. **Kaggle Integration**: Expose the [predict](cci:1://file:///home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/src/manual_data_processing/unsupervised_pretraining.py:98:0-163:29) function via the Kaggle NFL Inference Server.\n",
    "\n",
    "### Key Compatibility Notes\n",
    "- **Protobuf**: The `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION` environment variable must be set to `'python'` *before* any TensorFlow imports to avoid version conflicts on Kaggle.\n",
    "- **Feature Consistency**: The preprocessing logic **must** exactly match the training pipeline (`csv_to_keras_sequence.py`) to avoid train-serve skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ecd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kaggle_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 244\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m inference_server \u001b[38;5;241m=\u001b[39m \u001b[43mkaggle_evaluation\u001b[49m\u001b[38;5;241m.\u001b[39mnfl_inference_server\u001b[38;5;241m.\u001b[39mNFLInferenceServer(predict)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAGGLE_IS_COMPETITION_RERUN\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    247\u001b[0m     inference_server\u001b[38;5;241m.\u001b[39mserve()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kaggle_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Set environment variables BEFORE any imports to fix Protobuf conflicts\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Import TensorFlow FIRST to avoid Protobuf version conflicts\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Now import other libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import zlib\n",
    "# import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "# =================================================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =================================================================================================\n",
    "## 1. Configuration\n",
    "'''\n",
    "This section defines all configurable parameters for the inference pipeline. Modify these values to point to your trained model and normalization statistics.\n",
    "\n",
    "| Parameter        | Description                                                               |\n",
    "|------------------|---------------------------------------------------------------------------|\n",
    "| `MODEL_PATH`     | Absolute path to the trained `.keras` model file.                         |\n",
    "| `ID_COLUMNS`     | Columns to exclude from features (identifiers, not predictive signals).   |\n",
    "| `MAX_SEQ_LENGTH` | Maximum input sequence length (must match training).                      |\n",
    "| `MEAN` / `STD`   | Per-feature normalization statistics from training (optional but recommended). |\n",
    "'''\n",
    "\n",
    "MODEL_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/trained_models/fine_tuned_encoder_60_epochs_submission_6.keras'\n",
    "\n",
    "# ID columns to EXCLUDE (matching csv_to_keras_sequence.py)\n",
    "ID_COLUMNS = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'player_to_predict', 'time']\n",
    "\n",
    "# Maximum sequence length (matching training data)\n",
    "MAX_SEQ_LENGTH = 10\n",
    "\n",
    "# Normalization Statistics\n",
    "# IMPORTANT: Replace these with the actual mean and std from your training data!\n",
    "# These must be numpy arrays of shape (18,) matching the feature columns.\n",
    "MEAN = None \n",
    "STD = None\n",
    "\n",
    "# Global Model Variable\n",
    "model = None\n",
    "\n",
    "'''\n",
    "---\n",
    "## 2. Model Management\n",
    "\n",
    "The model is loaded lazilyâ€”only when the first prediction is requested. This\n",
    "avoids unnecessary memory usage if the notebook cell is run but no\n",
    "predictions are made (e.g., during development). The loaded model is cached\n",
    "in a global variable to prevent redundant disk reads.\n",
    "'''\n",
    "\n",
    "def load_model_if_needed():\n",
    "    \"\"\"Lazily loads the Keras model into global memory.\n",
    "    This function implements a singleton pattern for the model. It checks if\n",
    "    the global `model` variable is None, and if so, loads the model from\n",
    "    `MODEL_PATH`. Subsequent calls return instantly.\n",
    "    This approach minimizes startup time and memory usage in development,\n",
    "    while ensuring the model is ready before the first prediction.\n",
    "    Raises:\n",
    "        Exception: If the model file cannot be loaded (e.g., file not found,\n",
    "            corrupted file, or incompatible TensorFlow version).\n",
    "    Returns:\n",
    "        tf.keras.Model: The loaded Keras model instance.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    if model is None:\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"Model loaded successfully.\")\n",
    "            print(f\"Model expects input shape: {model.input_shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "## 3. Feature Preprocessing\n",
    "\n",
    "These functions transform raw input data into the numerical format expected by the model. \n",
    "\n",
    "### Critical Requirement: Train-Serve Consistency\n",
    "The preprocessing logic here **must be identical** to the logic used in `csv_to_keras_sequence.py` during training. Any discrepancy will cause a distribution shift between training and inference data, degrading model performance. \n",
    "\n",
    "### Processing Pipeline\n",
    "1. **Type Conversion**: Convert booleans, categorical strings, and dates to floats.\n",
    "2. **String Hashing**: Unknown string values are hashed using `zlib.adler32` for a deterministic numeric representation.\n",
    "3. **Feature Selection**: Only non-ID columns are used as features.\n",
    "4. **Sequence Padding**: Variable-length sequences are padded to `MAX_SEQ_LENGTH`.\n",
    "5. **Normalization**: Features are standardized using pre-computed `MEAN` and `STD` (if provided).\n",
    "'''\n",
    "\n",
    "def process_value(val):\n",
    "    \"\"\"Converts a single value to a float, matching training preprocessing.\n",
    "    This function handles the type conversion for individual cell values\n",
    "    from the input DataFrame. It is designed to exactly replicate the\n",
    "    feature engineering performed in `csv_to_keras_sequence.py`.\n",
    "    Conversion Rules:\n",
    "        - None: 0.0\n",
    "        - bool: True -> 1.0, False -> 0.0\n",
    "        - int/float: Cast to float\n",
    "        - str 'true'/'false': 1.0 / 0.0\n",
    "        - str 'left'/'right': 0.0 / 1.0 (direction encoding)\n",
    "        - str 'defense'/'offense': 0.0 / 1.0 (team side encoding)\n",
    "        - str (numeric): Parsed as float\n",
    "        - str (other): Hashed to integer using zlib.adler32 modulo 10000\n",
    "    Args:\n",
    "        val: The value to convert. Can be any type.\n",
    "    Returns:\n",
    "        float: The numeric representation of the input value.\n",
    "    \"\"\"\n",
    "    # Handle None/null values\n",
    "    if val is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Handle Booleans\n",
    "    if isinstance(val, bool):\n",
    "        return 1.0 if val else 0.0\n",
    "    \n",
    "    # Handle numeric types\n",
    "    if isinstance(val, (int, float)):\n",
    "        return float(val)\n",
    "    \n",
    "    # Handle string values\n",
    "    if isinstance(val, str):\n",
    "        val_lower = val.lower()\n",
    "        \n",
    "        # Booleans\n",
    "        if val_lower == 'true':\n",
    "            return 1.0\n",
    "        if val_lower == 'false':\n",
    "            return 0.0\n",
    "        \n",
    "        # Direction\n",
    "        if val_lower == 'left':\n",
    "            return 0.0\n",
    "        if val_lower == 'right':\n",
    "            return 1.0\n",
    "        \n",
    "        # Player Side\n",
    "        if val_lower == 'defense':\n",
    "            return 0.0\n",
    "        if val_lower == 'offense':\n",
    "            return 1.0\n",
    "        \n",
    "        # Try to parse as number\n",
    "        try:\n",
    "            return float(val_lower)\n",
    "        except ValueError:\n",
    "            # Hash the string using zlib.adler32 to match training\n",
    "            return float(zlib.adler32(val.encode('utf-8')) % 10000)\n",
    "    \n",
    "    # Fallback: hash any other type\n",
    "    return float(zlib.adler32(str(val).encode('utf-8')) % 10000)\n",
    "\n",
    "\n",
    "def preprocess(test_df, test_input_df):\n",
    "    \"\"\"Transforms raw input DataFrames into model-ready feature tensors.\n",
    "    This function replicates the full preprocessing pipeline from training,\n",
    "    ensuring feature consistency between training and inference. It performs:\n",
    "    1. DataFrame conversion (Pandas -> Polars if needed)\n",
    "    2. Vectorized type casting and categorical encoding\n",
    "    3. Per-player sequence extraction\n",
    "    4. Zero-padding to `MAX_SEQ_LENGTH`\n",
    "    5. Optional normalization with `MEAN` and `STD`\n",
    "    Args:\n",
    "        test_df (pl.DataFrame | pd.DataFrame): Metadata for the prediction\n",
    "            request. Contains `game_id`, `play_id`, and `nfl_id` to identify\n",
    "            which player's trajectory to predict.\n",
    "        test_input_df (pl.DataFrame | pd.DataFrame): Context data for the play.\n",
    "            Contains time-series features for all players in the play.\n",
    "    Returns:\n",
    "        np.ndarray: A 3D NumPy array of shape [(batch_size, MAX_SEQ_LENGTH, 18)](cci:1://file:///home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/src/manual_data_processing/unsupervised_pretraining.py:166:0-316:17)\n",
    "            containing the preprocessed and padded feature sequences. `batch_size`\n",
    "            equals the number of rows in `test_df`.\n",
    "    \"\"\"\n",
    "    # Convert to Polars if needed\n",
    "    if not isinstance(test_df, pl.DataFrame):\n",
    "        test_df = pl.from_pandas(test_df.to_pandas() if hasattr(test_df, 'to_pandas') else test_df)\n",
    "            \n",
    "    if not isinstance(test_input_df, pl.DataFrame):\n",
    "        test_input_df = pl.from_pandas(test_input_df.to_pandas() if hasattr(test_input_df, 'to_pandas') else test_input_df)\n",
    "    \n",
    "    # Get feature columns (all columns EXCEPT ID columns)\n",
    "    all_columns = test_input_df.columns\n",
    "    feature_cols = [col for col in all_columns if col not in ID_COLUMNS]\n",
    "    \n",
    "    # Process features using vectorized Polars operations\n",
    "    expressions = []\n",
    "    for col in feature_cols:\n",
    "        if test_input_df[col].dtype == pl.Utf8:\n",
    "            # Handle string columns\n",
    "            expr = (\n",
    "                pl.when(pl.col(col).str.to_lowercase() == \"true\").then(1.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"false\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"left\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"right\").then(1.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"defense\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"offense\").then(1.0)\n",
    "                .otherwise(\n",
    "                    pl.col(col).cast(pl.Float64, strict=False).fill_null(\n",
    "                        pl.col(col).map_elements(lambda x: float(zlib.adler32(x.encode('utf-8')) % 10000) if x else 0.0, return_dtype=pl.Float64)\n",
    "                    )\n",
    "                ).cast(pl.Float64).alias(col)\n",
    "            )\n",
    "            expressions.append(expr)\n",
    "        else:\n",
    "            # Numeric columns\n",
    "            expressions.append(pl.col(col).cast(pl.Float64).fill_null(0.0).alias(col))\n",
    "    \n",
    "    # Apply all transformations\n",
    "    test_input_df = test_input_df.with_columns(expressions)\n",
    "    \n",
    "    # Build sequences\n",
    "    sequences = []\n",
    "    \n",
    "    for row in test_df.iter_rows(named=True):\n",
    "        # Filter for this specific player\n",
    "        player_data = test_input_df.filter(\n",
    "            (pl.col('game_id') == row['game_id']) &\n",
    "            (pl.col('play_id') == row['play_id']) &\n",
    "            (pl.col('nfl_id') == row['nfl_id'])\n",
    "        )\n",
    "        \n",
    "        # Filter for player_to_predict == True (matching training data)\n",
    "        if 'player_to_predict' in test_input_df.columns:\n",
    "            player_data = player_data.filter(\n",
    "                (pl.col('player_to_predict') == 1.0) | \n",
    "                (pl.col('player_to_predict').cast(pl.Utf8).str.to_lowercase() == 'true')\n",
    "            )\n",
    "        \n",
    "        if len(player_data) == 0:\n",
    "            # Fallback: create zero sequence\n",
    "            seq = np.zeros((1, len(feature_cols)), dtype=np.float32)\n",
    "        else:\n",
    "            # Sort by frame_id\n",
    "            if 'frame_id' in player_data.columns:\n",
    "                player_data = player_data.sort('frame_id')\n",
    "            \n",
    "            # Select ONLY feature columns (excludes ID columns)\n",
    "            seq = player_data.select(feature_cols).to_numpy().astype(np.float32)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    \n",
    "    # Pad sequences to MAX_SEQ_LENGTH\n",
    "    X_padded = pad_sequences(\n",
    "        sequences,\n",
    "        maxlen=MAX_SEQ_LENGTH,\n",
    "        dtype='float32',\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        value=0.0\n",
    "    )\n",
    "    \n",
    "    # Normalize if stats are available\n",
    "    if MEAN is not None and STD is not None:\n",
    "        X_padded = (X_padded - MEAN) / STD\n",
    "    \n",
    "    return X_padded\n",
    "\n",
    "\n",
    "'''\n",
    "## 4. Inference\n",
    "\n",
    "The [predict](cci:1://file:///home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/src/manual_data_processing/unsupervised_pretraining.py:98:0-163:29) function is the main entry point called by the Kaggle evaluation server. It orchestrates the full inference flow:\n",
    "1. Ensures the model is loaded.\n",
    "2. Preprocesses the input DataFrames.\n",
    "3. Runs the model forward pass.\n",
    "4. Formats the output for submission.\n",
    "\n",
    "### Output Handling\n",
    "The model outputs a 3D tensor of shape [(batch_size, sequence_length, 2)]\n",
    "(cci:1://file:///home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/\n",
    "src/manual_data_processing/unsupervised_pretraining.py:166:0-316:17). Since\n",
    " the competition expects a single (x, y) prediction per player, we extract\n",
    "  the prediction from the **last timestep** of each sequence.\n",
    "'''\n",
    "\n",
    "\n",
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"Generates (x, y) trajectory predictions for a batch of players.\n",
    "    This is the main entry point called by the Kaggle NFL Inference Server.\n",
    "    It orchestrates model loading, preprocessing, and inference.\n",
    "    The model outputs a sequence of predictions. To produce a single (x, y)\n",
    "    prediction per player, the **last timestep** of each output sequence\n",
    "    is selected.\n",
    "    Args:\n",
    "        test_df (pl.DataFrame | pd.DataFrame): Prediction request metadata.\n",
    "            Each row specifies a unique (game_id, play_id, nfl_id) combination\n",
    "            for which a prediction is required.\n",
    "        test_input_df (pl.DataFrame | pd.DataFrame): Contextual tracking data\n",
    "            for the play, including positions, velocities, and player attributes.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with two columns:\n",
    "            - 'x': Predicted x-coordinate on the field.\n",
    "            - 'y': Predicted y-coordinate on the field.\n",
    "            The number of rows matches the number of rows in `test_df`.\n",
    "    \"\"\"\n",
    "    load_model_if_needed()\n",
    "    \n",
    "    # Preprocess\n",
    "    features = preprocess(test_df, test_input_df)\n",
    "    \n",
    "    # Run inference\n",
    "    if len(features) > 32:\n",
    "        predictions_xy = model.predict(features, batch_size=32, verbose=0)\n",
    "    else:\n",
    "        predictions_xy = model(features, training=False).numpy()\n",
    "    \n",
    "    # Handle 3D output (batch_size, time_steps, features)\n",
    "    # The model returns a sequence of predictions, take the last timestep\n",
    "    if len(predictions_xy.shape) == 3:\n",
    "        predictions_xy = predictions_xy[:, -1, :]\n",
    "    \n",
    "    # Ensure we have exactly 2 features (x, y)\n",
    "    if predictions_xy.shape[1] != 2:\n",
    "        predictions_xy = predictions_xy[:, :2]  # Take first 2 columns\n",
    "    \n",
    "    # Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n",
    "\n",
    "# =================================================================================================\n",
    "# INFERENCE SERVER (ENTRY POINT)\n",
    "# =================================================================================================\n",
    "\n",
    "'''\n",
    "## 5. Kaggle Inference Server Integration\n",
    "\n",
    "This section initializes the `NFLInferenceServer` provided by the\n",
    "`kaggle_evaluation` package. \n",
    "\n",
    "- **Competition Rerun**: When the notebook runs in the Kaggle competition \n",
    "environment (`KAGGLE_IS_COMPETITION_RERUN` is set), the server listens for \n",
    "incoming prediction requests.\n",
    "- **Local Testing**: For local development, the `run_local_gateway` method \n",
    "simulates the server using local data files.\n",
    "\n",
    "> **Note**: On local machines without the `kaggle_evaluation` package \n",
    "installed, this section will raise an error. This is expected and does not \n",
    "affect model development.\n",
    "'''\n",
    "if __name__==\"__main__\":\n",
    "    pass\n",
    "\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # For local testing\n",
    "    inference_server.run_local_gateway((\n",
    "        '/kaggle/input/nfl-big-data-bowl-2026-prediction/',\n",
    "    ))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
