{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Import TensorFlow first to avoid Protobuf version conflicts with other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 1: LOCAL DATA LOADING (FOR DEBUGGING & DEVELOPMENT ONLY)\n",
    "# =================================================================================================\n",
    "# The code in this section is NOT part of the standard submission template.\n",
    "# It is used to load data locally using the 'Load_dataframe_manual' module for testing purposes.\n",
    "# This allows you to inspect the data and verify the preprocessing logic before submitting.\n",
    "# =================================================================================================\n",
    "\n",
    "# # Add current directory to path to find the custom module\n",
    "# sys.path.append(os.getcwd())\n",
    "\n",
    "# # Define paths for local testing files\n",
    "# TEST_INPUT_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/test_input.csv'\n",
    "# TEST_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/test.csv'\n",
    "\n",
    "# test_input_df_manual = None\n",
    "# test_df_manual = None\n",
    "\n",
    "# try:\n",
    "#     from Load_dataframe_manual import load_dataframe\n",
    "#     print(\"--- Local Data Loading ---\")\n",
    "#     print(f\"Attempting to load test data from:\\n {TEST_INPUT_PATH}\\n {TEST_PATH}\")\n",
    "    \n",
    "#     # Load DataFrames manually\n",
    "#     test_input_df_manual = load_dataframe(TEST_INPUT_PATH)\n",
    "#     test_df_manual = load_dataframe(TEST_PATH)\n",
    "#     print(\"Local data loaded successfully.\")\n",
    "    \n",
    "# except ImportError:\n",
    "#     print(\"Module 'Load_dataframe_manual' not found. Skipping local data loading.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during local data loading: {e}\")\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 2: SUBMISSION CODE (REQUIRED)\n",
    "# =================================================================================================\n",
    "# The following code implements the logic required for the Kaggle submission.\n",
    "# It includes model loading, data preprocessing, and the prediction function.\n",
    "# =================================================================================================\n",
    "\n",
    "# Constants\n",
    "MODEL_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/trained_models/nfl_23_input_validation loss_ 118.4529.keras'\n",
    "\n",
    "# Columns expected by the model (matching training data from csv_to_numpy.py)\n",
    "COLUMN_ORDER = [\n",
    "    'game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', \n",
    "    'play_direction', 'absolute_yardline_number', 'player_name', \n",
    "    'player_height', 'player_weight', 'player_birth_date', 'player_position', \n",
    "    'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', \n",
    "    'num_frames_output', 'ball_land_x', 'ball_land_y'\n",
    "]\n",
    "\n",
    "# Global Model Variable\n",
    "model = None\n",
    "\n",
    "def load_model_if_needed():\n",
    "    \"\"\"\n",
    "    Loads the Keras model if it hasn't been loaded yet.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    if model is None:\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "    return model\n",
    "\n",
    "def process_value(val):\n",
    "    \"\"\"\n",
    "    Converts a single value into the appropriate type for the model.\n",
    "    Matches the logic used in 'csv_to_numpy.py' during training.\n",
    "    \"\"\"\n",
    "    # Handle Booleans (including numpy/pandas bool types)\n",
    "    if isinstance(val, (bool, np.bool_)):\n",
    "        return 1.0 if val else 0.0\n",
    "        \n",
    "    if isinstance(val, (int, float, np.number)):\n",
    "        return float(val)\n",
    "        \n",
    "    val_str = str(val).lower()\n",
    "\n",
    "    # Handle Booleans (string representation)\n",
    "    if val_str == 'true':\n",
    "        return 1.0\n",
    "    if val_str == 'false':\n",
    "        return 0.0\n",
    "    \n",
    "    # Handle Direction (left/right)\n",
    "    if val_str == 'left':\n",
    "        return 0.0\n",
    "    if val_str == 'right':\n",
    "        return 1.0\n",
    "\n",
    "    # Handle Player Side (defense/offense)\n",
    "    if val_str == 'defense':\n",
    "        return 0.0\n",
    "    if val_str == 'offense':\n",
    "        return 1.0\n",
    "    \n",
    "    # Handle Numbers (Integers and Floats in string format)\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        pass\n",
    "        \n",
    "    # Handle Strings (Object type) - hashing\n",
    "    # This matches the fallback in NFLDataSequence\n",
    "    return float(hash(str(val)) % 10000)\n",
    "\n",
    "def preprocess(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the input dataframes into the format expected by the model.\n",
    "    1. Converts Polars to Pandas (if needed).\n",
    "    2. Filters for the specific player and play.\n",
    "    3. Extracts features in the correct order.\n",
    "    4. Pads sequences to create a batch.\n",
    "    \"\"\"\n",
    "    # Convert Polars to Pandas\n",
    "    if isinstance(test_df, pl.DataFrame):\n",
    "        test_df = test_df.to_pandas()\n",
    "    if isinstance(test_input_df, pl.DataFrame):\n",
    "        test_input_df = test_input_df.to_pandas()\n",
    "\n",
    "    # Normalize player_to_predict to boolean for filtering\n",
    "    if 'player_to_predict' in test_input_df.columns:\n",
    "        if test_input_df['player_to_predict'].dtype == 'object':\n",
    "             # Handle string 'True'/'False'\n",
    "             test_input_df['player_to_predict'] = test_input_df['player_to_predict'].astype(str).str.lower() == 'true'\n",
    "        else:\n",
    "             # Handle boolean or numeric (1/0)\n",
    "             test_input_df['player_to_predict'] = test_input_df['player_to_predict'].astype(bool)\n",
    "\n",
    "    features_batch = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        # Filter for the specific player and play\n",
    "        # The test_df specifies which player (nfl_id) in which play (game_id, play_id) to predict\n",
    "        mask = (\n",
    "            (test_input_df['game_id'] == row['game_id']) & \n",
    "            (test_input_df['play_id'] == row['play_id']) & \n",
    "            (test_input_df['nfl_id'] == row['nfl_id'])\n",
    "        )\n",
    "        \n",
    "        # Strictly enforce player_to_predict == True\n",
    "        if 'player_to_predict' in test_input_df.columns:\n",
    "            mask = mask & (test_input_df['player_to_predict'] == True)\n",
    "            \n",
    "        player_data = test_input_df[mask]\n",
    "        \n",
    "        if player_data.empty:\n",
    "            # Fallback if no matching data found - return zeros of correct shape\n",
    "            seq = np.zeros((1, len(COLUMN_ORDER)))\n",
    "        else:\n",
    "            # Sort by frame_id to ensure temporal order\n",
    "            if 'frame_id' in player_data.columns:\n",
    "                player_data = player_data.sort_values('frame_id')\n",
    "            \n",
    "            seq = []\n",
    "            for _, r in player_data.iterrows():\n",
    "                frame_feats = []\n",
    "                # Extract all columns in the specific order used during training\n",
    "                for col in COLUMN_ORDER:\n",
    "                    if col in r:\n",
    "                        frame_feats.append(process_value(r[col]))\n",
    "                    else:\n",
    "                        # Missing column fallback\n",
    "                        frame_feats.append(0.0)\n",
    "                \n",
    "                seq.append(frame_feats)\n",
    "            \n",
    "            seq = np.array(seq)\n",
    "            \n",
    "        features_batch.append(seq)\n",
    "    \n",
    "    # Pad sequences to the max length in this batch\n",
    "    X_padded = pad_sequences(\n",
    "        features_batch, \n",
    "        dtype='float32',\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        value=0.0\n",
    "    )\n",
    "    \n",
    "    return X_padded\n",
    "\n",
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    Args:\n",
    "        test_df (pl.DataFrame or pd.DataFrame): Metadata for the prediction request.\n",
    "        test_input_df (pl.DataFrame or pd.DataFrame): Context data for the play.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'x' and 'y' predictions.\n",
    "    \"\"\"\n",
    "    load_model_if_needed()\n",
    "    \n",
    "    # Preprocess\n",
    "    features = preprocess(test_df, test_input_df)\n",
    "    \n",
    "    # Run inference\n",
    "    # model(features) is faster than model.predict(features) for small batches\n",
    "    # However, for large batches (like local testing), we use model.predict to handle batching and avoid OOM\n",
    "    if len(features) > 32:\n",
    "        predictions_xy = model.predict(features, batch_size=32, verbose=0)\n",
    "    else:\n",
    "        predictions_xy = model(features, training=False).numpy()\n",
    "    \n",
    "    # Handle 3D output (batch_size, time_steps, features)\n",
    "    # The model returns a sequence. We take the last timestep to get (batch_size, 2)\n",
    "    if len(predictions_xy.shape) == 3:\n",
    "        predictions_xy = predictions_xy[:, -1, :]\n",
    "        \n",
    "    # Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 3: INFERENCE SERVER (ENTRY POINT)\n",
    "# =================================================================================================\n",
    "# This block initializes the inference server provided by Kaggle.\n",
    "# =================================================================================================\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # if test_df_manual is not None and test_input_df_manual is not None:\n",
    "    #     print(\"Running local prediction test...\")\n",
    "    #     predictions = predict(test_df_manual, test_input_df_manual)\n",
    "    #     print(\"Predictions generated successfully:\")\n",
    "    #     print(predictions.head())\n",
    "    # else:\n",
    "    #     print(\"Skipping local test: Data not loaded.\")\n",
    "    pass\n",
    "\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/',))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
