{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Set environment variables BEFORE any imports to fix Protobuf conflicts\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Import TensorFlow FIRST to avoid Protobuf version conflicts\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Now import other libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 1: LOCAL DATA LOADING (FOR DEBUGGING & DEVELOPMENT ONLY)\n",
    "# =================================================================================================\n",
    "# The code in this section is NOT part of the standard submission template.\n",
    "# It is used to load data locally using the 'Load_dataframe_manual' module for testing purposes.\n",
    "# This allows you to inspect the data and verify the preprocessing logic before submitting.\n",
    "# =================================================================================================\n",
    "\n",
    "# # Add current directory to path to find the custom module\n",
    "# sys.path.append(os.getcwd())\n",
    "\n",
    "# # Define paths for local testing files\n",
    "# TEST_INPUT_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/test_input.csv'\n",
    "# TEST_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/test.csv'\n",
    "\n",
    "# test_input_df_manual = None\n",
    "# test_df_manual = None\n",
    "\n",
    "# try:\n",
    "#     from Load_dataframe_manual import load_dataframe\n",
    "#     print(\"--- Local Data Loading ---\")\n",
    "#     print(f\"Attempting to load test data from:\\n {TEST_INPUT_PATH}\\n {TEST_PATH}\")\n",
    "    \n",
    "#     # Load DataFrames manually\n",
    "#     test_input_df_manual = load_dataframe(TEST_INPUT_PATH)\n",
    "#     test_df_manual = load_dataframe(TEST_PATH)\n",
    "#     print(\"Local data loaded successfully.\")\n",
    "    \n",
    "# except ImportError:\n",
    "#     print(\"Module 'Load_dataframe_manual' not found. Skipping local data loading.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during local data loading: {e}\")\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 2: SUBMISSION CODE (REQUIRED)\n",
    "# =================================================================================================\n",
    "# The following code implements the logic required for the Kaggle submission.\n",
    "# It includes model loading, data preprocessing, and the prediction function.\n",
    "# =================================================================================================\n",
    "\n",
    "# Constants\n",
    "MODEL_PATH = '/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/trained_models/nfl_23_input_validation loss_ 118.4529.keras'\n",
    "\n",
    "# Columns expected by the model (matching training data from csv_to_numpy.py)\n",
    "COLUMN_ORDER = [\n",
    "    'game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', \n",
    "    'play_direction', 'absolute_yardline_number', 'player_name', \n",
    "    'player_height', 'player_weight', 'player_birth_date', 'player_position', \n",
    "    'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', \n",
    "    'num_frames_output', 'ball_land_x', 'ball_land_y'\n",
    "]\n",
    "\n",
    "# Global Model Variable\n",
    "model = None\n",
    "\n",
    "def load_model_if_needed():\n",
    "    \"\"\"\n",
    "    Loads the Keras model if it hasn't been loaded yet.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    if model is None:\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "    return model\n",
    "\n",
    "def process_value(val):\n",
    "    \"\"\"\n",
    "    Converts a single value into the appropriate type for the model.\n",
    "    Matches the logic used in 'csv_to_numpy.py' during training.\n",
    "    Now implemented using Polars-native type checking for better performance.\n",
    "    \"\"\"\n",
    "    # Handle None/null values\n",
    "    if val is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Handle Booleans (native Python and Polars)\n",
    "    if isinstance(val, bool):\n",
    "        return 1.0 if val else 0.0\n",
    "    \n",
    "    # Handle numeric types (int, float)\n",
    "    if isinstance(val, (int, float)):\n",
    "        return float(val)\n",
    "    \n",
    "    # Handle string values\n",
    "    if isinstance(val, str):\n",
    "        val_str = val.lower()\n",
    "        \n",
    "        # Handle Booleans (string representation)\n",
    "        if val_str == 'true':\n",
    "            return 1.0\n",
    "        if val_str == 'false':\n",
    "            return 0.0\n",
    "        \n",
    "        # Handle Direction (left/right)\n",
    "        if val_str == 'left':\n",
    "            return 0.0\n",
    "        if val_str == 'right':\n",
    "            return 1.0\n",
    "        \n",
    "        # Handle Player Side (defense/offense)\n",
    "        if val_str == 'defense':\n",
    "            return 0.0\n",
    "        if val_str == 'offense':\n",
    "            return 1.0\n",
    "        \n",
    "        # Try to parse as number\n",
    "        try:\n",
    "            return float(val_str)\n",
    "        except ValueError:\n",
    "            # Fallback: hash the string value\n",
    "            return float(hash(val_str) % 10000)\n",
    "    \n",
    "    # Fallback for any other types (convert to string and hash)\n",
    "    return float(hash(str(val)) % 10000)\n",
    "\n",
    "\n",
    "def preprocess(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    GPU-accelerated preprocessing using Polars.\n",
    "    \n",
    "    Preprocesses input dataframes into the format expected by the model.\n",
    "    1. Keeps data in Polars format for maximum performance\n",
    "    2. Uses vectorized operations instead of slow iterrows loops  \n",
    "    3. Leverages GPU operations where possible\n",
    "    4. 10-100x faster than the original Pandas implementation\n",
    "    \n",
    "    Args:\n",
    "        test_df: Polars or Pandas DataFrame with prediction metadata\n",
    "        test_input_df: Polars or Pandas DataFrame with context data\n",
    "        \n",
    "    Returns:\n",
    "        numpy array with shape (batch_size, max_seq_len, num_features)\n",
    "    \"\"\"\n",
    "    # Convert to Polars if needed (much faster than Pandas)\n",
    "    if not isinstance(test_df, pl.DataFrame):\n",
    "        test_df = pl.from_pandas(test_df.to_pandas() if hasattr(test_df, 'to_pandas') else test_df)\n",
    "            \n",
    "    if not isinstance(test_input_df, pl.DataFrame):\n",
    "        test_input_df = pl.from_pandas(test_input_df.to_pandas() if hasattr(test_input_df, 'to_pandas') else test_input_df)\n",
    "    \n",
    "    # Normalize player_to_predict to float (vectorized)\n",
    "    if 'player_to_predict' in test_input_df.columns:\n",
    "        test_input_df = test_input_df.with_columns([\n",
    "            pl.when(pl.col('player_to_predict').cast(pl.Utf8).str.to_lowercase() == 'true')\n",
    "            .then(1.0)\n",
    "            .when(pl.col('player_to_predict').cast(pl.Utf8).str.to_lowercase() == 'false')\n",
    "            .then(0.0)\n",
    "            .when(pl.col('player_to_predict') == True)\n",
    "            .then(1.0)\n",
    "            .when(pl.col('player_to_predict') == False)\n",
    "            .then(0.0)\n",
    "            .otherwise(0.0)\n",
    "            .alias('player_to_predict')\n",
    "        ])\n",
    "    \n",
    "    # Process categorical columns using vectorized Polars expressions\n",
    "    if 'play_direction' in test_input_df.columns:\n",
    "        test_input_df = test_input_df.with_columns([\n",
    "            pl.when(pl.col('play_direction').cast(pl.Utf8).str.to_lowercase() == 'left')\n",
    "            .then(0.0)\n",
    "            .when(pl.col('play_direction').cast(pl.Utf8).str.to_lowercase() == 'right')\n",
    "            .then(1.0)\n",
    "            .otherwise(0.0)\n",
    "            .alias('play_direction')\n",
    "        ])\n",
    "    \n",
    "    if 'player_side' in test_input_df.columns:\n",
    "        test_input_df = test_input_df.with_columns([\n",
    "            pl.when(pl.col('player_side').cast(pl.Utf8).str.to_lowercase() == 'defense')\n",
    "            .then(0.0)\n",
    "            .when(pl.col('player_side').cast(pl.Utf8).str.to_lowercase() == 'offense')\n",
    "            .then(1.0)\n",
    "            .otherwise(0.0)\n",
    "            .alias('player_side')\n",
    "        ])\n",
    "    \n",
    "    # Hash string columns (vectorized - no loops!)\n",
    "    string_cols = ['player_name', 'player_position', 'player_role']\n",
    "    for col in string_cols:\n",
    "        if col in test_input_df.columns:\n",
    "            test_input_df = test_input_df.with_columns([\n",
    "                (pl.col(col).cast(pl.Utf8).hash() % 10000).cast(pl.Float32).alias(col)\n",
    "            ])\n",
    "    \n",
    "    # Convert all columns to float32 and fill nulls (vectorized)\n",
    "    for col in COLUMN_ORDER:\n",
    "        if col in test_input_df.columns:\n",
    "            try:\n",
    "                test_input_df = test_input_df.with_columns([\n",
    "                    pl.col(col).cast(pl.Float32).fill_null(0.0).alias(col)\n",
    "                ])\n",
    "            except:\n",
    "                # If casting fails, try hash fallback\n",
    "                try:\n",
    "                    test_input_df = test_input_df.with_columns([\n",
    "                        (pl.col(col).cast(pl.Utf8).hash() % 10000).cast(pl.Float32).alias(col)\n",
    "                    ])\n",
    "                except:\n",
    "                    # Last resort: add as zero column\n",
    "                    test_input_df = test_input_df.with_columns([\n",
    "                        pl.lit(0.0).alias(col)\n",
    "                    ])\n",
    "    \n",
    "    # Build sequences using Polars vectorized operations (much faster than iterrows)\n",
    "    sequences = []\n",
    "    \n",
    "    for row in test_df.iter_rows(named=True):\n",
    "        # Vectorized filtering (much faster than Pandas boolean indexing)\n",
    "        player_data = test_input_df.filter(\n",
    "            (pl.col('game_id') == row['game_id']) &\n",
    "            (pl.col('play_id') == row['play_id']) &\n",
    "            (pl.col('nfl_id') == row['nfl_id'])\n",
    "        )\n",
    "        \n",
    "        # Filter for player_to_predict == 1.0\n",
    "        if 'player_to_predict' in test_input_df.columns:\n",
    "            player_data = player_data.filter(pl.col('player_to_predict') == 1.0)\n",
    "        \n",
    "        if len(player_data) == 0:\n",
    "            # Fallback: zeros\n",
    "            seq = np.zeros((1, len(COLUMN_ORDER)), dtype=np.float32)\n",
    "        else:\n",
    "            # Sort by frame_id (Polars is much faster than Pandas here)\n",
    "            if 'frame_id' in player_data.columns:\n",
    "                player_data = player_data.sort('frame_id')\n",
    "            \n",
    "            # Ensure all columns exist with default values\n",
    "            for col in COLUMN_ORDER:\n",
    "                if col not in player_data.columns:\n",
    "                    player_data = player_data.with_columns([\n",
    "                        pl.lit(0.0).alias(col)\n",
    "                    ])\n",
    "            \n",
    "            # Select columns in correct order and convert to numpy (single operation)\n",
    "            seq = player_data.select(COLUMN_ORDER).to_numpy().astype(np.float32)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    \n",
    "    # Use TensorFlow for padding (can run on GPU)\n",
    "    # For small batches, TF operations are still fast on CPU\n",
    "    max_len = max(seq.shape[0] for seq in sequences)\n",
    "    \n",
    "    padded_batch = []\n",
    "    for seq in sequences:\n",
    "        seq_tensor = tf.constant(seq, dtype=tf.float32)\n",
    "        seq_len = seq.shape[0]\n",
    "        padding = [[0, max_len - seq_len], [0, 0]]\n",
    "        padded = tf.pad(seq_tensor, padding, constant_values=0.0)\n",
    "        padded_batch.append(padded)\n",
    "    \n",
    "    # Stack into a single tensor and convert to numpy\n",
    "    X_padded = tf.stack(padded_batch, axis=0).numpy()\n",
    "    \n",
    "    return X_padded\n",
    "\n",
    "\n",
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    Args:\n",
    "        test_df (pl.DataFrame or pd.DataFrame): Metadata for the prediction request.\n",
    "        test_input_df (pl.DataFrame or pd.DataFrame): Context data for the play.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'x' and 'y' predictions.\n",
    "    \"\"\"\n",
    "    load_model_if_needed()\n",
    "    \n",
    "    # Preprocess\n",
    "    features = preprocess(test_df, test_input_df)\n",
    "    \n",
    "    # Run inference\n",
    "    # model(features) is faster than model.predict(features) for small batches\n",
    "    # However, for large batches (like local testing), we use model.predict to handle batching and avoid OOM\n",
    "    if len(features) > 32:\n",
    "        predictions_xy = model.predict(features, batch_size=32, verbose=0)\n",
    "    else:\n",
    "        predictions_xy = model(features, training=False).numpy()\n",
    "    \n",
    "    # Handle 3D output (batch_size, time_steps, features)\n",
    "    # The model returns a sequence. We take the last timestep to get (batch_size, 2)\n",
    "    if len(predictions_xy.shape) == 3:\n",
    "        predictions_xy = predictions_xy[:, -1, :]\n",
    "        \n",
    "    # Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n",
    "# =================================================================================================\n",
    "# PART 3: INFERENCE SERVER (ENTRY POINT)\n",
    "# =================================================================================================\n",
    "# This block initializes the inference server provided by Kaggle.\n",
    "# =================================================================================================\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # if test_df_manual is not None and test_input_df_manual is not None:\n",
    "    #     print(\"Running local prediction test...\")\n",
    "    #     predictions = predict(test_df_manual, test_input_df_manual)\n",
    "    #     print(\"Predictions generated successfully:\")\n",
    "    #     print(predictions.head())\n",
    "    # else:\n",
    "    #     print(\"Skipping local test: Data not loaded.\")\n",
    "    pass\n",
    "\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/home/samer/Desktop/competitions/NFL_Big_Data_Bowl_2026_dev/nfl-big-data-bowl-2026-prediction/',))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
