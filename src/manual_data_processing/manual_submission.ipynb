{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T15:01:29.713621Z",
     "iopub.status.busy": "2025-12-01T15:01:29.713339Z",
     "iopub.status.idle": "2025-12-01T15:02:38.362718Z",
     "shell.execute_reply": "2025-12-01T15:02:38.361932Z",
     "shell.execute_reply.started": "2025-12-01T15:01:29.713601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CRITICAL: Set environment variables BEFORE any imports to fix Protobuf conflicts\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Import TensorFlow FIRST to avoid Protobuf version conflicts\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Now import other libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import zlib\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "# =================================================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =================================================================================================\n",
    "\n",
    "MODEL_PATH = '/kaggle/input/m/samerattrah/nfl-supervised-submission-10/keras/default/1/best_model_submission_10.keras'\n",
    "\n",
    "# ID columns to EXCLUDE (matching csv_to_keras_sequence.py)\n",
    "ID_COLUMNS = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'player_to_predict', 'time']\n",
    "\n",
    "# Maximum sequence length (matching training data)\n",
    "MAX_SEQ_LENGTH = 10\n",
    "\n",
    "# Normalization Statistics\n",
    "# IMPORTANT: Replace these with the actual mean and std from your training data!\n",
    "# These must be numpy arrays of shape (18,) matching the feature columns.\n",
    "MEAN = None \n",
    "STD = None\n",
    "\n",
    "# Global Model Variable\n",
    "model = None\n",
    "\n",
    "def load_model_if_needed():\n",
    "    \"\"\"\n",
    "    Loads the Keras model if it hasn't been loaded yet.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    if model is None:\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"Model loaded successfully.\")\n",
    "            print(f\"Model expects input shape: {model.input_shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_value(val):\n",
    "    \"\"\"\n",
    "    Converts a single value into the appropriate numeric type.\n",
    "    Matches the logic used in csv_to_keras_sequence.py during training.\n",
    "    \"\"\"\n",
    "    # Handle None/null values\n",
    "    if val is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Handle Booleans\n",
    "    if isinstance(val, bool):\n",
    "        return 1.0 if val else 0.0\n",
    "    \n",
    "    # Handle numeric types\n",
    "    if isinstance(val, (int, float)):\n",
    "        return float(val)\n",
    "    \n",
    "    # Handle string values\n",
    "    if isinstance(val, str):\n",
    "        val_lower = val.lower()\n",
    "        \n",
    "        # Booleans\n",
    "        if val_lower == 'true':\n",
    "            return 1.0\n",
    "        if val_lower == 'false':\n",
    "            return 0.0\n",
    "        \n",
    "        # Direction\n",
    "        if val_lower == 'left':\n",
    "            return 0.0\n",
    "        if val_lower == 'right':\n",
    "            return 1.0\n",
    "        \n",
    "        # Player Side\n",
    "        if val_lower == 'defense':\n",
    "            return 0.0\n",
    "        if val_lower == 'offense':\n",
    "            return 1.0\n",
    "        \n",
    "        # Try to parse as number\n",
    "        try:\n",
    "            return float(val_lower)\n",
    "        except ValueError:\n",
    "            # Hash the string using zlib.adler32 to match training\n",
    "            return float(zlib.adler32(val.encode('utf-8')) % 10000)\n",
    "    \n",
    "    # Fallback: hash any other type\n",
    "    return float(zlib.adler32(str(val).encode('utf-8')) % 10000)\n",
    "\n",
    "\n",
    "def preprocess(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses input dataframes to match the format from csv_to_keras_sequence.py.\n",
    "    \n",
    "    Key differences from old implementation:\n",
    "    - Uses the SAME feature extraction as csv_to_keras_sequence.py\n",
    "    - Excludes ID columns: ['game_id', 'play_id', 'nfl_id', 'frame_id', 'player_to_predict', 'time']\n",
    "    - Takes ALL remaining columns as features (18 features)\n",
    "    - Filters for player_to_predict == True\n",
    "    - Applies Normalization if MEAN and STD are provided\n",
    "    \n",
    "    Args:\n",
    "        test_df: Polars or Pandas DataFrame with prediction metadata\n",
    "        test_input_df: Polars or Pandas DataFrame with context data\n",
    "        \n",
    "    Returns:\n",
    "        numpy array with shape (batch_size, MAX_SEQ_LENGTH, 18)\n",
    "    \"\"\"\n",
    "    # Convert to Polars if needed\n",
    "    if not isinstance(test_df, pl.DataFrame):\n",
    "        test_df = pl.from_pandas(test_df.to_pandas() if hasattr(test_df, 'to_pandas') else test_df)\n",
    "            \n",
    "    if not isinstance(test_input_df, pl.DataFrame):\n",
    "        test_input_df = pl.from_pandas(test_input_df.to_pandas() if hasattr(test_input_df, 'to_pandas') else test_input_df)\n",
    "    \n",
    "    # Get feature columns (all columns EXCEPT ID columns)\n",
    "    all_columns = test_input_df.columns\n",
    "    feature_cols = [col for col in all_columns if col not in ID_COLUMNS]\n",
    "    \n",
    "    # Process features using vectorized Polars operations\n",
    "    expressions = []\n",
    "    for col in feature_cols:\n",
    "        if test_input_df[col].dtype == pl.Utf8:\n",
    "            # Handle string columns\n",
    "            expr = (\n",
    "                pl.when(pl.col(col).str.to_lowercase() == \"true\").then(1.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"false\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"left\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"right\").then(1.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"defense\").then(0.0)\n",
    "                .when(pl.col(col).str.to_lowercase() == \"offense\").then(1.0)\n",
    "                .otherwise(\n",
    "                    pl.col(col).cast(pl.Float64, strict=False).fill_null(\n",
    "                        pl.col(col).map_elements(lambda x: float(zlib.adler32(x.encode('utf-8')) % 10000) if x else 0.0, return_dtype=pl.Float64)\n",
    "                    )\n",
    "                ).cast(pl.Float64).alias(col)\n",
    "            )\n",
    "            expressions.append(expr)\n",
    "        else:\n",
    "            # Numeric columns\n",
    "            expressions.append(pl.col(col).cast(pl.Float64).fill_null(0.0).alias(col))\n",
    "    \n",
    "    # Apply all transformations\n",
    "    test_input_df = test_input_df.with_columns(expressions)\n",
    "    \n",
    "    # Build sequences\n",
    "    sequences = []\n",
    "    \n",
    "    for row in test_df.iter_rows(named=True):\n",
    "        # Filter for this specific player\n",
    "        player_data = test_input_df.filter(\n",
    "            (pl.col('game_id') == row['game_id']) &\n",
    "            (pl.col('play_id') == row['play_id']) &\n",
    "            (pl.col('nfl_id') == row['nfl_id'])\n",
    "        )\n",
    "        \n",
    "        # Filter for player_to_predict == True (matching training data)\n",
    "        if 'player_to_predict' in test_input_df.columns:\n",
    "            player_data = player_data.filter(\n",
    "                (pl.col('player_to_predict') == 1.0) | \n",
    "                (pl.col('player_to_predict').cast(pl.Utf8).str.to_lowercase() == 'true')\n",
    "            )\n",
    "        \n",
    "        if len(player_data) == 0:\n",
    "            # Fallback: create zero sequence\n",
    "            seq = np.zeros((1, len(feature_cols)), dtype=np.float32)\n",
    "        else:\n",
    "            # Sort by frame_id\n",
    "            if 'frame_id' in player_data.columns:\n",
    "                player_data = player_data.sort('frame_id')\n",
    "            \n",
    "            # Select ONLY feature columns (excludes ID columns)\n",
    "            seq = player_data.select(feature_cols).to_numpy().astype(np.float32)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    \n",
    "    # Pad sequences to MAX_SEQ_LENGTH\n",
    "    X_padded = pad_sequences(\n",
    "        sequences,\n",
    "        maxlen=MAX_SEQ_LENGTH,\n",
    "        dtype='float32',\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        value=0.0\n",
    "    )\n",
    "    \n",
    "    # Normalize if stats are available\n",
    "    if MEAN is not None and STD is not None:\n",
    "        X_padded = (X_padded - MEAN) / STD\n",
    "    \n",
    "    return X_padded\n",
    "\n",
    "\n",
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    \n",
    "    Args:\n",
    "        test_df (pl.DataFrame or pd.DataFrame): Metadata for the prediction request.\n",
    "        test_input_df (pl.DataFrame or pd.DataFrame): Context data for the play.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'x' and 'y' predictions.\n",
    "    \"\"\"\n",
    "    load_model_if_needed()\n",
    "    \n",
    "    # Preprocess\n",
    "    features = preprocess(test_df, test_input_df)\n",
    "    \n",
    "    # Run inference\n",
    "    if len(features) > 32:\n",
    "        predictions_xy = model.predict(features, batch_size=32, verbose=0)\n",
    "    else:\n",
    "        predictions_xy = model(features, training=False).numpy()\n",
    "    \n",
    "    # Handle 3D output (batch_size, time_steps, features)\n",
    "    # The model returns a sequence of predictions, take the last timestep\n",
    "    if len(predictions_xy.shape) == 3:\n",
    "        predictions_xy = predictions_xy[:, -1, :]\n",
    "    \n",
    "    # Ensure we have exactly 2 features (x, y)\n",
    "    if predictions_xy.shape[1] != 2:\n",
    "        predictions_xy = predictions_xy[:, :2]  # Take first 2 columns\n",
    "    \n",
    "    # Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n",
    "\n",
    "# =================================================================================================\n",
    "# INFERENCE SERVER (ENTRY POINT)\n",
    "# =================================================================================================\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    pass\n",
    "\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # For local testing\n",
    "    inference_server.run_local_gateway((\n",
    "        '/kaggle/input/nfl-big-data-bowl-2026-prediction/',\n",
    "    ))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "isSourceIdPinned": false,
     "sourceId": 114239,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 514731,
     "modelInstanceId": 499494,
     "sourceId": 660402,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 519117,
     "modelInstanceId": 504062,
     "sourceId": 665939,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 520682,
     "modelInstanceId": 505875,
     "sourceId": 668182,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 520787,
     "modelInstanceId": 505990,
     "sourceId": 668320,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 521021,
     "modelInstanceId": 506219,
     "sourceId": 668589,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 521157,
     "modelInstanceId": 506365,
     "sourceId": 668748,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 521169,
     "modelInstanceId": 506378,
     "sourceId": 668763,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
