{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "This cell imports the necessary Python libraries for the submission, including `pandas` for data manipulation, `numpy` for numerical operations, `tensorflow` for running the model inference, and `joblib` for loading the saved preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:29:16.030094Z",
     "iopub.status.busy": "2025-11-21T09:29:16.029859Z",
     "iopub.status.idle": "2025-11-21T09:30:44.142111Z",
     "shell.execute_reply": "2025-11-21T09:30:44.141299Z",
     "shell.execute_reply.started": "2025-11-21T09:29:16.030069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow keras\n",
    "!pip install --upgrade polars\n",
    "!pip install --upgrade scikit-learn==1.7.2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "\n",
    "os.environ['KAGGLE_IS_COMPETITION_RERUN'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Constants and Utility Functions\n",
    "This cell defines a helper function `height_to_inches` to convert player height into a numerical format. It also sets up global constants for the model's `SEQUENCE_LENGTH` and the file paths for the saved model (`MODEL_PATH`) and preprocessor (`PREPROCESSOR_PATH`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:30:44.144381Z",
     "iopub.status.busy": "2025-11-21T09:30:44.143950Z",
     "iopub.status.idle": "2025-11-21T09:30:44.148972Z",
     "shell.execute_reply": "2025-11-21T09:30:44.148238Z",
     "shell.execute_reply.started": "2025-11-21T09:30:44.144358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def height_to_inches(height_str):\n",
    "    \"\"\"\n",
    "    Converts height string 'feet-inches' to inches.\n",
    "    \"\"\"\n",
    "    if isinstance(height_str, str):\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return feet * 12 + inches\n",
    "    return np.nan\n",
    "\n",
    "SEQUENCE_LENGTH = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model and Preprocessor\n",
    "This cell defines the `load_artifacts` function, which loads the trained Keras model and the scikit-learn preprocessor from the files specified in the constants. It includes error handling to raise a `FileNotFoundError` if either of the files is missing, which is crucial for debugging in the Kaggle environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:30:44.149956Z",
     "iopub.status.busy": "2025-11-21T09:30:44.149727Z",
     "iopub.status.idle": "2025-11-21T09:30:44.874841Z",
     "shell.execute_reply": "2025-11-21T09:30:44.873938Z",
     "shell.execute_reply.started": "2025-11-21T09:30:44.149923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/kaggle/input/first-kt-product-100-epochs-nfl-model/keras/default/1/first_KT_product_100_epochs_nfl_model.h5\"\n",
    "PREPROCESSOR_PATH = '/kaggle/input/first-kt-product-100-epochs-nfl-model/keras/default/1/first_KT_product_100_epochs_nfl_preprocessor.joblib'\n",
    "\n",
    "def load_artifacts():\n",
    "    \"\"\"\n",
    "    Loads the trained Keras model and the preprocessor from disk.\n",
    "    Raises FileNotFoundError if either artifact is missing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please train the model first by running predictor.py.\")\n",
    "    if not os.path.exists(PREPROCESSOR_PATH):\n",
    "        raise FileNotFoundError(f\"Preprocessor file not found at {PREPROCESSOR_PATH}. Please train the model first.\")\n",
    "\n",
    "    print(f\"Loading model from {MODEL_PATH}\")\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    print(f\"Loading preprocessor from {PREPROCESSOR_PATH}\")\n",
    "    preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "    \n",
    "    return model, preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess Features for Inference\n",
    "First, the model and preprocessor are loaded into global memory to be available for the `predict` function without reloading on each call. The `preprocess_features` function replicates the exact feature engineering and preprocessing steps used during training. It takes the raw test dataframes, combines them, creates features like player `age`, applies the pre-fitted `preprocessor`, and finally constructs the input sequences of `SEQUENCE_LENGTH` frames that the LSTM model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:30:44.876053Z",
     "iopub.status.busy": "2025-11-21T09:30:44.875787Z",
     "iopub.status.idle": "2025-11-21T09:30:47.121100Z",
     "shell.execute_reply": "2025-11-21T09:30:47.120470Z",
     "shell.execute_reply.started": "2025-11-21T09:30:44.876026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the model globally to avoid reloading it for each batch.\n",
    "model, preprocessor = load_artifacts()\n",
    "\n",
    "def preprocess_features(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw input dataframes into a format the model expects.\n",
    "    This function replicates the feature engineering and sequence creation from\n",
    "    the training pipeline (`data_loader.py`).\n",
    "    \n",
    "    Args:\n",
    "        test_df (pd.DataFrame): The dataframe with the rows to predict.\n",
    "        test_input_df (pd.DataFrame): The dataframe with the input features for the play.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A 3D array of shape (num_predictions, SEQUENCE_LENGTH, num_features)\n",
    "                  ready to be fed into the LSTM model.\n",
    "    \"\"\"\n",
    "    num_predictions = len(test_df)\n",
    "    if num_predictions == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    # Combine input data for the entire play. `test_input_df` contains frame 0 (the context),\n",
    "    # and `test_df` contains the frames we need to predict for.\n",
    "    play_df = pd.concat([test_input_df, test_df], ignore_index=True)\n",
    "    play_df = play_df.sort_values(by=['nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "\n",
    "    # 1. Recreate the exact same features as in training\n",
    "    play_df['height_inches'] = play_df['player_height'].apply(height_to_inches)\n",
    "    game_date_str = play_df['game_id'].astype(str).str[:8]\n",
    "    game_date = pd.to_datetime(game_date_str, format='%Y%m%d')\n",
    "    player_birth_date = pd.to_datetime(play_df['player_birth_date'])\n",
    "    play_df['age'] = (game_date - player_birth_date).dt.days / 365.25\n",
    "\n",
    "    # 2. Apply the pre-fitted preprocessor\n",
    "    feature_cols = preprocessor.feature_names_in_\n",
    "    processed_features_array = preprocessor.transform(play_df[feature_cols])\n",
    "    processed_features_df = pd.DataFrame(processed_features_array, index=play_df.index)\n",
    "\n",
    "    # 3. Create sequences for each row in the original `test_df` (each row to predict)\n",
    "    processed_df_with_ids = pd.concat([play_df[['nfl_id', 'frame_id']], processed_features_df], axis=1)\n",
    "    sequences = []\n",
    "    for _, row_to_predict in test_df.iterrows():\n",
    "        player_id = row_to_predict['nfl_id']\n",
    "        frame_id = row_to_predict['frame_id']\n",
    "        \n",
    "        # Find the player's data and the exact frame we need to predict\n",
    "        player_data_with_ids = processed_df_with_ids[processed_df_with_ids['nfl_id'] == player_id]\n",
    "        prediction_frame_index = player_data_with_ids[player_data_with_ids['frame_id'] == frame_id].index[0]\n",
    "        \n",
    "        # The sequence consists of the `SEQUENCE_LENGTH` frames *before* the prediction frame\n",
    "        start_idx = prediction_frame_index - SEQUENCE_LENGTH\n",
    "        end_idx = prediction_frame_index\n",
    "        \n",
    "        if start_idx < 0:\n",
    "            # If we don't have enough history, pad with the first frame or zeros\n",
    "            # Here we slice from 0 to end_idx\n",
    "            sequence = processed_features_df.iloc[0:end_idx].values\n",
    "            # Pad with zeros at the beginning\n",
    "            pad_width = SEQUENCE_LENGTH - len(sequence)\n",
    "            if pad_width > 0:\n",
    "                # Pad with the first available frame (repetition) or zeros. \n",
    "                # Using zeros is safer if we assume missing history means 'nothing happened'\n",
    "                # But repetition might be better for continuity. Let's use zero padding for now as it's standard.\n",
    "                padding = np.zeros((pad_width, sequence.shape[1]))\n",
    "                sequence = np.vstack([padding, sequence])\n",
    "        else:\n",
    "            # Slice the sequence from the purely numerical dataframe\n",
    "            sequence = processed_features_df.iloc[start_idx:end_idx].values\n",
    "        \n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions\n",
    "The `predict` function is the core of the inference logic. It receives data for a single play, converts the dataframes to pandas, and passes them to `preprocess_features` to get the model inputs. It then runs the prediction using the loaded model and formats the output into a pandas DataFrame with 'x' and 'y' columns as required by the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:30:47.122106Z",
     "iopub.status.busy": "2025-11-21T09:30:47.121804Z",
     "iopub.status.idle": "2025-11-21T09:30:47.127021Z",
     "shell.execute_reply": "2025-11-21T09:30:47.126252Z",
     "shell.execute_reply.started": "2025-11-21T09:30:47.122087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    \"\"\"\n",
    "    # The gateway provides polars dataframes, convert them to pandas\n",
    "    test_df = test_df.to_pandas()\n",
    "    test_input_df = test_input_df.to_pandas()\n",
    "\n",
    "    # 1. Preprocess the data to create features for the model\n",
    "    features = preprocess_features(test_df, test_input_df)\n",
    "\n",
    "    if features.shape[0] == 0:\n",
    "        return pd.DataFrame([], columns=['x', 'y'])\n",
    "    \n",
    "    if scipy.sparse.issparse(features):\n",
    "        features = features.toarray()\n",
    "    # 2. Run inference\n",
    "    # Calling the model directly is often faster for inference than model.predict()\n",
    "    predictions_xy = model(features, training=False).numpy()\n",
    "\n",
    "    if scipy.sparse.issparse(predictions_xy):\n",
    "        preds = predictions_xy.toarray()\n",
    "\n",
    "    # 3. Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Inference Server\n",
    "This final cell sets up the Kaggle evaluation environment. It initializes the `NFLInferenceServer` with our `predict` function. The server will then either run in a live competition environment or use a local gateway for testing, depending on the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-21T09:31:52.310Z",
     "iopub.execute_input": "2025-11-21T09:30:47.128150Z",
     "iopub.status.busy": "2025-11-21T09:30:47.127899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "isSourceIdPinned": false,
     "sourceId": 114239,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 510781,
     "modelInstanceId": 495376,
     "sourceId": 655455,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
