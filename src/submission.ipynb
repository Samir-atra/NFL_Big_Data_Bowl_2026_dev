{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b8c7d6",
   "metadata": {},
   "source": [
    "### 1. Import Libraries\n",
    "This cell imports the necessary Python libraries for the submission, including `pandas` for data manipulation, `numpy` for numerical operations, `tensorflow` for running the model inference, and `joblib` for loading the saved preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c2d1",
   "metadata": {},
   "source": [
    "### 2. Define Constants and Utility Functions\n",
    "This cell defines a helper function `height_to_inches` to convert player height into a numerical format. It also sets up global constants for the model's `SEQUENCE_LENGTH` and the file paths for the saved model (`MODEL_PATH`) and preprocessor (`PREPROCESSOR_PATH`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_inches(height_str):\n",
    "    \"\"\"\n",
    "    Converts height string 'feet-inches' to inches.\n",
    "    \"\"\"\n",
    "    if isinstance(height_str, str):\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return feet * 12 + inches\n",
    "    return np.nan\n",
    "\n",
    "SEQUENCE_LENGTH = 10\n",
    "MODEL_PATH = 'nfl_model.h5'\n",
    "PREPROCESSOR_PATH = 'preprocessor.joblib'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4e3f2",
   "metadata": {},
   "source": [
    "### 3. Load Model and Preprocessor\n",
    "This cell defines the `load_artifacts` function, which loads the trained Keras model and the scikit-learn preprocessor from the files specified in the constants. It includes error handling to raise a `FileNotFoundError` if either of the files is missing, which is crucial for debugging in the Kaggle environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_artifacts():\n",
    "    \"\"\"\n",
    "    Loads the trained Keras model and the preprocessor from disk.\n",
    "    Raises FileNotFoundError if either artifact is missing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please train the model first by running predictor.py.\")\n",
    "    if not os.path.exists(PREPROCESSOR_PATH):\n",
    "        raise FileNotFoundError(f\"Preprocessor file not found at {PREPROCESSOR_PATH}. Please train the model first.\")\n",
    "\n",
    "    print(f\"Loading model from {MODEL_PATH}\")\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    print(f\"Loading preprocessor from {PREPROCESSOR_PATH}\")\n",
    "    preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "    \n",
    "    return model, preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5f4a3",
   "metadata": {},
   "source": [
    "### 4. Preprocess Features for Inference\n",
    "First, the model and preprocessor are loaded into global memory to be available for the `predict` function without reloading on each call. The `preprocess_features` function replicates the exact feature engineering and preprocessing steps used during training. It takes the raw test dataframes, combines them, creates features like player `age`, applies the pre-fitted `preprocessor`, and finally constructs the input sequences of `SEQUENCE_LENGTH` frames that the LSTM model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model globally to avoid reloading it for each batch.\n",
    "model, preprocessor = load_artifacts()\n",
    "\n",
    "def preprocess_features(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw input dataframes into a format the model expects.\n",
    "    This function replicates the feature engineering and sequence creation from\n",
    "    the training pipeline (`data_loader.py`).\n",
    "    \n",
    "    Args:\n",
    "        test_df (pd.DataFrame): The dataframe with the rows to predict.\n",
    "        test_input_df (pd.DataFrame): The dataframe with the input features for the play.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A 3D array of shape (num_predictions, SEQUENCE_LENGTH, num_features)\n",
    "                  ready to be fed into the LSTM model.\n",
    "    \"\"\"\n",
    "    num_predictions = len(test_df)\n",
    "    if num_predictions == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    # Combine input data for the entire play. `test_input_df` contains frame 0 (the context),\n",
    "    # and `test_df` contains the frames we need to predict for.\n",
    "    play_df = pd.concat([test_input_df, test_df], ignore_index=True)\n",
    "    play_df = play_df.sort_values(by=['nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "\n",
    "    # 1. Apply the pre-fitted preprocessor\n",
    "    # The feature columns are determined by what the preprocessor was trained on\n",
    "    feature_cols = [col for col in preprocessor.feature_names_in_]\n",
    "    processed_features_array = preprocessor.transform(play_df[feature_cols])\n",
    "    processed_features_df = pd.DataFrame(processed_features_array, index=play_df.index)\n",
    "\n",
    "    # Add back identifiers needed for sequence creation\n",
    "    processed_df = pd.concat([play_df[['nfl_id', 'frame_id']], processed_features_df], axis=1)\n",
    "    \n",
    "    # 3. Create sequences for each row in the original `test_df` (each row to predict)\n",
    "    sequences = []\n",
    "    for _, row_to_predict in test_df.iterrows():\n",
    "        player_id = row_to_predict['nfl_id']\n",
    "        frame_id = row_to_predict['frame_id']\n",
    "        \n",
    "        # Find the player's data and the exact frame we need to predict\n",
    "        player_data = processed_df[processed_df['nfl_id'] == player_id]\n",
    "        prediction_frame_index = player_data[player_data['frame_id'] == frame_id].index[0]\n",
    "        \n",
    "        # The sequence consists of the `SEQUENCE_LENGTH` frames *before* the prediction frame\n",
    "        start_idx = prediction_frame_index - SEQUENCE_LENGTH\n",
    "        end_idx = prediction_frame_index\n",
    "        \n",
    "        sequence = player_data.iloc[start_idx:end_idx].drop(columns=['nfl_id', 'frame_id']).values\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return np.array(sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6a5b4",
   "metadata": {},
   "source": [
    "### 5. Make Predictions\n",
    "The `predict` function is the core of the inference logic. It receives data for a single play, converts the dataframes to pandas, and passes them to `preprocess_features` to get the model inputs. It then runs the prediction using the loaded model and formats the output into a pandas DataFrame with 'x' and 'y' columns as required by the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    \"\"\"\n",
    "    # The gateway provides polars dataframes, convert them to pandas\n",
    "    test_df = test_df.to_pandas()\n",
    "    test_input_df = test_input_df.to_pandas()\n",
    "\n",
    "    # 1. Preprocess the data to create features for the model\n",
    "    features = preprocess_features(test_df, test_input_df)\n",
    "\n",
    "    if features.shape[0] == 0:\n",
    "        return pd.DataFrame([], columns=['x', 'y'])\n",
    "\n",
    "    # 2. Run inference\n",
    "    # Calling the model directly is often faster for inference than model.predict()\n",
    "    predictions_xy = model(features, training=False).numpy()\n",
    "\n",
    "    # 3. Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807b6c5",
   "metadata": {},
   "source": [
    "### 6. Run Inference Server\n",
    "This final cell sets up the Kaggle evaluation environment. It initializes the `NFLInferenceServer` with our `predict` function. The server will then either run in a live competition environment or use a local gateway for testing, depending on the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e08bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
