{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_inches(height_str):\n",
    "    \"\"\"\n",
    "    Converts height string 'feet-inches' to inches.\n",
    "    \"\"\"\n",
    "    if isinstance(height_str, str):\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return feet * 12 + inches\n",
    "    return np.nan\n",
    "\n",
    "SEQUENCE_LENGTH = 10\n",
    "MODEL_PATH = 'nfl_model.h5'\n",
    "PREPROCESSOR_PATH = 'preprocessor.joblib'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_artifacts():\n",
    "    \"\"\"\n",
    "    Loads the trained Keras model and the preprocessor from disk.\n",
    "    Raises FileNotFoundError if either artifact is missing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please train the model first by running predictor.py.\")\n",
    "    if not os.path.exists(PREPROCESSOR_PATH):\n",
    "        raise FileNotFoundError(f\"Preprocessor file not found at {PREPROCESSOR_PATH}. Please train the model first.\")\n",
    "\n",
    "    print(f\"Loading model from {MODEL_PATH}\")\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    print(f\"Loading preprocessor from {PREPROCESSOR_PATH}\")\n",
    "    preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "    \n",
    "    return model, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model globally to avoid reloading it for each batch.\n",
    "model, preprocessor = load_artifacts()\n",
    "\n",
    "def preprocess_features(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw input dataframes into a format the model expects.\n",
    "    This function replicates the feature engineering and sequence creation from\n",
    "    the training pipeline (`data_loader.py`).\n",
    "    \n",
    "    Args:\n",
    "        test_df (pd.DataFrame): The dataframe with the rows to predict.\n",
    "        test_input_df (pd.DataFrame): The dataframe with the input features for the play.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A 3D array of shape (num_predictions, SEQUENCE_LENGTH, num_features)\n",
    "                  ready to be fed into the LSTM model.\n",
    "    \"\"\"\n",
    "    num_predictions = len(test_df)\n",
    "    if num_predictions == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    # Combine input data for the entire play. `test_input_df` contains frame 0 (the context),\n",
    "    # and `test_df` contains the frames we need to predict for.\n",
    "    play_df = pd.concat([test_input_df, test_df], ignore_index=True)\n",
    "    play_df = play_df.sort_values(by=['nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "\n",
    "    # 1. Recreate the exact same features as in training\n",
    "    play_df['height_inches'] = play_df['player_height'].apply(height_to_inches)\n",
    "    game_date_str = play_df['game_id'].astype(str).str[:8]\n",
    "    game_date = pd.to_datetime(game_date_str, format='%Y%m%d')\n",
    "    player_birth_date = pd.to_datetime(play_df['player_birth_date'])\n",
    "    play_df['age'] = (game_date - player_birth_date).dt.days / 365.25\n",
    "\n",
    "    # 2. Apply the pre-fitted preprocessor\n",
    "    feature_cols = preprocessor.feature_names_in_\n",
    "    processed_features_array = preprocessor.transform(play_df[feature_cols])\n",
    "    processed_features_df = pd.DataFrame(processed_features_array, index=play_df.index)\n",
    "\n",
    "    # Add back identifiers needed for sequence creation\n",
    "    processed_df = pd.concat([play_df[['nfl_id', 'frame_id']], processed_features_df], axis=1)\n",
    "    \n",
    "    # 3. Create sequences for each row in the original `test_df` (each row to predict)\n",
    "    sequences = []\n",
    "    for _, row_to_predict in test_df.iterrows():\n",
    "        player_id = row_to_predict['nfl_id']\n",
    "        frame_id = row_to_predict['frame_id']\n",
    "        \n",
    "        # Find the player's data and the exact frame we need to predict\n",
    "        player_data = processed_df[processed_df['nfl_id'] == player_id]\n",
    "        prediction_frame_index = player_data[player_data['frame_id'] == frame_id].index[0]\n",
    "        \n",
    "        # The sequence consists of the `SEQUENCE_LENGTH` frames *before* the prediction frame\n",
    "        start_idx = prediction_frame_index - SEQUENCE_LENGTH\n",
    "        end_idx = prediction_frame_index\n",
    "        \n",
    "        sequence = player_data.iloc[start_idx:end_idx].drop(columns=['nfl_id', 'frame_id']).values\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return np.array(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, test_input_df):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single batch (play).\n",
    "    \"\"\"\n",
    "    # The gateway provides polars dataframes, convert them to pandas\n",
    "    test_df = test_df.to_pandas()\n",
    "    test_input_df = test_input_df.to_pandas()\n",
    "\n",
    "    # 1. Preprocess the data to create features for the model\n",
    "    features = preprocess_features(test_df, test_input_df)\n",
    "\n",
    "    if features.shape[0] == 0:\n",
    "        return pd.DataFrame([], columns=['x', 'y'])\n",
    "\n",
    "    # 2. Run inference\n",
    "    # Calling the model directly is often faster for inference than model.predict()\n",
    "    predictions_xy = model(features, training=False).numpy()\n",
    "\n",
    "    # 3. Format the predictions into the required DataFrame\n",
    "    return pd.DataFrame(predictions_xy, columns=['x', 'y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e08bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
