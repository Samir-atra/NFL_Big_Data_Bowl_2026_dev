{"metadata":{"kernelspec":{"name":"","display_name":""},"language_info":{"name":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a9b8c7d6","cell_type":"markdown","source":"### 1. Import Libraries\nThis cell imports the necessary Python libraries for the submission, including `pandas` for data manipulation, `numpy` for numerical operations, `tensorflow` for running the model inference, and `joblib` for loading the saved preprocessor.","metadata":{}},{"id":"b345c3d2","cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport joblib\n","metadata":{},"outputs":[],"execution_count":null},{"id":"b4a3c2d1","cell_type":"markdown","source":"### 2. Define Constants and Utility Functions\nThis cell defines a helper function `height_to_inches` to convert player height into a numerical format. It also sets up global constants for the model's `SEQUENCE_LENGTH` and the file paths for the saved model (`MODEL_PATH`) and preprocessor (`PREPROCESSOR_PATH`).","metadata":{}},{"id":"179f438c","cell_type":"code","source":"def height_to_inches(height_str):\n    \"\"\"\n    Converts height string 'feet-inches' to inches.\n    \"\"\"\n    if isinstance(height_str, str):\n        feet, inches = map(int, height_str.split('-'))\n        return feet * 12 + inches\n    return np.nan\n\nSEQUENCE_LENGTH = 10\nMODEL_PATH = 'nfl_model.h5'\nPREPROCESSOR_PATH = 'preprocessor.joblib'\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c5d4e3f2","cell_type":"markdown","source":"### 3. Load Model and Preprocessor\nThis cell defines the `load_artifacts` function, which loads the trained Keras model and the scikit-learn preprocessor from the files specified in the constants. It includes error handling to raise a `FileNotFoundError` if either of the files is missing, which is crucial for debugging in the Kaggle environment.","metadata":{}},{"id":"111d9798","cell_type":"code","source":"MODEL_PATH = 'nfl_model.h5'\nPREPROCESSOR_PATH = 'preprocessor.joblib'\n\ndef load_artifacts():\n    \"\"\"\n    Loads the trained Keras model and the preprocessor from disk.\n    Raises FileNotFoundError if either artifact is missing.\n    \"\"\"\n    if not os.path.exists(MODEL_PATH):\n        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please train the model first by running predictor.py.\")\n    if not os.path.exists(PREPROCESSOR_PATH):\n        raise FileNotFoundError(f\"Preprocessor file not found at {PREPROCESSOR_PATH}. Please train the model first.\")\n\n    print(f\"Loading model from {MODEL_PATH}\")\n    model = tf.keras.models.load_model(MODEL_PATH)\n    \n    print(f\"Loading preprocessor from {PREPROCESSOR_PATH}\")\n    preprocessor = joblib.load(PREPROCESSOR_PATH)\n    \n    return model, preprocessor","metadata":{},"outputs":[],"execution_count":null},{"id":"d6e5f4a3","cell_type":"markdown","source":"### 4. Preprocess Features for Inference\nFirst, the model and preprocessor are loaded into global memory to be available for the `predict` function without reloading on each call. The `preprocess_features` function replicates the exact feature engineering and preprocessing steps used during training. It takes the raw test dataframes, combines them, creates features like player `age`, applies the pre-fitted `preprocessor`, and finally constructs the input sequences of `SEQUENCE_LENGTH` frames that the LSTM model expects.","metadata":{}},{"id":"8dca9dbc","cell_type":"code","source":"# Load the model globally to avoid reloading it for each batch.\nmodel, preprocessor = load_artifacts()\n\ndef preprocess_features(test_df, test_input_df):\n    \"\"\"\n    Preprocesses the raw input dataframes into a format the model expects.\n    This function replicates the feature engineering and sequence creation from\n    the training pipeline (`data_loader.py`).\n    \n    Args:\n        test_df (pd.DataFrame): The dataframe with the rows to predict.\n        test_input_df (pd.DataFrame): The dataframe with the input features for the play.\n\n    Returns:\n        np.array: A 3D array of shape (num_predictions, SEQUENCE_LENGTH, num_features)\n                  ready to be fed into the LSTM model.\n    \"\"\"\n    num_predictions = len(test_df)\n    if num_predictions == 0:\n        return np.array([])\n\n    # Combine input data for the entire play. `test_input_df` contains frame 0 (the context),\n    # and `test_df` contains the frames we need to predict for.\n    play_df = pd.concat([test_input_df, test_df], ignore_index=True)\n    play_df = play_df.sort_values(by=['nfl_id', 'frame_id']).reset_index(drop=True)\n\n    # 1. Recreate the exact same features as in training\n    play_df['height_inches'] = play_df['player_height'].apply(height_to_inches)\n    game_date_str = play_df['game_id'].astype(str).str[:8]\n    game_date = pd.to_datetime(game_date_str, format='%Y%m%d')\n    player_birth_date = pd.to_datetime(play_df['player_birth_date'])\n    play_df['age'] = (game_date - player_birth_date).dt.days / 365.25\n\n    # 2. Apply the pre-fitted preprocessor\n    feature_cols = preprocessor.feature_names_in_\n    processed_features_array = preprocessor.transform(play_df[feature_cols])\n    processed_features_df = pd.DataFrame(processed_features_array, index=play_df.index)\n\n    # 3. Create sequences for each row in the original `test_df` (each row to predict)\n    processed_df_with_ids = pd.concat([play_df[['nfl_id', 'frame_id']], processed_features_df], axis=1)\n    sequences = []\n    for _, row_to_predict in test_df.iterrows():\n        player_id = row_to_predict['nfl_id']\n        frame_id = row_to_predict['frame_id']\n        \n        # Find the player's data and the exact frame we need to predict\n        player_data_with_ids = processed_df_with_ids[processed_df_with_ids['nfl_id'] == player_id]\n        prediction_frame_index = player_data_with_ids[player_data_with_ids['frame_id'] == frame_id].index[0]\n        \n        # The sequence consists of the `SEQUENCE_LENGTH` frames *before* the prediction frame\n        start_idx = prediction_frame_index - SEQUENCE_LENGTH\n        end_idx = prediction_frame_index\n        \n        if start_idx < 0:\n            # If we don't have enough history, pad with the first frame or zeros\n            # Here we slice from 0 to end_idx\n            sequence = processed_features_df.iloc[0:end_idx].values\n            # Pad with zeros at the beginning\n            pad_width = SEQUENCE_LENGTH - len(sequence)\n            if pad_width > 0:\n                # Pad with the first available frame (repetition) or zeros. \n                # Using zeros is safer if we assume missing history means 'nothing happened'\n                # But repetition might be better for continuity. Let's use zero padding for now as it's standard.\n                padding = np.zeros((pad_width, sequence.shape[1]))\n                sequence = np.vstack([padding, sequence])\n        else:\n            # Slice the sequence from the purely numerical dataframe\n            sequence = processed_features_df.iloc[start_idx:end_idx].values\n        \n        sequences.append(sequence)\n\n    return np.array(sequences)","metadata":{},"outputs":[],"execution_count":null},{"id":"e7f6a5b4","cell_type":"markdown","source":"### 5. Make Predictions\nThe `predict` function is the core of the inference logic. It receives data for a single play, converts the dataframes to pandas, and passes them to `preprocess_features` to get the model inputs. It then runs the prediction using the loaded model and formats the output into a pandas DataFrame with 'x' and 'y' columns as required by the competition.","metadata":{}},{"id":"b67e09e0","cell_type":"code","source":"def predict(test_df, test_input_df):\n    \"\"\"\n    Generates predictions for a single batch (play).\n    \"\"\"\n    # The gateway provides polars dataframes, convert them to pandas\n    test_df = test_df.to_pandas()\n    test_input_df = test_input_df.to_pandas()\n\n    # 1. Preprocess the data to create features for the model\n    features = preprocess_features(test_df, test_input_df)\n\n    if features.shape[0] == 0:\n        return pd.DataFrame([], columns=['x', 'y'])\n    \n    if scipy.sparse.issparse(features):\n        features = features.toarray()\n    # 2. Run inference\n    # Calling the model directly is often faster for inference than model.predict()\n    predictions_xy = model(features, training=False).numpy()\n\n    if scipy.sparse.issparse(predictions_xy):\n        preds = predictions_xy.toarray()\n\n    # 3. Format the predictions into the required DataFrame\n    return pd.DataFrame(predictions_xy, columns=['x', 'y'])","metadata":{},"outputs":[],"execution_count":null},{"id":"f807b6c5","cell_type":"markdown","source":"### 6. Run Inference Server\nThis final cell sets up the Kaggle evaluation environment. It initializes the `NFLInferenceServer` with our `predict` function. The server will then either run in a live competition environment or use a local gateway for testing, depending on the environment variables.","metadata":{}},{"id":"f6e08bf6","cell_type":"code","source":"inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))\n    ","metadata":{},"outputs":[],"execution_count":null}]}